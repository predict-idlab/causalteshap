{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt, erf, exp\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report,auc,r2_score,matthews_corrcoef\n",
    "from catboost import CatBoostRegressor,CatBoostClassifier\n",
    "from catboost.utils import get_roc_curve\n",
    "import shap\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "from sklearn import preprocessing\n",
    "from catboost import Pool, cv\n",
    "from scipy import stats\n",
    "import copy\n",
    "from sklearn import feature_selection as fs\n",
    "from tabulate import tabulate\n",
    "import tensorflow as tf\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "from numpy.random import RandomState\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stat\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def print_coef(model, columns):\n",
    "    \"\"\" Plot logistic regression model coefficients \"\"\" \n",
    "    coef = np.abs(pd.DataFrame(np.transpose(model.coef_), index = columns, columns = ['Coefficients']))\n",
    "    coef = coef.sort_values(by=['Coefficients'], ascending=True)\n",
    "    plt.figure(figsize = (6,18))\n",
    "    plt.scatter(y = range(len(coef)), x = coef['Coefficients'])\n",
    "    plt.yticks(range(len(coef)),coef.index, rotation = 'horizontal')\n",
    "    plt.xlabel('LR coefficient')\n",
    "    if present:\n",
    "        ax = plt.gca()\n",
    "        ax.patch.set_alpha(0)\n",
    "    plt.show()\n",
    "    #return coef\n",
    "    \n",
    "def print_coef_std_int(coefs,intercept, columns_feat):\n",
    "    \"\"\" Plot logistic regression model coefficients \"\"\" \n",
    "    coef = pd.DataFrame(coefs, columns = columns_feat)\n",
    "    #coef = coef.sort_values(by=['Coefficients'], ascending=True)\n",
    "    \n",
    "    quantile = p_values_null_coef(intercept)/100\n",
    "    if quantile > 0.5:\n",
    "        p_value_intercept = 1-quantile\n",
    "    else:\n",
    "        p_value_intercept = quantile\n",
    "\n",
    "\n",
    "    p_values_coef = [p_value_intercept]\n",
    "    for i in range(len(columns_feat)):\n",
    "        quantile = p_values_null_coef(coefs[:,i])/100\n",
    "        if quantile > 0.5:\n",
    "            p_values_coef.append(1-quantile)\n",
    "        else:\n",
    "            p_values_coef.append(quantile)\n",
    "    \n",
    "    plt.figure(figsize = (6,9))\n",
    "    plt.errorbar(x = np.append(intercept.mean(),coef.mean().values), y = range(len(columns_feat)+1), xerr = np.append(intercept.std(),coef.std()),ecolor=np.where(np.array(p_values_coef)<0.05,significant_color,non_significant_color), fmt='none')\n",
    "    plt.axvline(x=0,color='black',alpha=0.5)\n",
    "    plt.scatter(x = np.append(intercept.mean(),coef.mean().values), y = range(len(columns_feat)+1),color=np.where(np.array(p_values_coef)<0.05,significant_color,non_significant_color))\n",
    "    plt.yticks(range(len(columns_feat)+1),np.append([\"AF\"],columns_feat), rotation = 'horizontal')\n",
    "    plt.xlabel('Coefficient')\n",
    "    if present:\n",
    "        ax = plt.gca()\n",
    "        ax.patch.set_alpha(0)\n",
    "        leg = ax.legend(handles=legend_elements)\n",
    "        leg.get_frame().set_alpha(0)\n",
    "        for text in leg.get_texts():\n",
    "            text.set_color(\"white\")\n",
    "    else:\n",
    "        plt.legend(handles=legend_elements)\n",
    "    plt.show()\n",
    "    \n",
    "def print_coef_std(coefs, columns_feat,lim):\n",
    "    \"\"\" Plot logistic regression model coefficients \"\"\" \n",
    "    coef = pd.DataFrame(coefs, columns = columns_feat)\n",
    "    #coef = coef.sort_values(by=['Coefficients'], ascending=True)\n",
    "\n",
    "    p_values_coef = []\n",
    "    for i in range(len(columns_feat)):\n",
    "        quantile = p_values_null_coef(coefs[:,i])/100\n",
    "        if quantile > 0.5:\n",
    "            p_values_coef.append(1-quantile)\n",
    "        else:\n",
    "            p_values_coef.append(quantile)\n",
    "    \n",
    "    plt.figure(figsize = (6,9))\n",
    "    plt.errorbar(x = coef.mean().values, y = range(len(columns_feat)), xerr = [coef.mean().values-coef.quantile(0.05),coef.quantile(0.95)-coef.mean().values],ecolor=np.where(np.array(p_values_coef)<0.05,significant_color,non_significant_color), fmt='none')\n",
    "    plt.scatter(x = coef.mean().values, y = range(len(columns_feat)),color=np.where(np.array(p_values_coef)<0.05,significant_color,non_significant_color))\n",
    "    plt.yticks(range(len(columns_feat)),columns_feat, rotation = 'horizontal')\n",
    "    plt.xlabel('Coefficient')\n",
    "    if present:\n",
    "        ax = plt.gca()\n",
    "        ax.patch.set_alpha(0)\n",
    "        leg = ax.legend(handles=legend_elements)\n",
    "        leg.get_frame().set_alpha(0)\n",
    "        for text in leg.get_texts():\n",
    "            text.set_color(\"white\")\n",
    "    else:\n",
    "        plt.legend(handles=legend_elements)\n",
    "    if lim>0:\n",
    "        plt.xlim([-lim,lim])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def p_values_lin_reg(model,X,y):\n",
    "    model.fit(X,y)\n",
    "    sse = np.sum((model.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "    se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
    "\n",
    "    # compute the t-statistic for each feature\n",
    "    t_test_val = model.coef_ / se\n",
    "    # find the p-value for each feature\n",
    "    p_value_lin = np.squeeze(2 * (1 - stat.t.cdf(np.abs(t_test_val), y.shape[0] - X.shape[1])))\n",
    "    return p_value_lin\n",
    "\n",
    "def p_values_null_coef(coefficients):\n",
    "    #inverse of quantile\n",
    "    return stats.percentileofscore(coefficients,0)\n",
    "\n",
    "def p_values_arg_coef(coefficients,arg):\n",
    "    #inverse of quantile\n",
    "    return stats.percentileofscore(coefficients,arg)\n",
    "\n",
    "def epsilon_PEHE(y_1,y_0,ITE):\n",
    "    N = len(y_1)\n",
    "    \n",
    "    return 1/N * np.sum(((y_1-y_0)-(ITE))**2)\n",
    "\n",
    "\n",
    "def epsilon_PEHE(y_1,y_0,ITE):\n",
    "    N = len(y_1)\n",
    "    \n",
    "    return 1/N * np.sum(((y_1-y_0)-(ITE))**2)\n",
    "\n",
    "def normalized_epsilon_PEHE(y_1,y_0,ITE):\n",
    "    N = len(y_1)\n",
    "    \n",
    "    return 1/N * np.sum(((y_1-y_0)-(ITE))**2) * 1/(np.max(np.append(y_1,y_0))-np.min(np.append(y_1,y_0)))\n",
    "\n",
    "def sqrt_epsilon_PEHE(y_1,y_0,ITE):\n",
    "    return np.sqrt(epsilon_PEHE(y_1,y_0,ITE))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.2697515685575829\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.001\n",
      "Intercept = 0.00501330872611238 (+-0.0018478307637112943)\n",
      "-------------------->  0: 0.0\n",
      "-------------------->  1: 0.016\n",
      "-------------------->  2: 0.0\n",
      "-------------------->  3: 0.0\n",
      "-------------------->  4: 0.0\n",
      "5: 0.278\n",
      "-------------------->  6: 0.0\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.019\n",
      "-------------------->  9: 0.0\n",
      "====================================================================================================\n",
      "RUN: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.21145997584114068\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.013539131313076151 (+-0.002062338101954196)\n",
      "-------------------->  0: 0.0\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.016\n",
      "3: 0.18\n",
      "-------------------->  4: 0.0\n",
      "-------------------->  5: 0.0\n",
      "-------------------->  6: 0.038\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.001\n",
      "-------------------->  9: 0.0\n",
      "====================================================================================================\n",
      "RUN: 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.22079644288096575\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = 0.022609551112724335 (+-0.0019616242473080117)\n",
      "0: 0.208\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.0\n",
      "3: 0.394\n",
      "4: 0.298\n",
      "-------------------->  5: 0.0\n",
      "-------------------->  6: 0.011\n",
      "7: 0.116\n",
      "8: 0.21\n",
      "9: 0.329\n",
      "====================================================================================================\n",
      "RUN: 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.11911166447921052\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.0054562219931340895 (+-0.0018893102331023904)\n",
      "-------------------->  0: 0.007\n",
      "1: 0.135\n",
      "-------------------->  2: 0.0\n",
      "3: 0.073\n",
      "-------------------->  4: 0.0\n",
      "-------------------->  5: 0.0\n",
      "-------------------->  6: 0.0\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.0\n",
      "9: 0.141\n",
      "====================================================================================================\n",
      "RUN: 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.2447036857467286\n",
      " Iteration 750/1000\n",
      "TREATMENT: 0.394\n",
      "Intercept = 0.0005135446833951001 (+-0.0021359508692123217)\n",
      "-------------------->  0: 0.001\n",
      "-------------------->  1: 0.0\n",
      "2: 0.406\n",
      "-------------------->  3: 0.0\n",
      "-------------------->  4: 0.0\n",
      "-------------------->  5: 0.0\n",
      "-------------------->  6: 0.0\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.0\n",
      "-------------------->  9: 0.0\n",
      "====================================================================================================\n",
      "RUN: 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.29106915191036264\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.010458453598657465 (+-0.0018647495449249142)\n",
      "-------------------->  0: 0.001\n",
      "1: 0.147\n",
      "-------------------->  2: 0.0\n",
      "3: 0.152\n",
      "-------------------->  4: 0.0\n",
      "-------------------->  5: 0.0\n",
      "-------------------->  6: 0.005\n",
      "-------------------->  7: 0.0\n",
      "8: 0.287\n",
      "-------------------->  9: 0.013\n",
      "====================================================================================================\n",
      "RUN: 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.276486861407492\n",
      " Iteration 750/1000\n",
      "TREATMENT: 0.096\n",
      "Intercept = 0.0022428551665415585 (+-0.001719860708483167)\n",
      "0: 0.066\n",
      "-------------------->  1: 0.016\n",
      "-------------------->  2: 0.018\n",
      "-------------------->  3: 0.037\n",
      "-------------------->  4: 0.032\n",
      "-------------------->  5: 0.028\n",
      "-------------------->  6: 0.006\n",
      "-------------------->  7: 0.035\n",
      "-------------------->  8: 0.002\n",
      "9: 0.077\n",
      "====================================================================================================\n",
      "RUN: 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.322205129294288\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = 0.01123393932434141 (+-0.0017892787419674357)\n",
      "-------------------->  0: 0.0\n",
      "1: 0.095\n",
      "-------------------->  2: 0.037\n",
      "3: 0.329\n",
      "-------------------->  4: 0.0\n",
      "-------------------->  5: 0.0\n",
      "6: 0.251\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.011\n",
      "9: 0.061\n",
      "====================================================================================================\n",
      "RUN: 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.14325416606913133\n",
      " Iteration 750/1000\n",
      "TREATMENT: 0.056\n",
      "Intercept = -0.003116241663235666 (+-0.0019432155872583289)\n",
      "0: 0.088\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.0\n",
      "-------------------->  3: 0.0\n",
      "-------------------->  4: 0.0\n",
      "5: 0.435\n",
      "6: 0.186\n",
      "-------------------->  7: 0.0\n",
      "8: 0.285\n",
      "9: 0.278\n",
      "====================================================================================================\n",
      "RUN: 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.1270571345646948\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = 0.009839762400913546 (+-0.0016996060291469275)\n",
      "-------------------->  0: 0.0\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.0\n",
      "-------------------->  3: 0.0\n",
      "-------------------->  4: 0.0\n",
      "5: 0.085\n",
      "-------------------->  6: 0.035\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.0\n",
      "9: 0.165\n",
      "====================================================================================================\n",
      "RUN: 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.1411533034787451\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.01582581773886172 (+-0.0020810459073481074)\n",
      "-------------------->  0: 0.042\n",
      "1: 0.179\n",
      "2: 0.344\n",
      "-------------------->  3: 0.0\n",
      "4: 0.258\n",
      "-------------------->  5: 0.001\n",
      "-------------------->  6: 0.0\n",
      "-------------------->  7: 0.0\n",
      "8: 0.358\n",
      "9: 0.294\n",
      "====================================================================================================\n",
      "RUN: 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.13763724915300216\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.035\n",
      "Intercept = -0.003223518797998892 (+-0.0018161666133312592)\n",
      "0: 0.131\n",
      "-------------------->  1: 0.003\n",
      "-------------------->  2: 0.006\n",
      "3: 0.069\n",
      "-------------------->  4: 0.009\n",
      "-------------------->  5: 0.013\n",
      "-------------------->  6: 0.0\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.0\n",
      "-------------------->  9: 0.0\n",
      "====================================================================================================\n",
      "RUN: 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.24518026114092611\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = 0.008963439914575846 (+-0.0016575809291905312)\n",
      "0: 0.114\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.044\n",
      "-------------------->  3: 0.0\n",
      "-------------------->  4: 0.0\n",
      "-------------------->  5: 0.0\n",
      "6: 0.158\n",
      "-------------------->  7: 0.0\n",
      "8: 0.373\n",
      "9: 0.358\n",
      "====================================================================================================\n",
      "RUN: 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.14994389679914202\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.01529259638400391 (+-0.0016651691552166334)\n",
      "-------------------->  0: 0.0\n",
      "1: 0.157\n",
      "-------------------->  2: 0.004\n",
      "3: 0.071\n",
      "4: 0.402\n",
      "-------------------->  5: 0.0\n",
      "-------------------->  6: 0.003\n",
      "7: 0.45\n",
      "8: 0.39\n",
      "-------------------->  9: 0.0\n",
      "====================================================================================================\n",
      "RUN: 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.16059722388608738\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.01091317256091861 (+-0.0018254079511466773)\n",
      "-------------------->  0: 0.018\n",
      "-------------------->  1: 0.0\n",
      "2: 0.352\n",
      "3: 0.167\n",
      "-------------------->  4: 0.011\n",
      "-------------------->  5: 0.0\n",
      "6: 0.318\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.001\n",
      "9: 0.226\n",
      "====================================================================================================\n",
      "RUN: 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.22316012250363274\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = 0.01794249483793781 (+-0.0017402437555624317)\n",
      "-------------------->  0: 0.0\n",
      "-------------------->  1: 0.0\n",
      "2: 0.349\n",
      "-------------------->  3: 0.0\n",
      "-------------------->  4: 0.012\n",
      "-------------------->  5: 0.0\n",
      "6: 0.18\n",
      "-------------------->  7: 0.0\n",
      "8: 0.342\n",
      "-------------------->  9: 0.002\n",
      "====================================================================================================\n",
      "RUN: 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.2213392119637699\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.003\n",
      "Intercept = 0.006136128034144911 (+-0.002170769337792788)\n",
      "-------------------->  0: 0.008\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.0\n",
      "3: 0.473\n",
      "-------------------->  4: 0.0\n",
      "-------------------->  5: 0.003\n",
      "-------------------->  6: 0.0\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.0\n",
      "-------------------->  9: 0.0\n",
      "====================================================================================================\n",
      "RUN: 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.2994991896123072\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.019357974125189272 (+-0.001740838317611678)\n",
      "-------------------->  0: 0.011\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.047\n",
      "-------------------->  3: 0.0\n",
      "-------------------->  4: 0.016\n",
      "-------------------->  5: 0.014\n",
      "-------------------->  6: 0.005\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.0\n",
      "-------------------->  9: 0.001\n",
      "====================================================================================================\n",
      "RUN: 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.23473896429620325\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = -0.0165038676463831 (+-0.0017276926449257377)\n",
      "-------------------->  0: 0.006\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.031\n",
      "-------------------->  3: 0.0\n",
      "4: 0.178\n",
      "-------------------->  5: 0.011\n",
      "-------------------->  6: 0.0\n",
      "7: 0.143\n",
      "8: 0.486\n",
      "-------------------->  9: 0.0\n",
      "====================================================================================================\n",
      "RUN: 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PEHE = 0.1613839677905953\n",
      " Iteration 750/1000\n",
      "-------------------->  TREATMENT: 0.0\n",
      "Intercept = 0.011565727623649494 (+-0.001811376014176284)\n",
      "-------------------->  0: 0.0\n",
      "-------------------->  1: 0.0\n",
      "-------------------->  2: 0.0\n",
      "3: 0.275\n",
      "4: 0.062\n",
      "-------------------->  5: 0.036\n",
      "-------------------->  6: 0.0\n",
      "-------------------->  7: 0.0\n",
      "-------------------->  8: 0.016\n",
      "9: 0.081\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "runs = 20\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"RUN: \"+str(i)+\"/\"+str(runs))\n",
    "    samples = 10000\n",
    "    n_features = 10\n",
    "    noise_level = 0.8#0.1\n",
    "\n",
    "    x=np.random.multivariate_normal(np.zeros(n_features),0.5*(np.random.uniform(-1,1,(n_features,n_features))+np.transpose(np.random.uniform(-1,1,(n_features,n_features)))),(samples))\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    treatment_weights = np.random.uniform(-0.1,0.1,(n_features))\n",
    "    treatment_noise = np.random.normal(0,noise_level)\n",
    "    t_cond_x = np.random.binomial(1,sigmoid(np.matmul(x,treatment_weights)+treatment_noise))\n",
    "\n",
    "    outcome_weights = np.random.uniform(-1,1,(n_features,2))\n",
    "    outcome_noise = np.random.multivariate_normal(np.zeros(2),[[noise_level,0],[0,noise_level]],(samples))\n",
    "    Y_cond_x = sigmoid(np.matmul(x,outcome_weights)+outcome_noise)\n",
    "    Y_cond_x_labels = np.round(Y_cond_x)\n",
    "\n",
    "    Y_treatment_outcomes = Y_cond_x_labels[:,0]#np.take(Y_cond_x_labels.flatten(),t_cond_x+2*np.arange(0,len(t_cond_x)))\n",
    "\n",
    "    T0_idx_train,T0_idx_test = train_test_split(np.arange(0,samples)[t_cond_x==0],test_size=0.2)\n",
    "    T1_idx_train,T1_idx_test = train_test_split(np.arange(0,samples)[t_cond_x==1],test_size=0.2)\n",
    "\n",
    "    T0_X_train =  x[T0_idx_train]\n",
    "    T0_X_test =  x[T0_idx_test]\n",
    "    T0_y_train =  Y_treatment_outcomes[T0_idx_train]\n",
    "    T0_y_test = Y_treatment_outcomes[T0_idx_test]\n",
    "    T1_X_train = x[T1_idx_train]\n",
    "    T1_X_test = x[T1_idx_test]\n",
    "    T1_y_train = Y_treatment_outcomes[T1_idx_train]\n",
    "    T1_y_test  = Y_treatment_outcomes[T1_idx_test]\n",
    "\n",
    "    C_X_train = np.vstack((np.hstack((T0_X_train,np.zeros((len(T0_X_train),1)))),np.hstack((T1_X_train,np.zeros((len(T1_X_train),1))+1))))\n",
    "    C_X_test_separate = np.vstack((T0_X_test,T1_X_test))\n",
    "    C_X_test_T0 = np.hstack((C_X_test_separate,np.zeros((len(C_X_test_separate),1))))\n",
    "    C_X_test_T1 = np.hstack((C_X_test_separate,np.zeros((len(C_X_test_separate),1))+1))\n",
    "    C_y_train = np.append(T0_y_train,T1_y_train)\n",
    "    C_y_test = np.append(T0_y_test,T1_y_test)\n",
    "\n",
    "    T0_class_balance = [T0_y_train.sum()/len(T0_y_train),1-T0_y_train.sum()/len(T0_y_train)]\n",
    "    T0_CB_model = CatBoostClassifier(verbose=False,iterations=250,class_weights=T0_class_balance)\n",
    "    T0_CB_model.fit(Pool(T0_X_train,T0_y_train))\n",
    "\n",
    "    T1_class_balance = [T1_y_train.sum()/len(T1_y_train),1-T1_y_train.sum()/len(T1_y_train)]\n",
    "    T1_CB_model = CatBoostClassifier(verbose=False,iterations=250,class_weights=T1_class_balance)\n",
    "    T1_CB_model.fit(Pool(T1_X_train,T1_y_train))\n",
    "\n",
    "    #C_class_balance = [C_y_train.sum()/len(C_y_train),1-C_y_train.sum()/len(C_y_train)]\n",
    "    #C_CB_model = CatBoostClassifier(verbose=False,iterations=250,class_weights=C_class_balance)\n",
    "    #C_CB_model.fit(Pool(C_X_train,C_y_train))\n",
    "\n",
    "    ITE = T1_CB_model.predict_proba(C_X_test_separate)[:,1]-T0_CB_model.predict_proba(C_X_test_separate)[:,1]\n",
    "    #combo_ITE = C_CB_model.predict_proba(C_X_test_T1)[:,1]-C_CB_model.predict_proba(C_X_test_T0)[:,1]\n",
    "\n",
    "    label_ITE = ITE\n",
    "\n",
    "    X_lin_analysis = pd.DataFrame(C_X_test_separate)\n",
    "\n",
    "    print(\"E PEHE = \"+str(epsilon_PEHE(Y_cond_x[np.append(T0_idx_test,T1_idx_test),1],Y_cond_x[np.append(T0_idx_test,T1_idx_test),0],label_ITE)))\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "    intercept = []\n",
    "    r2s = []\n",
    "    coefs = np.array([])\n",
    "    loops = 1000\n",
    "    for i in range(loops):#(1000):\n",
    "        if i%250==0:\n",
    "            print(\"\\r Iteration \"+str(i)+\"/\"+str(loops),end='')\n",
    "        train_X_LinReg = X_lin_analysis.reset_index(drop=True).sample(int(len(X_lin_analysis)*0.67),random_state=i)\n",
    "        train_Y_LinReg = label_ITE[train_X_LinReg.index.values]\n",
    "        Lin_ITE = LinearRegression().fit(train_X_LinReg.values,train_Y_LinReg)\n",
    "        #r2s.append(r2_score(ITE,Lin_ITE.predict(X_test_ITE_lin_reg.values)))\n",
    "        intercept.append(Lin_ITE.intercept_)\n",
    "        if len(coefs)==0:\n",
    "            coefs = Lin_ITE.coef_\n",
    "        else:\n",
    "            coefs = np.vstack([coefs,Lin_ITE.coef_])\n",
    "    intercept = np.array(intercept)        \n",
    "\n",
    "    print(\"\")\n",
    "    quantile = p_values_null_coef(intercept)/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "    significant_string = \"\" if (np.round(p_value,3)>0.05) else 20*\"-\"+\">  \" \n",
    "    print(significant_string+\"TREATMENT: \"+str(np.round(p_value,3)))\n",
    "    print(\"Intercept = \"+str(np.mean(intercept))+\" (+-\"+str(np.std(intercept))+\")\")\n",
    "\n",
    "    for i in range(len(X_lin_analysis.columns)):\n",
    "        quantile = p_values_null_coef(coefs[:,i])/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "        significant_string = \"\" if (np.round(p_value,3)>0.05) else 20*\"-\"+\">  \"\n",
    "        print(significant_string+str(X_lin_analysis.columns[i])+\": \"+str(np.round(p_value,3)))\n",
    "    print(100*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_bool = False\n",
    "if print_bool:\n",
    "    print(\"\")\n",
    "    print(\"T0 TRAIN\")\n",
    "    print(classification_report(T0_y_train,T0_CB_model.predict(T0_X_train)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T0_CB_model, Pool(data=T0_X_train,label=T0_y_train), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T0_y_train,T0_CB_model.predict(T0_X_train)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "\n",
    "    print(\"T1 TRAIN\")\n",
    "    print(classification_report(T1_y_train,T1_CB_model.predict(T1_X_train)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T1_CB_model, Pool(data=T1_X_train,label=T1_y_train), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T1_y_train,T1_CB_model.predict(T1_X_train)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    print(\"COMBO TRAIN\")\n",
    "    print(classification_report(C_y_train,C_CB_model.predict(C_X_train)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(C_CB_model, Pool(data=C_X_train,label=C_y_train), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(C_y_train,C_CB_model.predict(C_X_train)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    print(\"T0 TEST\")\n",
    "    print(classification_report(T0_y_test,T0_CB_model.predict(T0_X_test)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T0_CB_model, Pool(data=T0_X_test,label=T0_y_test), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T0_y_test,T0_CB_model.predict(T0_X_test)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    print(\"T1 TEST\")\n",
    "    print(classification_report(T1_y_test,T1_CB_model.predict(T1_X_test)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T1_CB_model, Pool(data=T1_X_test,label=T1_y_test), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T1_y_test,T1_CB_model.predict(T1_X_test)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    C_X_test_sep_T0 = np.hstack((T0_X_test,np.zeros((len(T0_X_test),1))))\n",
    "    print(\"COMBO TEST T0\")\n",
    "    print(classification_report(T0_y_test,C_CB_model.predict(C_X_test_sep_T0)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(C_CB_model, Pool(data=C_X_test_sep_T0,label=T0_y_test), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T0_y_test,C_CB_model.predict(C_X_test_sep_T0)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    C_X_test_sep_T1 = np.hstack((T1_X_test,np.zeros((len(T1_X_test),1))+1))\n",
    "    print(\"COMBO TEST T1\")\n",
    "    print(classification_report(T1_y_test,C_CB_model.predict(C_X_test_sep_T1)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(C_CB_model, Pool(data=C_X_test_sep_T1,label=T1_y_test), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T1_y_test,C_CB_model.predict(C_X_test_sep_T1)),4)))\n",
    "    print(50*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWINS DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The covariates data has 46 features\n",
    "x = pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/TWINS/twin_pairs_X_3years_samesex.csv\")\n",
    "\n",
    "#The outcome data contains mortality of the lighter and heavier twin\n",
    "y = pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/TWINS/twin_pairs_Y_3years_samesex.csv\")\n",
    "\n",
    "#The treatment data contains weight in grams of both the twins\n",
    "t = pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/TWINS/twin_pairs_T_3years_samesex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MORT 1 : 0.1635940873609035\n",
      "MEAN MORT 0 : 0.18875602059458563\n",
      "ATE -0.025161933233682127\n",
      "ITE STD 0.319516317500626\n",
      "Treatment selection of T1: 0.49750871948181363\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#_0 denotes features specific to the lighter twin and _1 denotes features specific to the heavier twin\n",
    "lighter_columns = ['pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "        'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "        'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "        'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "        'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "        'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "        'data_year', 'nprevistq', 'dfageq', 'feduc6', #'infant_id_0',\n",
    "        'dlivord_min', 'dtotord_min', 'bord_0','random_uniform_feature',\n",
    "        'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']\n",
    "heavier_columns = [ 'pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "        'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "        'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "        'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "        'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "        'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "        'data_year', 'nprevistq', 'dfageq', 'feduc6',#'infant_id_1', \n",
    "        'dlivord_min', 'dtotord_min', 'bord_1','random_uniform_feature',\n",
    "        'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']\n",
    "\n",
    "#heavier_columns = ['gestat10', 'nprevistq', 'csex', 'hydra','random_uniform_feature']\n",
    "#lighter_columns = ['gestat10', 'nprevistq', 'csex', 'hydra','random_uniform_feature']\n",
    "\n",
    "Exclude_features = [\"infant_id_1\",\"infant_id_0\",\"\"]\n",
    "\n",
    "x.columns\n",
    "x = x[['pldel', 'birattnd', 'brstate',\n",
    "       'stoccfipb', 'mager8', 'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir',\n",
    "       'mpre5', 'adequacy', 'orfath', 'frace', 'birmon', 'gestat10', 'csex',\n",
    "       'anemia', 'cardiac', 'lung', 'diabetes', 'herpes', 'hydra', 'hemo',\n",
    "       'chyper', 'phyper', 'eclamp', 'incervix', 'pre4000', 'preterm', 'renal',\n",
    "       'rh', 'uterine', 'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5',\n",
    "       'crace', 'data_year', 'nprevistq', 'dfageq', 'feduc6', 'infant_id_0',\n",
    "       'infant_id_1', 'dlivord_min', 'dtotord_min', 'bord_0', 'bord_1',\n",
    "       'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']]\n",
    "dataset = x.copy(deep=True)\n",
    "dataset[\"mort_0\"]=y.mort_0\n",
    "dataset[\"mort_1\"]=y.mort_1\n",
    "dataset[\"dbirwt_0\"]=t.dbirwt_0\n",
    "dataset[\"dbirwt_1\"]=t.dbirwt_1\n",
    "\n",
    "#select only if both <=2kg\n",
    "dataset = dataset[(dataset.dbirwt_0<=2000) & (dataset.dbirwt_1<=2000)]\n",
    "dataset[\"lightest_baby\"]=0\n",
    "dataset.loc[dataset.dbirwt_0>dataset.dbirwt_1,\"lightest_baby\"]=1\n",
    "\n",
    "print(\"MEAN MORT 1 : \"+str(np.mean(dataset[\"mort_1\"])))\n",
    "print(\"MEAN MORT 0 : \"+str(np.mean(dataset[\"mort_0\"])))\n",
    "print(\"ATE\", np.mean(dataset[\"mort_1\"])- np.mean(dataset[\"mort_0\"]))\n",
    "print(\"ITE STD\", np.std(dataset[\"mort_1\"]- dataset[\"mort_0\"]))\n",
    "plt.hist(dataset[\"mort_1\"]-dataset[\"mort_0\"])\n",
    "plt.title(\"ITE\")\n",
    "\n",
    "if not selection_bias:\n",
    "    treatment_observation_arr = np.random.randint(0,2,len(dataset))\n",
    "else:\n",
    "    #ADD SELECTION BIAS\n",
    "    noise_level = 0.1\n",
    "    feat = ['pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "           'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "           'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "           'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "           'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "           'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "           'data_year', 'nprevistq', 'dfageq', 'feduc6',\n",
    "           'dlivord_min', 'dtotord_min',\n",
    "           'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']\n",
    "    n_features = len(feat)\n",
    "    treatment_weights = np.random.uniform(-0.1,0.1,(n_features))\n",
    "    treatment_noise = 0#np.random.normal(0,noise_level)\n",
    "    treatment_observation_arr = np.random.binomial(1,sigmoid(np.matmul(dataset[feat].fillna(0).values,treatment_weights)+treatment_noise))  \n",
    "    \n",
    "dataset[\"treatment\"]=treatment_observation_arr\n",
    "dataset[\"random_uniform_feature\"] = np.random.uniform(-1,1,(len(dataset)))\n",
    "print(\"Treatment selection of T1: \"+str(sum(treatment_observation_arr)/len(treatment_observation_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900\n",
      "-0.025135132890365453\n"
     ]
    }
   ],
   "source": [
    "ATEs = []\n",
    "for i in range(10000):\n",
    "    if i%100==0:\n",
    "        print(\"\\r\"+str(i),end=\"\")\n",
    "    sampled_dataset = dataset.sample(int(0.2*len(dataset)),replace=False,random_state=i)\n",
    "    ATEs.append(np.mean(sampled_dataset[\"mort_1\"])- np.mean(sampled_dataset[\"mort_0\"]))\n",
    "\n",
    "print(\"\")\n",
    "print(np.mean(np.array(ATEs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"mort\"] = 0\n",
    "dataset.loc[dataset.treatment==1,\"mort\"] = dataset[dataset.treatment==1].mort_1\n",
    "dataset.loc[dataset.treatment==0,\"mort\"] = dataset[dataset.treatment==0].mort_0\n",
    "\n",
    "dataset[\"bord\"] = 0\n",
    "dataset.loc[dataset.treatment==1,\"bord\"] = dataset[dataset.treatment==1].bord_1\n",
    "dataset.loc[dataset.treatment==0,\"bord\"] = dataset[dataset.treatment==0].bord_0\n",
    "\n",
    "dataset[\"infant_id\"] = 0\n",
    "dataset.loc[dataset.treatment==1,\"infant_id\"] = dataset[dataset.treatment==1].infant_id_1\n",
    "dataset.loc[dataset.treatment==0,\"infant_id\"] = dataset[dataset.treatment==0].infant_id_0\n",
    "\n",
    "dataset[\"dbirwt\"] = 0\n",
    "dataset.loc[dataset.treatment==1,\"dbirwt\"] = dataset[dataset.treatment==1].dbirwt_1\n",
    "dataset.loc[dataset.treatment==0,\"dbirwt\"] = dataset[dataset.treatment==0].dbirwt_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['pldel', 'birattnd', 'brstate',\n",
    "       'stoccfipb', 'mager8', 'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir',\n",
    "       'mpre5', 'adequacy', 'orfath', 'frace', 'birmon', 'gestat10', 'csex',\n",
    "       'anemia', 'cardiac', 'lung', 'diabetes', 'herpes', 'hydra', 'hemo',\n",
    "       'chyper', 'phyper', 'eclamp', 'incervix', 'pre4000', 'preterm', 'renal',\n",
    "       'rh', 'uterine', 'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5',\n",
    "       'crace', 'data_year', 'nprevistq', 'dfageq', 'feduc6', 'dlivord_min', 'dtotord_min', 'bord',\n",
    "       'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.106287\n",
      "0:\tlearn: 0.6926568\ttotal: 5.07ms\tremaining: 1.26s\n",
      "100:\tlearn: 0.6536262\ttotal: 360ms\tremaining: 531ms\n",
      "200:\tlearn: 0.6105526\ttotal: 727ms\tremaining: 177ms\n",
      "249:\tlearn: 0.5924484\ttotal: 910ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diff   -0.022039\n",
       "dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causallib.estimation import IPW \n",
    "\n",
    "ipw = IPW(CatBoostClassifier(n_estimators=250,verbose=100))\n",
    "ipw.fit(dataset[columns_list], dataset[\"treatment\"])\n",
    "potential_outcomes = ipw.estimate_population_outcome(dataset[columns_list], dataset[\"treatment\"], dataset[\"mort\"])\n",
    "effect = ipw.estimate_effect(potential_outcomes[1], potential_outcomes[0])\n",
    "effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../causalteshap/\")\n",
    "from causalteshap import CausalTeShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900\n",
      "-0.02513615608136156\n"
     ]
    }
   ],
   "source": [
    "ATEs = []\n",
    "for i in range(10000):\n",
    "    if i%100==0:\n",
    "        print(\"\\r\"+str(i),end=\"\")\n",
    "    d_temp = dataset.reset_index(drop=True)\n",
    "\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        np.arange(len(d_temp)),\n",
    "        test_size=0.2,\n",
    "        random_state=i,\n",
    "    )\n",
    "\n",
    "    ATEs.append(np.mean(d_temp.iloc[np.sort(val_idx)].mort_1.values-d_temp.iloc[np.sort(val_idx)].mort_0.values))\n",
    "\n",
    "print(\"\")\n",
    "print(np.mean(np.array(ATEs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_X, prev_auc,after_auc = causal_selector.propensity_matching(\n",
    "    dataset[columns_list],\n",
    "                    dataset.mort.values,dataset[\"treatment\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020298317712979963"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_dataset = dataset.iloc[matched_X]\n",
    "\n",
    "np.mean(np.mean(match_dataset[match_dataset[\"treatment\"]==1].mort.values)-np.mean(match_dataset[match_dataset[\"treatment\"]==0].mort.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801c934461e74dcd8ef53f1d23413d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.018480018480018484\n",
      "-0.018767377201112156\n",
      "-0.01824059108750864\n",
      "-0.03014018691588785\n",
      "-0.02251624883936862\n",
      "-0.020369936782954817\n",
      "-0.017400721756553467\n",
      "-0.02034211742949607\n",
      "-0.020847810979847115\n",
      "-0.017923001224815327\n",
      "\n",
      "Done\n",
      "Propensity matching was included in fitting - Propensity information: \n",
      "\n",
      "Before matching auc \t | mean (std) = 0.5015 (0.0068)\n",
      "After matching auc \t | mean (std) = 0.5015 (0.0056)\n",
      "T0 amount of class 1 samples \t |  807 samples = 18.71% of all matched 4314 samples\n",
      "T1 amount of class 1 samples \t | 718 samples = 16.66% of all matched 4315 samples\n",
      "\n",
      "Causality information:\n",
      "TRAIN: \t CATE = -0.0322212793955799 \t| p-value = 0.0\n",
      "VAL: \t CATE = -0.03286403184308402 \t| p-value = 0.0\n",
      "============================================================\n",
      "CATE shap stats\n",
      "----------------------------------------------------------------------\n",
      "|             |       impact |   p_value |\n",
      "|:------------|-------------:|----------:|\n",
      "| T           | -0.250699    |         0 |\n",
      "| csex        |  0.0202758   |         0 |\n",
      "| gestat10    |  0.0141057   |         0 |\n",
      "| data_year   | -0.00848034  |         0 |\n",
      "| meduc6      | -0.00625929  |         0 |\n",
      "| bord        | -0.00188409  |         0 |\n",
      "| mrace       | -0.00185499  |         0 |\n",
      "| dtotord_min | -0.00131006  |         0 |\n",
      "| orfath      | -0.00106066  |         0 |\n",
      "| mplbir      | -0.00104554  |         0 |\n",
      "| feduc6      | -0.00102691  |         0 |\n",
      "| rh          | -0.00102474  |         0 |\n",
      "| crace       |  0.000755013 |         0 |\n",
      "| drink5      | -0.000457878 |         0 |\n",
      "| birattnd    | -0.00039021  |         0 |\n",
      "| anemia      | -0.000340585 |         0 |\n",
      "| incervix    |  0.000312528 |         0 |\n",
      "| othermr     | -0.00024565  |         0 |\n",
      "| tobacco     |  0.000218558 |         0 |\n",
      "| phyper      |  0.000217472 |         0 |\n",
      "| alcohol     |  0.000148322 |         0 |\n",
      "| renal       |  0.000118064 |         0 |\n",
      "| diabetes    |  6.91633e-05 |         0 |\n",
      "| herpes      | -2.99706e-05 |         0 |\n",
      "| pre4000     | -2.75662e-05 |         0 |\n",
      "| chyper      | -1.75588e-05 |         0 |\n",
      "| cardiac     |  1.63518e-05 |         0 |\n",
      "| pldel       |  1.52896e-05 |         0 |\n",
      "| ormoth      |  1.37047e-05 |         0 |\n",
      "| hemo        | -1.17554e-05 |         0 |\n",
      "| lung        |  7.3124e-06  |         0 |\n",
      "| uterine     |  2.13377e-06 |         0 |\n",
      "======================================================================\n",
      "T0 shap stats\n",
      "----------------------------------------------------------------------\n",
      "|           |   impact |   p_value |\n",
      "|:----------|---------:|----------:|\n",
      "| gestat10  | 1.5126   |         0 |\n",
      "| nprevistq | 0.264424 |         0 |\n",
      "| csex      | 0.184707 |         0 |\n",
      "======================================================================\n",
      "T1 shap stats\n",
      "----------------------------------------------------------------------\n",
      "|           |   impact |   p_value |\n",
      "|:----------|---------:|----------:|\n",
      "| gestat10  | 1.54049  |         0 |\n",
      "| nprevistq | 0.283835 |         0 |\n",
      "| csex      | 0.207692 |         0 |\n",
      "| T         | 0.144349 |         0 |\n",
      "======================================================================\n",
      "\n",
      "All predictive variables = \n",
      " \t \t['T', 'csex', 'gestat10', 'data_year', 'meduc6', 'bord', 'mrace', 'dtotord_min', 'orfath', 'mplbir', 'feduc6', 'rh', 'crace', 'drink5', 'birattnd', 'anemia', 'incervix', 'othermr', 'tobacco', 'phyper', 'alcohol', 'renal', 'diabetes', 'herpes', 'pre4000', 'chyper', 'cardiac', 'pldel', 'ormoth', 'hemo', 'lung', 'uterine']\n",
      "All prognostic variables = \n",
      " \t \t['csex', 'gestat10', 'nprevistq']\n",
      " (Beware, S-learner is True, look at the impact to really discern between prognostic and predictive or only prognostic for variables that are both in the predictive and prognostic set)\n"
     ]
    }
   ],
   "source": [
    "causal_selector = CausalTeShap(CatBoostClassifier,iterations=10,S_learner=True,power_alpha=0.01,verbose=True,classification=True)\n",
    "\n",
    "causal_selector.fit(dataset[columns_list],\n",
    "                    dataset.mort.values,dataset[\"treatment\"].values,propensity_matching=True)\n",
    "\n",
    "causal_selector.show_all_causality_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear analysis on the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nan_features = False\n",
    "lin_anal_loops = 1000\n",
    "samples = 5000\n",
    "\n",
    "dataset_linal = dataset.sample(samples)\n",
    "linal_treatment_observation_arr = np.random.randint(0,2,len(dataset_linal))\n",
    "\n",
    "X_lin_analysis = dataset_linal[linal_treatment_observation_arr==0][lighter_columns].rename(columns={'infant_id_0':'infant_id',  'bord_0':'bord'})\n",
    "X_lin_analysis = X_lin_analysis.append(dataset_linal[linal_treatment_observation_arr==1][heavier_columns].rename(columns={'infant_id_1':'infant_id',  'bord_1':'bord'}))\n",
    "label_ITE = dataset_linal[linal_treatment_observation_arr==0].mort_1.values - dataset_linal[linal_treatment_observation_arr==0].mort_0.values\n",
    "label_ITE = np.append(label_ITE,dataset_linal[linal_treatment_observation_arr==1].mort_1.values - dataset_linal[linal_treatment_observation_arr==1].mort_0.values)\n",
    "print(np.mean(label_ITE))\n",
    "\n",
    "if add_nan_features:\n",
    "    possible_NaN_features = ['pldel', 'birattnd', 'ormoth',  'meduc6', 'mplbir',\n",
    "    'mpre5', 'adequacy', 'orfath', 'frace', \n",
    "    'anemia', 'cardiac', 'lung', 'diabetes', 'herpes', 'hydra', 'hemo',\n",
    "    'chyper', 'phyper', 'eclamp', 'incervix', 'pre4000', 'preterm', 'renal',\n",
    "    'rh', 'uterine', 'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5',\n",
    "    'nprevistq', 'dfageq', 'feduc6',  'dlivord_min', 'dtotord_min', 'bord', \n",
    "    'mplbir_reg']\n",
    "\n",
    "    for feat in possible_NaN_features:\n",
    "        X_lin_analysis[feat+\"_NaN\"]=0\n",
    "        X_lin_analysis.loc[X_lin_analysis[feat].isna(),feat+\"_NaN\"]=1\n",
    "\n",
    "X_lin_analysis = X_lin_analysis.fillna(X_lin_analysis.mean())\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "intercept = []\n",
    "r2s = []\n",
    "coefs = np.array([])\n",
    "for i in range(lin_anal_loops):#(1000):\n",
    "    if i%250==0:\n",
    "        print(\"\\r Iteration \"+str(i)+\"/\"+str(lin_anal_loops),end='')\n",
    "    train_X_LinReg = X_lin_analysis.reset_index(drop=True).sample(int(len(X_lin_analysis)*0.67),random_state=i)\n",
    "    train_Y_LinReg = label_ITE[train_X_LinReg.index.values]\n",
    "    Lin_ITE = LinearRegression().fit(train_X_LinReg.values,train_Y_LinReg)\n",
    "    #r2s.append(r2_score(ITE,Lin_ITE.predict(X_test_ITE_lin_reg.values)))\n",
    "    intercept.append(Lin_ITE.intercept_)\n",
    "    if len(coefs)==0:\n",
    "        coefs = Lin_ITE.coef_\n",
    "    else:\n",
    "        coefs = np.vstack([coefs,Lin_ITE.coef_])\n",
    "intercept = np.array(intercept)        \n",
    "\n",
    "print(\"\")\n",
    "quantile = p_values_null_coef(intercept)/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "significant_string = \"\" if (np.round(p_value,3)>0.05) else 20*\"-\"+\">  \" \n",
    "print(significant_string+\"TREATMENT: \"+str(np.round(p_value,3)))\n",
    "print(\"Intercept = \"+str(np.mean(intercept))+\" (+-\"+str(np.std(intercept))+\")\")\n",
    "\n",
    "for i in range(len(X_lin_analysis.columns)):\n",
    "    quantile = p_values_null_coef(coefs[:,i])/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "    significant_string = \"\" if (np.round(p_value,3)>0.05) else 20*\"-\"+\">  \"\n",
    "    print(significant_string+str(X_lin_analysis.columns[i])+\": \"+str(np.round(p_value,3)))\n",
    "print(100*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Analysis on Catboost ITE estimation (both shared and separate response surfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nan_features = False\n",
    "verbose_bool = False\n",
    "do_lin_al = True\n",
    "combo = False\n",
    "pehes = []\n",
    "ITEs = []\n",
    "runs = 10\n",
    "lin_anal_loops = 1000\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"\\r run \"+str(i)+\"/\"+str(runs),end=\"\")\n",
    "    #samples = 10000\n",
    "    #n_features = 10\n",
    "    #noise_level = 0.8#0.1\n",
    "\n",
    "    #treatment_weights = np.random.uniform(-0.1,0.1,(n_features))\n",
    "    #treatment_noise = np.random.normal(0,noise_level)\n",
    "    #t_cond_x = np.random.binomial(1,sigmoid(np.matmul(x,treatment_weights)+treatment_noise))\n",
    "\n",
    "    T0_train_dataset,T0_test_dataset = train_test_split(dataset[treatment_observation_arr==0],test_size=0.2,random_state=i)\n",
    "    T0_train_dataset,T0_val_dataset = train_test_split(T0_train_dataset,test_size=0.3,random_state=42)\n",
    "\n",
    "    T1_train_dataset,T1_test_dataset = train_test_split(dataset[treatment_observation_arr==1],test_size=0.2,random_state=i)\n",
    "    T1_train_dataset,T1_val_dataset = train_test_split(T1_train_dataset,test_size=0.3,random_state=42)\n",
    "\n",
    "    T0_X_train =  T0_train_dataset[lighter_columns]\n",
    "    T0_X_val =  T0_val_dataset[lighter_columns]\n",
    "    T0_X_test =  T0_test_dataset[lighter_columns]\n",
    "    T0_X_train = T0_X_train.rename(columns={'infant_id_0':'infant_id',  'bord_0':'bord'})\n",
    "    T0_X_val = T0_X_val.rename(columns={'infant_id_0':'infant_id',  'bord_0':'bord'})\n",
    "    T0_X_test = T0_X_test.rename(columns={'infant_id_0':'infant_id',  'bord_0':'bord'})\n",
    "\n",
    "    T0_y_train =  T0_train_dataset[\"mort_0\"]\n",
    "    T0_y_val =  T0_val_dataset[\"mort_0\"]\n",
    "    T0_y_test = T0_test_dataset[\"mort_0\"]\n",
    "\n",
    "    T1_X_train = T1_train_dataset[heavier_columns]\n",
    "    T1_X_val = T1_val_dataset[heavier_columns]\n",
    "    T1_X_test = T1_test_dataset[heavier_columns]\n",
    "    T1_X_train = T1_X_train.rename(columns={'infant_id_1':'infant_id',  'bord_1':'bord'})\n",
    "    T1_X_val = T1_X_val.rename(columns={'infant_id_1':'infant_id',  'bord_1':'bord'})\n",
    "    T1_X_test = T1_X_test.rename(columns={'infant_id_1':'infant_id',  'bord_1':'bord'})\n",
    "\n",
    "    T1_y_train = T1_train_dataset[\"mort_1\"]\n",
    "    T1_y_val = T1_val_dataset[\"mort_1\"]\n",
    "    T1_y_test  = T1_test_dataset[\"mort_1\"]\n",
    "    \n",
    "    X_test_separate = np.vstack((T0_X_test,T1_X_test))\n",
    "    \n",
    "    if combo:\n",
    "        C_X_train = np.vstack((np.hstack((T0_X_train,np.zeros((len(T0_X_train),1)))),np.hstack((T1_X_train,np.zeros((len(T1_X_train),1))+1))))\n",
    "        C_X_val = np.vstack((np.hstack((T0_X_val,np.zeros((len(T0_X_val),1)))),np.hstack((T1_X_val,np.zeros((len(T1_X_val),1))+1))))\n",
    "        C_X_test_T0 = np.hstack((X_test_separate,np.zeros((len(X_test_separate),1))))\n",
    "        C_X_test_T1 = np.hstack((X_test_separate,np.zeros((len(X_test_separate),1))+1))\n",
    "        C_y_train = np.append(T0_y_train,T1_y_train)\n",
    "        C_y_val = np.append(T0_y_val,T1_y_val)\n",
    "        C_y_test = np.append(T0_y_test,T1_y_test)\n",
    "\n",
    "    if not combo:\n",
    "        T0_class_balance = [T0_y_train.sum()/len(T0_y_train),1-T0_y_train.sum()/len(T0_y_train)]\n",
    "        T0_CB_model = CatBoostClassifier(verbose=verbose_bool,iterations=100,class_weights=T0_class_balance,use_best_model=True)\n",
    "        T0_CB_model.fit(Pool(T0_X_train,T0_y_train),eval_set=(T0_X_val,T0_y_val))\n",
    "\n",
    "        T1_class_balance = [T1_y_train.sum()/len(T1_y_train),1-T1_y_train.sum()/len(T1_y_train)]\n",
    "        T1_CB_model = CatBoostClassifier(verbose=verbose_bool,iterations=100,class_weights=T1_class_balance,use_best_model=True)\n",
    "        T1_CB_model.fit(Pool(T1_X_train,T1_y_train),eval_set=(T1_X_val,T1_y_val))\n",
    "        \n",
    "        label_ITE = T1_CB_model.predict_proba(X_test_separate)[:,1]-T0_CB_model.predict_proba(X_test_separate)[:,1]\n",
    "\n",
    "    else:\n",
    "        C_class_balance = [C_y_train.sum()/len(C_y_train),1-C_y_train.sum()/len(C_y_train)]\n",
    "        C_CB_model = CatBoostClassifier(verbose=verbose_bool,iterations=100,class_weights=C_class_balance,use_best_model=True)\n",
    "        C_CB_model.fit(Pool(C_X_train,C_y_train),eval_set=(C_X_val,C_y_val))\n",
    "        \n",
    "        label_ITE = C_CB_model.predict_proba(C_X_test_T1)[:,1]-C_CB_model.predict_proba(C_X_test_T0)[:,1]\n",
    "\n",
    "    print(\"\")\n",
    "    print(np.mean(label_ITE))\n",
    "    pehes_temp = sqrt_epsilon_PEHE(np.append(T0_test_dataset[\"mort_1\"],T1_test_dataset[\"mort_1\"]),np.append(T0_test_dataset[\"mort_0\"],T1_test_dataset[\"mort_0\"]),label_ITE)\n",
    "    pehes.append(pehes_temp)\n",
    "    #print(\"SQRT(E_PEHE) = \"+str(pehes_temp))\n",
    "\n",
    "    if do_lin_al:\n",
    "        possible_NaN_features = ['pldel', 'birattnd', 'ormoth',  'meduc6', 'mplbir',\n",
    "           'mpre5', 'adequacy', 'orfath', 'frace', \n",
    "           'anemia', 'cardiac', 'lung', 'diabetes', 'herpes', 'hydra', 'hemo',\n",
    "           'chyper', 'phyper', 'eclamp', 'incervix', 'pre4000', 'preterm', 'renal',\n",
    "           'rh', 'uterine', 'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5',\n",
    "            'nprevistq', 'dfageq', 'feduc6',  'dlivord_min', 'dtotord_min', 'bord', \n",
    "            'mplbir_reg']\n",
    "\n",
    "        X_train_T1_lin_reg = T1_X_train.copy(deep=True)\n",
    "        X_test_T1_lin_reg = T1_X_test.copy(deep=True)\n",
    "        X_train_T0_lin_reg = T0_X_train.copy(deep=True)\n",
    "        X_test_T0_lin_reg = T0_X_test.copy(deep=True)\n",
    "\n",
    "        if add_nan_features:\n",
    "            for feat in possible_NaN_features:\n",
    "                X_train_T1_lin_reg[feat+\"_NaN\"]=0\n",
    "                X_train_T1_lin_reg.loc[X_train_T1_lin_reg[feat].isna(),feat+\"_NaN\"]=1\n",
    "\n",
    "                X_test_T1_lin_reg[feat+\"_NaN\"]=0\n",
    "                X_test_T1_lin_reg.loc[X_test_T1_lin_reg[feat].isna(),feat+\"_NaN\"]=1\n",
    "\n",
    "                X_train_T0_lin_reg[feat+\"_NaN\"]=0\n",
    "                X_train_T0_lin_reg.loc[X_train_T0_lin_reg[feat].isna(),feat+\"_NaN\"]=1\n",
    "\n",
    "                X_test_T0_lin_reg[feat+\"_NaN\"]=0\n",
    "                X_test_T0_lin_reg.loc[X_test_T0_lin_reg[feat].isna(),feat+\"_NaN\"]=1\n",
    "\n",
    "\n",
    "        X_train_T1_lin_reg = X_train_T1_lin_reg.fillna(0)\n",
    "        X_test_T1_lin_reg = X_test_T1_lin_reg.fillna(0)\n",
    "        X_train_T0_lin_reg = X_train_T0_lin_reg.fillna(0)\n",
    "        X_test_T0_lin_reg = X_test_T0_lin_reg.fillna(0)  \n",
    "\n",
    "        X_lin_analysis = X_test_T1_lin_reg.append(X_test_T0_lin_reg).sample(len(X_test_T1_lin_reg)+len(X_test_T0_lin_reg),random_state=42)\n",
    "\n",
    "        #X_lin_analysis = pd.DataFrame(C_X_test_separate)\n",
    "\n",
    "\n",
    "        from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "        intercept = []\n",
    "        r2s = []\n",
    "        coefs = np.array([])\n",
    "        for i in range(lin_anal_loops):#(1000):\n",
    "            if i%250==0:\n",
    "                print(\"\\r Iteration \"+str(i)+\"/\"+str(lin_anal_loops),end='')\n",
    "            train_X_LinReg = X_lin_analysis.reset_index(drop=True).sample(int(len(X_lin_analysis)*0.67),random_state=i)\n",
    "            train_Y_LinReg = label_ITE[train_X_LinReg.index.values]\n",
    "            Lin_ITE = LinearRegression().fit(train_X_LinReg.values,train_Y_LinReg)\n",
    "            #r2s.append(r2_score(ITE,Lin_ITE.predict(X_test_ITE_lin_reg.values)))\n",
    "            intercept.append(Lin_ITE.intercept_)\n",
    "            if len(coefs)==0:\n",
    "                coefs = Lin_ITE.coef_\n",
    "            else:\n",
    "                coefs = np.vstack([coefs,Lin_ITE.coef_])\n",
    "        intercept = np.array(intercept)        \n",
    "\n",
    "        print(\"\")\n",
    "        quantile = p_values_null_coef(intercept)/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "        significant_string = \"\" if (np.round(p_value,3)>0.05) else 20*\"-\"+\">  \" \n",
    "        print(significant_string+\"TREATMENT: \"+str(np.round(p_value,3)))\n",
    "        print(\"Intercept = \"+str(np.mean(intercept))+\" (+-\"+str(np.std(intercept))+\")\")\n",
    "\n",
    "        for i in range(len(X_lin_analysis.columns)):\n",
    "            quantile = p_values_null_coef(coefs[:,i])/100\n",
    "            if quantile > 0.5:\n",
    "                p_value = 1-quantile\n",
    "            else:\n",
    "                p_value = quantile\n",
    "            significant_string = \"\" if (np.round(p_value,3)>0.05) else 20*\"-\"+\">  \"\n",
    "            print(significant_string+str(X_lin_analysis.columns[i])+\": \"+str(np.round(p_value,3)))\n",
    "        print(100*\"=\")\n",
    "        \n",
    "print(\"\")       \n",
    "print(\"MEAN SQRT E_PEHE: \"+str(np.mean(pehes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_bool = False\n",
    "if print_bool:\n",
    "    print(\"\")\n",
    "    print(\"T0 TRAIN\")\n",
    "    print(classification_report(T0_y_train,T0_CB_model.predict(T0_X_train)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T0_CB_model, Pool(data=T0_X_train,label=T0_y_train), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T0_y_train,T0_CB_model.predict(T0_X_train)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    print(\"T1 TRAIN\")\n",
    "    print(classification_report(T1_y_train,T1_CB_model.predict(T1_X_train)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T1_CB_model, Pool(data=T1_X_train,label=T1_y_train), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T1_y_train,T1_CB_model.predict(T1_X_train)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    print(\"T0 TEST\")\n",
    "    print(classification_report(T0_y_test,T0_CB_model.predict(T0_X_test)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T0_CB_model, Pool(data=T0_X_test,label=T0_y_test), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T0_y_test,T0_CB_model.predict(T0_X_test)),4)))\n",
    "    print(50*\"=\")\n",
    "\n",
    "    print(\"T1 TEST\")\n",
    "    print(classification_report(T1_y_test,T1_CB_model.predict(T1_X_test)))\n",
    "    print(\"\\n\")\n",
    "    (fpr, tpr, thresholds) = get_roc_curve(T1_CB_model, Pool(data=T1_X_test,label=T1_y_test), plot=False)\n",
    "    print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "    print(\"MCC = \"+str(np.round(matthews_corrcoef(T1_y_test,T1_CB_model.predict(T1_X_test)),4)))\n",
    "    print(50*\"=\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITE Varying Random_state procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROPENSITY MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_multiple = 42\n",
    "\n",
    "feat = ['pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "           'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "           'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "           'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "           'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "           'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "           'data_year', 'nprevistq', 'dfageq', 'feduc6',\n",
    "           'dlivord_min', 'dtotord_min',\n",
    "           'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']\n",
    "\n",
    "train_dat,test_dat,train_y,test_y=train_test_split(dataset,treatment_observation_arr,test_size=0.25,random_state=42)\n",
    "\n",
    "train_dat = train_dat.reset_index()\n",
    "#train_dat = dataset.reset_index()\n",
    "#train_y = treatment_observation_arr\n",
    "\n",
    "test_dat = test_dat.reset_index()\n",
    "\n",
    "X_train_or = train_dat[feat].copy(deep=True)\n",
    "\n",
    "y_train_or = pd.Series(data=train_y)\n",
    "\n",
    "#if y_train_or.sum()/len(y_train_or)<0.5:\n",
    "#    y_train = y_train_or[y_train_or==1].append(y_train_or[y_train_or==0].sample(len(y_train_or[y_train_or==1]),random_state=RS_multiple))\n",
    "#    X_train = X_train_or[y_train_or==1].append(X_train_or[y_train_or==0].sample(len(y_train_or[y_train_or==1]),random_state=RS_multiple))\n",
    "#else:\n",
    "#    y_train = y_train_or[y_train_or==0].append(y_train_or[y_train_or==1].sample(len(y_train_or[y_train_or==0]),random_state=RS_multiple))\n",
    "#    X_train = X_train_or[y_train_or==0].append(X_train_or[y_train_or==1].sample(len(y_train_or[y_train_or==0]),random_state=RS_multiple))\n",
    "X_train=   X_train_or    \n",
    "y_train=   y_train_or\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_or = test_dat[feat].copy(deep=True)\n",
    "y_test_or = pd.Series(data=test_y)\n",
    "y_test = y_test_or\n",
    "X_test = X_test_or\n",
    "\n",
    "if y_test_or.sum()/len(y_test_or)<0.5:\n",
    "    y_test = y_test_or[y_test_or==1].append(y_test_or[y_test_or==0].sample(len(y_test_or[y_test_or==1]),random_state=RS_multiple))\n",
    "    X_test = X_test_or[y_test_or==1].append(X_test_or[y_test_or==0].sample(len(y_test_or[y_test_or==1]),random_state=RS_multiple))\n",
    "else:\n",
    "    y_test = y_test_or[y_test_or==0].append(y_test_or[y_test_or==1].sample(len(y_test_or[y_test_or==0]),random_state=RS_multiple))\n",
    "    X_test = X_test_or[y_test_or==0].append(X_test_or[y_test_or==1].sample(len(y_test_or[y_test_or==0]),random_state=RS_multiple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN PATIENTS \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.87      0.67      2610\n",
      "           1       0.93      0.71      0.81      6421\n",
      "\n",
      "    accuracy                           0.76      9031\n",
      "   macro avg       0.74      0.79      0.74      9031\n",
      "weighted avg       0.82      0.76      0.77      9031\n",
      "\n",
      "\n",
      "\n",
      "AUC = 0.8703\n",
      "MCC = 0.5258\n",
      "==================================================\n",
      "TEST PATIENTS \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       877\n",
      "           1       0.90      0.80      0.85       877\n",
      "\n",
      "    accuracy                           0.85      1754\n",
      "   macro avg       0.86      0.85      0.85      1754\n",
      "weighted avg       0.86      0.85      0.85      1754\n",
      "\n",
      "\n",
      "\n",
      "AUC = 0.9444\n",
      "MCC = 0.711\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "catboost_model = CatBoostClassifier\n",
    "#catboost_model = CatBoostRegressor\n",
    "#propensity_class_balance = [y_train.sum()/len(y_train),1-y_train.sum()/len(y_train)]\n",
    "propensity_class_balance = [y_test.sum()/len(y_test),1-y_test.sum()/len(y_test)]\n",
    "\n",
    "CB_treat = catboost_model(verbose=False,iterations=500,learning_rate=0.01,class_weights=propensity_class_balance)\n",
    "\n",
    "#CB_treat.fit(Pool(X_train,y_train))\n",
    "CB_treat.fit(Pool(X_test,y_test))\n",
    "\n",
    "print(\"\")\n",
    "print(\"TRAIN PATIENTS \")\n",
    "print(classification_report(y_train,CB_treat.predict(X_train)))\n",
    "print(\"\\n\")\n",
    "(fpr, tpr, thresholds) = get_roc_curve(CB_treat, Pool(data=X_train,label=y_train), plot=False)\n",
    "print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "print(\"MCC = \"+str(np.round(matthews_corrcoef(y_train,CB_treat.predict(X_train)),4)))\n",
    "print(50*\"=\")\n",
    "\n",
    "print(\"TEST PATIENTS \")\n",
    "print(classification_report(y_test,CB_treat.predict(X_test)))\n",
    "print(\"\\n\")\n",
    "(fpr, tpr, thresholds) = get_roc_curve(CB_treat, Pool(data=X_test,label=y_test), plot=False)\n",
    "print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "print(\"MCC = \"+str(np.round(matthews_corrcoef(y_test,CB_treat.predict(X_test)),4)))\n",
    "print(50*\"=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_one_matching = False\n",
    "multiple_exact = 1 if one_to_one_matching else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.special import logit\n",
    "causal_label=\"treatment\"\n",
    "\n",
    "## TRAINING\n",
    "train_AF_dataset_match = train_dat[feat+[\"index\"]].copy(deep=True).reset_index(drop=True)\n",
    "train_AF_dataset_match[\"treatment\"]=train_y\n",
    "train_AF_dataset_match[\"propensity_score_logit\"]=0\n",
    "\n",
    "y_train_proba = CB_treat.predict_proba(train_AF_dataset_match[feat])\n",
    "y_train_logit = np.array([logit(xi) for xi in y_train_proba[:,1]])\n",
    "train_AF_dataset_match.loc[:,\"propensity_score_logit\"]=y_train_logit\n",
    "\n",
    "NO_NOR_train_match = train_AF_dataset_match[train_AF_dataset_match[causal_label] == 0].copy(deep=True)\n",
    "NO_NOR_train_match = NO_NOR_train_match.reset_index(drop=True)\n",
    "NOR_train_match = train_AF_dataset_match[train_AF_dataset_match[causal_label] == 1].copy(deep=True)\n",
    "NOR_train_match = NOR_train_match.reset_index(drop=True)\n",
    "\n",
    "Neighbours = len(NO_NOR_train_match) if one_to_one_matching else multiple_exact\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=Neighbours)# , p = 2, radius=np.std(y_train_logit) * 0.25)\n",
    "knn.fit(NO_NOR_train_match[['propensity_score_logit']].to_numpy())\n",
    "      \n",
    "\n",
    "matched_element_arr = np.zeros((len(NOR_train_match),multiple_exact))\n",
    "j = 0\n",
    "if one_to_one_matching:\n",
    "    for row in NOR_train_match.iterrows():\n",
    "        distance,indexes = knn.kneighbors(np.reshape([row[1].propensity_score_logit],(-1,1)),n_neighbors=Neighbours)\n",
    "\n",
    "        for idx in indexes[0,:]:\n",
    "            if idx not in matched_element_arr[:,0]:\n",
    "                matched_element_arr[j,0] = idx\n",
    "                break\n",
    "        j = j+1\n",
    "        \n",
    "else:\n",
    "    for row in NOR_train_match.iterrows():\n",
    "        distance,indexes = knn.kneighbors(np.reshape([row[1].propensity_score_logit],(-1,1)),n_neighbors=Neighbours)\n",
    "        for i in range(multiple_exact):\n",
    "            matched_element_arr[j,i] = indexes[0,i]\n",
    "        \n",
    "        j = j+1\n",
    "\n",
    "if one_to_one_matching:  \n",
    "    all_matched_data = pd.concat([train_AF_dataset_match[train_AF_dataset_match[causal_label] == 1], NO_NOR_train_match.iloc[matched_element_arr[:,0]]])\n",
    "else:\n",
    "    all_matched_data = pd.concat([train_AF_dataset_match[train_AF_dataset_match[causal_label] == 1], NO_NOR_train_match.iloc[matched_element_arr[:,0]]])\n",
    "    for i in range(multiple_exact-1):\n",
    "        all_matched_data = pd.concat([all_matched_data, NO_NOR_train_match.iloc[matched_element_arr[:,i]]])\n",
    "        \n",
    "all_matched_data = all_matched_data.drop_duplicates(\"index\")\n",
    "\n",
    "## TEST SET\n",
    "test_AF_dataset_match = test_dat[feat+[\"index\"]].copy(deep=True).reset_index(drop=True)\n",
    "test_AF_dataset_match[\"treatment\"]=test_y\n",
    "test_AF_dataset_match[\"propensity_score_logit\"]=0\n",
    "\n",
    "y_test_proba = CB_treat.predict_proba(test_AF_dataset_match[feat])\n",
    "y_test_logit = np.array([logit(xi) for xi in y_test_proba[:,1]])\n",
    "test_AF_dataset_match.loc[:,\"propensity_score_logit\"]=y_test_logit\n",
    "\n",
    "NO_NOR_test_match = test_AF_dataset_match[test_AF_dataset_match[causal_label] == 0].copy(deep=True)\n",
    "NO_NOR_test_match = NO_NOR_test_match.reset_index(drop=True)\n",
    "NOR_test_match = test_AF_dataset_match[test_AF_dataset_match[causal_label] == 1].copy(deep=True)\n",
    "NOR_test_match = NOR_test_match.reset_index(drop=True)\n",
    "\n",
    "Neighbours = len(NO_NOR_test_match) if one_to_one_matching else multiple_exact\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=Neighbours)# , p = 2, radius=np.std(y_test_logit) * 0.25)\n",
    "knn.fit(NO_NOR_test_match[['propensity_score_logit']].to_numpy())\n",
    "      \n",
    "\n",
    "matched_element_arr = np.zeros((len(NOR_test_match),multiple_exact))\n",
    "j = 0\n",
    "if one_to_one_matching:\n",
    "    for row in NOR_test_match.iterrows():\n",
    "        distance,indexes = knn.kneighbors(np.reshape([row[1].propensity_score_logit],(-1,1)),n_neighbors=Neighbours)\n",
    "\n",
    "        for idx in indexes[0,:]:\n",
    "            if idx not in matched_element_arr[:,0]:\n",
    "                matched_element_arr[j,0] = idx\n",
    "                break\n",
    "        j = j+1\n",
    "        \n",
    "else:\n",
    "    for row in NOR_test_match.iterrows():\n",
    "        distance,indexes = knn.kneighbors(np.reshape([row[1].propensity_score_logit],(-1,1)),n_neighbors=Neighbours)\n",
    "        for i in range(multiple_exact):\n",
    "            matched_element_arr[j,i] = indexes[0,i]\n",
    "        \n",
    "        j = j+1\n",
    "\n",
    "if one_to_one_matching:  \n",
    "    test_all_matched_data = pd.concat([test_AF_dataset_match[test_AF_dataset_match[causal_label] == 1], NO_NOR_test_match.iloc[matched_element_arr[:,0]]])\n",
    "else:\n",
    "    test_all_matched_data = pd.concat([test_AF_dataset_match[test_AF_dataset_match[causal_label] == 1], NO_NOR_test_match.iloc[matched_element_arr[:,0]]])\n",
    "    for i in range(multiple_exact-1):\n",
    "        test_all_matched_data = pd.concat([test_all_matched_data, NO_NOR_test_match.iloc[matched_element_arr[:,i]]])\n",
    "        \n",
    "test_all_matched_data = test_all_matched_data.drop_duplicates(\"index\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN BALANCE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.74      0.47      1285\n",
      "           1       0.93      0.71      0.81      6421\n",
      "\n",
      "    accuracy                           0.72      7706\n",
      "   macro avg       0.64      0.73      0.64      7706\n",
      "weighted avg       0.83      0.72      0.75      7706\n",
      "\n",
      "\n",
      "\n",
      "AUC = 0.7962\n",
      "MCC = 0.3533\n",
      "==================================================\n",
      "\n",
      "TEST BALANCE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.77      0.47       341\n",
      "           1       0.95      0.76      0.84      2134\n",
      "\n",
      "    accuracy                           0.76      2475\n",
      "   macro avg       0.65      0.77      0.66      2475\n",
      "weighted avg       0.87      0.76      0.79      2475\n",
      "\n",
      "\n",
      "\n",
      "AUC = 0.8522\n",
      "MCC = 0.3926\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"TRAIN BALANCE\")\n",
    "print(classification_report(all_matched_data[causal_label],CB_treat.predict(all_matched_data[feat])))\n",
    "print(\"\\n\")\n",
    "(fpr, tpr, thresholds) = get_roc_curve(CB_treat, Pool(data=all_matched_data[feat],label=all_matched_data[causal_label]), plot=False)\n",
    "print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "print(\"MCC = \"+str(np.round(matthews_corrcoef(all_matched_data[causal_label],CB_treat.predict(all_matched_data[feat])),4)))\n",
    "print(50*\"=\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"TEST BALANCE\")\n",
    "print(classification_report(test_all_matched_data[causal_label],CB_treat.predict(test_all_matched_data[feat])))\n",
    "print(\"\\n\")\n",
    "(fpr, tpr, thresholds) = get_roc_curve(CB_treat, Pool(data=test_all_matched_data[feat],label=test_all_matched_data[causal_label]), plot=False)\n",
    "print(\"AUC = \"+str(np.round(auc(fpr,tpr),4)))\n",
    "print(\"MCC = \"+str(np.round(matthews_corrcoef(test_all_matched_data[causal_label],CB_treat.predict(test_all_matched_data[feat])),4)))\n",
    "print(50*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = dataset[dataset.index.isin(all_matched_data.index)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_temp\n",
    "treatment_observation_arr = dataset_temp.treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [09:07<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING SET\n",
      "+---------------+----------------------+---------------------+---------------------+\n",
      "|   SQRT E PEHE | ATE (std)            | STD ITE (std)       |   p-Value Treatment |\n",
      "+===============+======================+=====================+=====================+\n",
      "|        0.3188 | -0.03257 (+-0.01205) | 0.02998 (+-0.00715) |                   0 |\n",
      "+---------------+----------------------+---------------------+---------------------+\n",
      "\n",
      "TEST SET\n",
      "+---------------+----------------------+---------------------+---------------------+\n",
      "|   SQRT E PEHE | ATE (std)            | STD ITE (std)       |   p-Value Treatment |\n",
      "+===============+======================+=====================+=====================+\n",
      "|       0.32095 | -0.03258 (+-0.01209) | 0.02972 (+-0.00704) |                   0 |\n",
      "+---------------+----------------------+---------------------+---------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_nan_features = False\n",
    "verbose_bool = False\n",
    "selection_bias = False\n",
    "shap_prognost_predict = True\n",
    "combo = True #if set to True, we use a S-learner, if set to false we use T-learner\n",
    "pehes = []\n",
    "mean_ITEs = []\n",
    "std_ITEs = []\n",
    "train_pehes = []\n",
    "train_std_ITEs = []\n",
    "train_mean_ITEs = []\n",
    "bootstrap_iterations = 500#0\n",
    "test_test_size = 0.2\n",
    "val_test_size = 0.3\n",
    "shap_difs = np.array([])\n",
    "T0_shaps = np.array([])\n",
    "T0_shap_values_ar = np.array([])\n",
    "T1_shaps  = np.array([])\n",
    "T1_shap_values_ar = np.array([])\n",
    "T1_X_shap_ar = np.array([])\n",
    "T0_X_shap_ar = np.array([])\n",
    "\n",
    "for i in tqdm(range(bootstrap_iterations),ascii==True):\n",
    "    #print(\"\\rRun \"+str(i+1)+\"/\"+str(bootstrap_iterations),end=\"\")\n",
    "    \n",
    "    treatment_observation_arr = np.array([0]) \n",
    "    while(np.mean(treatment_observation_arr)<0.2 or np.mean(treatment_observation_arr)>0.8): \n",
    "        if not selection_bias:\n",
    "            treatment_observation_arr = np.random.randint(0,2,len(dataset))\n",
    "        else:\n",
    "            #ADD SELECTION BIAS\n",
    "            noise_level = 0.1\n",
    "            feat = ['pldel', 'birattnd', 'brstate', 'stoccfipb', 'mager8',\n",
    "                   'ormoth', 'mrace', 'meduc6', 'dmar', 'mplbir', 'mpre5', 'adequacy',\n",
    "                   'orfath', 'frace', 'birmon', 'gestat10', 'csex', 'anemia', 'cardiac',\n",
    "                   'lung', 'diabetes', 'herpes', 'hydra', 'hemo', 'chyper', 'phyper',\n",
    "                   'eclamp', 'incervix', 'pre4000', 'preterm', 'renal', 'rh', 'uterine',\n",
    "                   'othermr', 'tobacco', 'alcohol', 'cigar6', 'drink5', 'crace',\n",
    "                   'data_year', 'nprevistq', 'dfageq', 'feduc6',\n",
    "                   'dlivord_min', 'dtotord_min',\n",
    "                   'brstate_reg', 'stoccfipb_reg', 'mplbir_reg']\n",
    "            #feat=['gestat10', 'nprevistq', 'csex', 'hydra']\n",
    "            n_features = len(feat)\n",
    "            treatment_weights = np.random.uniform(-0.1,0.1,(n_features))\n",
    "            treatment_noise = np.random.normal(0,noise_level)\n",
    "            treatment_observation_arr = np.random.binomial(1,sigmoid(np.matmul(dataset[feat].fillna(0).values,treatment_weights)+treatment_noise))  \n",
    "\n",
    "    T0_train_dataset,T0_test_dataset = train_test_split(dataset[treatment_observation_arr==0],test_size=test_test_size,random_state=i)\n",
    "    T0_train_dataset,T0_val_dataset = train_test_split(T0_train_dataset,test_size=val_test_size,random_state=i)\n",
    "\n",
    "    T1_train_dataset,T1_test_dataset = train_test_split(dataset[treatment_observation_arr==1],test_size=test_test_size,random_state=i)\n",
    "    T1_train_dataset,T1_val_dataset = train_test_split(T1_train_dataset,test_size=val_test_size,random_state=i)\n",
    "\n",
    "    T0_X_train =  T0_train_dataset[lighter_columns]\n",
    "    T0_X_val =  T0_val_dataset[lighter_columns]\n",
    "    T0_X_test =  T0_test_dataset[lighter_columns]\n",
    "    T0_X_train = T0_X_train.rename(columns={'infant_id_0':'infant_id',  'bord_0':'bord'})\n",
    "    T0_X_val = T0_X_val.rename(columns={'infant_id_0':'infant_id',  'bord_0':'bord'})\n",
    "    T0_X_test = T0_X_test.rename(columns={'infant_id_0':'infant_id',  'bord_0':'bord'})\n",
    "\n",
    "    T0_y_train =  T0_train_dataset[\"mort_0\"]\n",
    "    T0_y_val =  T0_val_dataset[\"mort_0\"]\n",
    "    T0_y_test = T0_test_dataset[\"mort_0\"]\n",
    "\n",
    "    T1_X_train = T1_train_dataset[heavier_columns]\n",
    "    T1_X_val = T1_val_dataset[heavier_columns]\n",
    "    T1_X_test = T1_test_dataset[heavier_columns]\n",
    "    T1_X_train = T1_X_train.rename(columns={'infant_id_1':'infant_id',  'bord_1':'bord'})\n",
    "    T1_X_val = T1_X_val.rename(columns={'infant_id_1':'infant_id',  'bord_1':'bord'})\n",
    "    T1_X_test = T1_X_test.rename(columns={'infant_id_1':'infant_id',  'bord_1':'bord'})\n",
    "\n",
    "    T1_y_train = T1_train_dataset[\"mort_1\"]\n",
    "    T1_y_val = T1_val_dataset[\"mort_1\"]\n",
    "    T1_y_test  = T1_test_dataset[\"mort_1\"]\n",
    "    \n",
    "    X_test_separate = pd.DataFrame(data=np.vstack((T0_X_test,T1_X_test)),columns=T0_X_test.columns)\n",
    "    X_train_separate = pd.DataFrame(data=np.vstack((T0_X_train,T1_X_train)),columns=T0_X_train.columns) \n",
    "    \n",
    "    if combo:\n",
    "        C_X_train = pd.DataFrame(data=np.vstack((np.hstack((T0_X_train,np.zeros((len(T0_X_train),1)))),np.hstack((T1_X_train,np.zeros((len(T1_X_train),1))+1)))),columns=np.append(T0_X_train.columns.values,\"treatment\"))\n",
    "        C_X_val = pd.DataFrame(data=np.vstack((np.hstack((T0_X_val,np.zeros((len(T0_X_val),1)))),np.hstack((T1_X_val,np.zeros((len(T1_X_val),1))+1)))),columns=np.append(T0_X_val.columns.values,\"treatment\"))\n",
    "        C_X_test_T0 = pd.DataFrame(data=np.hstack((X_test_separate,np.zeros((len(X_test_separate),1)))),columns=np.append(X_test_separate.columns.values,\"treatment\"))\n",
    "        C_X_test_T1 = pd.DataFrame(data=np.hstack((X_test_separate,np.zeros((len(X_test_separate),1))+1)),columns=np.append(X_test_separate.columns.values,\"treatment\"))\n",
    "        C_X_train_T0 = pd.DataFrame(data=np.hstack((X_train_separate,np.zeros((len(X_train_separate),1)))),columns=np.append(X_train_separate.columns.values,\"treatment\"))\n",
    "        C_X_train_T1 = pd.DataFrame(data=np.hstack((X_train_separate,np.zeros((len(X_train_separate),1))+1)),columns=np.append(X_train_separate.columns.values,\"treatment\"))\n",
    "        C_y_train = np.append(T0_y_train,T1_y_train)\n",
    "        C_y_val = np.append(T0_y_val,T1_y_val)\n",
    "        C_y_test = np.append(T0_y_test,T1_y_test)\n",
    "\n",
    "    if not combo:\n",
    "        T0_class_balance = [T0_y_train.sum()/len(T0_y_train),1-T0_y_train.sum()/len(T0_y_train)]\n",
    "        T0_CB_model = CatBoostClassifier(verbose=verbose_bool,iterations=100,class_weights=T0_class_balance,use_best_model=True)\n",
    "        T0_CB_model.fit(Pool(T0_X_train,T0_y_train),eval_set=(T0_X_val,T0_y_val))\n",
    "\n",
    "        T1_class_balance = [T1_y_train.sum()/len(T1_y_train),1-T1_y_train.sum()/len(T1_y_train)]\n",
    "        T1_CB_model = CatBoostClassifier(verbose=verbose_bool,iterations=100,class_weights=T1_class_balance,use_best_model=True)\n",
    "        T1_CB_model.fit(Pool(T1_X_train,T1_y_train),eval_set=(T1_X_val,T1_y_val))\n",
    "        \n",
    "        label_ITE = T1_CB_model.predict_proba(X_test_separate)[:,1]-T0_CB_model.predict_proba(X_test_separate)[:,1]\n",
    "        train_label_ITE = T1_CB_model.predict_proba(X_train_separate)[:,1]-T0_CB_model.predict_proba(X_train_separate)[:,1]\n",
    "        \n",
    "        T1_explainer = shap.TreeExplainer(T1_CB_model)\n",
    "        T1_shap_values = np.abs(T1_explainer.shap_values(X_test_separate))\n",
    "        T0_explainer = shap.TreeExplainer(T0_CB_model)\n",
    "        T0_shap_values = np.abs(T0_explainer.shap_values(X_test_separate))\n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values,axis=0)\n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "            T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "            T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "            T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "            T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "\n",
    "    else:\n",
    "        C_class_balance = [C_y_train.sum()/len(C_y_train),1-C_y_train.sum()/len(C_y_train)]\n",
    "        C_CB_model = CatBoostClassifier(verbose=verbose_bool,iterations=100,class_weights=C_class_balance,use_best_model=True)\n",
    "        C_CB_model.fit(Pool(C_X_train,C_y_train),eval_set=(C_X_val,C_y_val))\n",
    "        \n",
    "        label_ITE = C_CB_model.predict_proba(C_X_test_T1)[:,1]-C_CB_model.predict_proba(C_X_test_T0)[:,1]\n",
    "        train_label_ITE = C_CB_model.predict_proba(C_X_train_T1)[:,1]-C_CB_model.predict_proba(C_X_train_T0)[:,1]\n",
    "\n",
    "        C_explainer = shap.TreeExplainer(C_CB_model)\n",
    "        T1_shap_values = C_explainer.shap_values(C_X_test_T1)\n",
    "        T0_shap_values = C_explainer.shap_values(C_X_test_T0)\n",
    "        \n",
    "        if len(T0_shap_values_ar)>0:\n",
    "            T0_shap_values_ar = np.vstack([T0_shap_values_ar,T0_shap_values])\n",
    "            T1_shap_values_ar = np.vstack([T1_shap_values_ar,T1_shap_values])\n",
    "            T1_X_shap_ar = np.vstack([T1_X_shap_ar,C_X_test_T1])\n",
    "            T0_X_shap_ar = np.vstack([T0_X_shap_ar,C_X_test_T0])\n",
    "        else:\n",
    "            T0_shap_values_ar = T0_shap_values\n",
    "            T1_shap_values_ar = T1_shap_values\n",
    "            T1_X_shap_ar = C_X_test_T1\n",
    "            T0_X_shap_ar = C_X_test_T0\n",
    "        \n",
    "        T1_shap_values = np.abs(T1_shap_values)\n",
    "        T0_shap_values = np.abs(T0_shap_values)\n",
    "        \n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values,axis=0)\n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "            T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "            T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "            T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "            T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "            \n",
    "\n",
    "\n",
    "    #print(\"\")\n",
    "    #print(np.mean(label_ITE))\n",
    "    mean_ITEs.append(np.mean(label_ITE))\n",
    "    std_ITEs.append(np.std(label_ITE))\n",
    "    train_mean_ITEs.append(np.mean(train_label_ITE))\n",
    "    train_std_ITEs.append(np.std(train_label_ITE))\n",
    "    pehes_temp = sqrt_epsilon_PEHE(np.append(T0_test_dataset[\"mort_1\"],T1_test_dataset[\"mort_1\"]),np.append(T0_test_dataset[\"mort_0\"],T1_test_dataset[\"mort_0\"]),label_ITE)\n",
    "    train_pehes_temp = sqrt_epsilon_PEHE(np.append(T0_train_dataset[\"mort_1\"],T1_train_dataset[\"mort_1\"]),np.append(T0_train_dataset[\"mort_0\"],T1_train_dataset[\"mort_0\"]),train_label_ITE)\n",
    "    pehes.append(pehes_temp)\n",
    "    train_pehes.append(train_pehes_temp)\n",
    "    #print(\"SQRT(E_PEHE) = \"+str(pehes_temp))\n",
    "\n",
    "#it does not matter which column array I pick, they all have the same\n",
    "if combo:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=np.append(T0_X_train.columns.values,\"treatment\"))\n",
    "    T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=np.append(T0_X_train.columns.values,\"treatment\"))\n",
    "    T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=np.append(T0_X_train.columns.values,\"treatment\"))\n",
    "else:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=T0_X_train.columns) \n",
    "    T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=T0_X_train.columns) \n",
    "    T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=T0_X_train.columns) \n",
    "\n",
    "########################################################################################################################################################   \n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(shap_difs_pd.columns)):\n",
    "    quantile = p_values_null_coef(np.array(shap_difs_pd.values[:,i]))/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_shap_diff_pd = pd.DataFrame(data=np.hstack([np.reshape(shap_difs_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=shap_difs_pd.mean().index)\n",
    "processed_shap_diff_pd = processed_shap_diff_pd.reindex(processed_shap_diff_pd.mean_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(T0_shaps_pd.columns)):\n",
    "    if shap_prognost_predict:\n",
    "        mean_random_uniform = T0_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "        quantile = p_values_arg_coef(np.array(T0_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "        p_value = quantile\n",
    "    else:\n",
    "        quantile = p_values_null_coef(np.array(T0_shaps_pd.values[:,i]))/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_T0_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T0_shaps_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=T0_shaps_pd.mean().index)\n",
    "processed_T0_shaps_pd = processed_T0_shaps_pd.reindex(processed_T0_shaps_pd.mean_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(T1_shaps_pd.columns)):\n",
    "    if shap_prognost_predict:\n",
    "        mean_random_uniform = T1_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "        quantile = p_values_arg_coef(np.array(T1_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "        p_value = quantile\n",
    "    else:\n",
    "        quantile = p_values_null_coef(np.array(T1_shaps_pd.values[:,i]))/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_T1_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T1_shaps_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=T1_shaps_pd.mean().index)\n",
    "processed_T1_shaps_pd = processed_T1_shaps_pd.reindex(processed_T1_shaps_pd.mean_shap.abs().sort_values(ascending=False).index)\n",
    "########################################################################################################################################################   \n",
    "\n",
    "## RESULT PRINTING\n",
    "print(\"\")       \n",
    "print(\"TRAINING SET\")\n",
    "quantile = p_values_null_coef(np.array(train_mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[np.round(np.mean(train_pehes),5),str(np.round(np.mean(train_mean_ITEs),5))+\" (+-\"+str(np.round(np.std(train_mean_ITEs),5))+\")\",str(np.round(np.mean(train_std_ITEs),5))+\" (+-\"+str(np.round(np.std(train_std_ITEs),5))+\")\",p_value]], [\"SQRT E PEHE\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))\n",
    "    \n",
    "print(\"\")       \n",
    "print(\"TEST SET\")\n",
    "quantile = p_values_null_coef(np.array(mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[np.round(np.mean(pehes),5),str(np.round(np.mean(mean_ITEs),5))+\" (+-\"+str(np.round(np.std(mean_ITEs),5))+\")\",str(np.round(np.mean(std_ITEs),5))+\" (+-\"+str(np.round(np.std(std_ITEs),5))+\")\",p_value]], [\"SQRT E PEHE\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gestat10</th>\n",
       "      <td>1.313800</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nprevistq</th>\n",
       "      <td>0.212441</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csex</th>\n",
       "      <td>0.121755</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>0.102638</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydra</th>\n",
       "      <td>0.074052</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_year</th>\n",
       "      <td>0.059552</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_shap  p_value\n",
       "gestat10    1.313800    0.000\n",
       "nprevistq   0.212441    0.000\n",
       "csex        0.121755    0.004\n",
       "treatment   0.102638    0.014\n",
       "hydra       0.074052    0.002\n",
       "data_year   0.059552    0.048"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_T1_shaps_pd[processed_T1_shaps_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x280.8 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.where(np.isin(C_X_test_T1.columns.values,processed_T1_shaps_pd[processed_T1_shaps_pd.p_value<0.05].index.values))\n",
    "shap.summary_plot(T1_shap_values_ar[:,list(idx[0])],pd.DataFrame(data=T1_X_shap_ar[:,list(idx[0])],columns=C_X_test_T1.columns[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gestat10</th>\n",
       "      <td>1.274192</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nprevistq</th>\n",
       "      <td>0.204924</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csex</th>\n",
       "      <td>0.118234</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydra</th>\n",
       "      <td>0.074803</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_shap  p_value\n",
       "gestat10    1.274192    0.000\n",
       "nprevistq   0.204924    0.000\n",
       "csex        0.118234    0.006\n",
       "treatment   0.091912    0.024\n",
       "hydra       0.074803    0.002"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_T0_shaps_pd[processed_T0_shaps_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.where(np.isin(C_X_test_T0.columns.values,processed_T0_shaps_pd[processed_T0_shaps_pd.p_value<0.05].index.values))\n",
    "shap.summary_plot(T0_shap_values_ar[:,list(idx[0])],pd.DataFrame(data=T0_X_shap_ar[:,list(idx[0])],columns=C_X_test_T0.columns[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gestat10</th>\n",
       "      <td>0.039608</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>0.010725</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_shap  p_value\n",
       "gestat10    0.039608    0.008\n",
       "treatment   0.010725    0.000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_shap_diff_pd[processed_shap_diff_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x165.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.where(np.isin(C_X_test_T0.columns.values,processed_shap_diff_pd[processed_shap_diff_pd.p_value<0.05].index.values))\n",
    "shap.summary_plot(T1_shap_values_ar[:,list(idx[0])]-T0_shap_values_ar[:,list(idx[0])],pd.DataFrame(data=T0_X_shap_ar[:,list(idx[0])],columns=C_X_test_T0.columns[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- T1 - T0 \n",
    "- Mortality = 1, survival = 0  \n",
    "- -> negative: T0_mortality > T1_mortality \n",
    "- high shap value (>0) -> more chance for mortality \n",
    "- lower shap value (<0) -> less chance for mortality \n",
    "- positive shap difference -> feature influences predicton adding more mortality in T1 compared to T0 \n",
    "- negative shap difference -> feature influences predicton adding more mortality in T0 compared to T1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHDP DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.599916</td>\n",
       "      <td>4.318780</td>\n",
       "      <td>3.268256</td>\n",
       "      <td>6.854457</td>\n",
       "      <td>-0.528603</td>\n",
       "      <td>-0.343455</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.316603</td>\n",
       "      <td>1.295216</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.875856</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.636059</td>\n",
       "      <td>7.562718</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>1.295216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.996273</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>1.570536</td>\n",
       "      <td>6.121617</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>-0.526556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.366206</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.244738</td>\n",
       "      <td>5.889125</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.857787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.963538</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.685048</td>\n",
       "      <td>6.191994</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>-0.360940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   1  5.599916  4.318780  3.268256  6.854457 -0.528603 -0.343455  1.128554   \n",
       "1   0  6.875856  7.856495  6.636059  7.562718 -1.736945 -1.802002  0.383828   \n",
       "2   0  2.996273  6.633952  1.570536  6.121617 -0.807451 -0.202946 -0.360898   \n",
       "3   0  1.366206  5.697239  1.244738  5.889125  0.390083  0.596582 -1.850350   \n",
       "4   0  1.963538  6.202582  1.685048  6.191994 -1.045229 -0.602710  0.011465   \n",
       "\n",
       "         8         9         10  11  12  13  14  15  16  17  18  19  20  21  \\\n",
       "0  0.161703 -0.316603  1.295216   1   0   1   0   0   0   0   1   0   1   1   \n",
       "1  2.244320 -0.629189  1.295216   0   0   0   1   0   0   1   1   1   1   1   \n",
       "2 -0.879606  0.808706 -0.526556   0   0   0   1   0   0   0   2   0   1   0   \n",
       "3 -0.879606 -0.004017 -0.857787   0   0   0   0   0   1   1   2   0   1   0   \n",
       "4  0.161703  0.683672 -0.360940   1   0   0   0   0   1   1   1   0   1   1   \n",
       "\n",
       "   22  23  24  25  26  27  28  29  \n",
       "0   1   1   0   0   0   0   0   0  \n",
       "1   1   1   0   0   0   0   0   0  \n",
       "2   1   1   0   0   0   0   0   0  \n",
       "3   1   1   0   0   0   0   0   0  \n",
       "4   1   1   0   0   0   0   0   0  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\", header = None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_factual</th>\n",
       "      <th>y_cfactual</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>y_1_outcome</th>\n",
       "      <th>y_0_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.599916</td>\n",
       "      <td>4.318780</td>\n",
       "      <td>3.268256</td>\n",
       "      <td>6.854457</td>\n",
       "      <td>-0.528603</td>\n",
       "      <td>-0.343455</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.316603</td>\n",
       "      <td>1.295216</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.599916</td>\n",
       "      <td>4.318780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.875856</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.636059</td>\n",
       "      <td>7.562718</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>1.295216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.875856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.996273</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>1.570536</td>\n",
       "      <td>6.121617</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>-0.526556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>2.996273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.366206</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.244738</td>\n",
       "      <td>5.889125</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.857787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.366206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.963538</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.685048</td>\n",
       "      <td>6.191994</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>-0.360940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.963538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  y_factual  y_cfactual       mu0       mu1        x1        x2  \\\n",
       "0          1   5.599916    4.318780  3.268256  6.854457 -0.528603 -0.343455   \n",
       "1          0   6.875856    7.856495  6.636059  7.562718 -1.736945 -1.802002   \n",
       "2          0   2.996273    6.633952  1.570536  6.121617 -0.807451 -0.202946   \n",
       "3          0   1.366206    5.697239  1.244738  5.889125  0.390083  0.596582   \n",
       "4          0   1.963538    6.202582  1.685048  6.191994 -1.045229 -0.602710   \n",
       "\n",
       "         x3        x4        x5        x6  x7  x8  x9  x10  x11  x12  x13  \\\n",
       "0  1.128554  0.161703 -0.316603  1.295216   1   0   1    0    0    0    0   \n",
       "1  0.383828  2.244320 -0.629189  1.295216   0   0   0    1    0    0    1   \n",
       "2 -0.360898 -0.879606  0.808706 -0.526556   0   0   0    1    0    0    0   \n",
       "3 -1.850350 -0.879606 -0.004017 -0.857787   0   0   0    0    0    1    1   \n",
       "4  0.011465  0.161703  0.683672 -0.360940   1   0   0    0    0    1    1   \n",
       "\n",
       "   x14  x15  x16  x17  x18  x19  x20  x21  x22  x23  x24  x25  y_1_outcome  \\\n",
       "0    1    0    1    1    1    1    0    0    0    0    0    0     5.599916   \n",
       "1    1    1    1    1    1    1    0    0    0    0    0    0     7.856495   \n",
       "2    2    0    1    0    1    1    0    0    0    0    0    0     6.633952   \n",
       "3    2    0    1    0    1    1    0    0    0    0    0    0     5.697239   \n",
       "4    1    0    1    1    1    1    0    0    0    0    0    0     6.202582   \n",
       "\n",
       "   y_0_outcome  \n",
       "0     4.318780  \n",
       "1     6.875856  \n",
       "2     2.996273  \n",
       "3     1.366206  \n",
       "4     1.963538  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col =  [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\" ,]\n",
    "\n",
    "for i in range(1,26):\n",
    "    col.append(\"x\"+str(i))\n",
    "dataset.columns = col\n",
    "\n",
    "dataset[\"y_1_outcome\"]=0\n",
    "dataset[\"y_0_outcome\"]=0\n",
    "dataset.loc[dataset.treatment==1,\"y_1_outcome\"]=dataset[dataset.treatment==1].y_factual\n",
    "dataset.loc[dataset.treatment==1,\"y_0_outcome\"]=dataset[dataset.treatment==1].y_cfactual\n",
    "\n",
    "dataset.loc[dataset.treatment==0,\"y_0_outcome\"]=dataset[dataset.treatment==0].y_factual\n",
    "dataset.loc[dataset.treatment==0,\"y_1_outcome\"]=dataset[dataset.treatment==0].y_cfactual\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['x1',\n",
    "             'x2',\n",
    "             'x3',\n",
    "             'x4',\n",
    "             'x5',\n",
    "             'x6',\n",
    "             'x7',\n",
    "             'x8',\n",
    "             'x9',\n",
    "             'x10',\n",
    "             'x11',\n",
    "             'x12',\n",
    "             'x13',\n",
    "             'x14',\n",
    "             'x15',\n",
    "             'x16',\n",
    "             'x17',\n",
    "             'x18',\n",
    "             'x19',\n",
    "             'x20',\n",
    "             'x21',\n",
    "             'x22',\n",
    "             'x23',\n",
    "             'x24',\n",
    "             'x25']\n",
    "\n",
    "#fixing some outliers \n",
    "for col in feature_cols:\n",
    "    dataset.loc[(dataset[col].values>dataset[~dataset[col].isna()][col].quantile(0.99))\n",
    "                            |(dataset[col].values<dataset[~dataset[col].isna()][col].quantile(0.01)),col]=np.NaN\n",
    "    \n",
    "dataset = dataset.fillna(dataset.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN FACTUAL : 3.1595375238575967\n",
      "MEAN COUNTERFACTUAL : 5.69610655030994\n",
      "ATE 4.0296612252169\n",
      "ITE STD 1.5997122212409884\n",
      "Treatment selection of T1: 0.18607764390896922\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"MEAN FACTUAL : \"+str(np.mean(dataset[\"y_factual\"])))\n",
    "print(\"MEAN COUNTERFACTUAL : \"+str(np.mean(dataset[\"y_cfactual\"])))\n",
    "print(\"ATE\", np.mean(dataset[\"y_1_outcome\"])- np.mean(dataset[\"y_0_outcome\"]))\n",
    "print(\"ITE STD\", np.std(dataset[\"y_1_outcome\"]- dataset[\"y_0_outcome\"]))\n",
    "plt.hist(dataset[\"y_1_outcome\"]-dataset[\"y_0_outcome\"])\n",
    "plt.title(\"ITE\")\n",
    "\n",
    "if not selection_bias:\n",
    "    #treatment_observation_arr = dataset[\"treatment\"]#np.random.randint(0,2,len(dataset))\n",
    "    treatment_observation_arr = np.random.randint(0,2,len(dataset))\n",
    "else:\n",
    "    #ADD SELECTION BIAS\n",
    "    #noise_level = 0.1\n",
    "    #feat = feature_cols\n",
    "    #n_features = len(feat)\n",
    "    #treatment_weights = np.random.uniform(-0.1,0.1,(n_features))\n",
    "    #treatment_noise = np.random.normal(0,noise_level)\n",
    "    treatment_observation_arr = dataset[\"treatment\"]#np.random.binomial(1,sigmoid(np.matmul(dataset[feat].fillna(0).values,treatment_weights)+treatment_noise))  \n",
    "    \n",
    "dataset[\"treatment\"]=treatment_observation_arr\n",
    "print(\"Treatment selection of T1: \"+str(sum(treatment_observation_arr)/len(treatment_observation_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:20<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING SET\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|   E PEHE | ATE (std)           | STD ITE (std)       |   p-Value Treatment |\n",
      "+==========+=====================+=====================+=====================+\n",
      "|  2.21965 | 3.62292 (+-0.09454) | 0.91933 (+-0.06409) |                   0 |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "\n",
      "TEST SET\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|   E PEHE | ATE (std)           | STD ITE (std)       |   p-Value Treatment |\n",
      "+==========+=====================+=====================+=====================+\n",
      "|  2.53815 | 3.61443 (+-0.11531) | 0.86702 (+-0.08252) |                   0 |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "           mean_shap  p_value\n",
      "treatment   3.624184    0.000\n",
      "x6         -0.008494    0.340\n",
      "x15        -0.003230    0.430\n",
      "x3          0.001680    0.390\n",
      "x1         -0.001372    0.370\n",
      "x2          0.001223    0.400\n",
      "x14        -0.001172    0.380\n",
      "x13         0.001044    0.360\n",
      "x18         0.000979    0.470\n",
      "x16         0.000898    0.360\n",
      "x10         0.000762    0.330\n",
      "x5         -0.000622    0.500\n",
      "x23        -0.000560    0.430\n",
      "x22        -0.000527    0.450\n",
      "x17        -0.000484    0.445\n",
      "x4          0.000349    0.470\n",
      "x7         -0.000336    0.470\n",
      "x20         0.000314    0.475\n",
      "x21        -0.000287    0.445\n",
      "x12        -0.000268    0.495\n",
      "x25         0.000263    0.465\n",
      "x19         0.000192    0.360\n",
      "x24        -0.000189    0.495\n",
      "x8         -0.000178    0.490\n",
      "x9          0.000137    0.440\n",
      "x11         0.000123    0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_nan_features = False\n",
    "verbose_bool = False\n",
    "combo = True\n",
    "pehes = []\n",
    "mean_ITEs = []\n",
    "std_ITEs = []\n",
    "train_pehes = []\n",
    "train_std_ITEs = []\n",
    "train_mean_ITEs = []\n",
    "bootstrap_iterations = 100#00\n",
    "test_test_size = 0.2\n",
    "val_test_size = 0.2\n",
    "shap_difs = np.array([])\n",
    "\n",
    "for i in tqdm(range(bootstrap_iterations),ascii==True):\n",
    "    #print(\"\\rRun \"+str(i+1)+\"/\"+str(bootstrap_iterations),end=\"\")\n",
    "\n",
    "    T0_train_dataset,T0_test_dataset = train_test_split(dataset[dataset.treatment==0],test_size=test_test_size,random_state=i)\n",
    "    T0_train_dataset,T0_val_dataset = train_test_split(T0_train_dataset,test_size=val_test_size,random_state=i)\n",
    "\n",
    "    T1_train_dataset,T1_test_dataset = train_test_split(dataset[dataset.treatment==1],test_size=test_test_size,random_state=i)\n",
    "    T1_train_dataset,T1_val_dataset = train_test_split(T1_train_dataset,test_size=val_test_size,random_state=i)\n",
    "\n",
    "    T0_X_train =  T0_train_dataset[feature_cols]\n",
    "    T0_X_val =  T0_val_dataset[feature_cols]\n",
    "    T0_X_test =  T0_test_dataset[feature_cols]\n",
    "\n",
    "    T0_y_train =  T0_train_dataset[\"y_0_outcome\"]\n",
    "    T0_y_val =  T0_val_dataset[\"y_0_outcome\"]\n",
    "    T0_y_test = T0_test_dataset[\"y_0_outcome\"]\n",
    "\n",
    "    T1_X_train = T1_train_dataset[feature_cols]\n",
    "    T1_X_val = T1_val_dataset[feature_cols]\n",
    "    T1_X_test = T1_test_dataset[feature_cols]\n",
    "    \n",
    "    T1_y_train = T1_train_dataset[\"y_1_outcome\"]\n",
    "    T1_y_val = T1_val_dataset[\"y_1_outcome\"]\n",
    "    T1_y_test  = T1_test_dataset[\"y_1_outcome\"]\n",
    "    \n",
    "    X_test_separate = pd.DataFrame(data=np.vstack((T0_X_test,T1_X_test)),columns=T0_X_test.columns)\n",
    "    X_train_separate = pd.DataFrame(data=np.vstack((T0_X_train,T1_X_train)),columns=T0_X_train.columns) \n",
    "    \n",
    "    if combo:\n",
    "        C_X_train = pd.DataFrame(data=np.vstack((np.hstack((T0_X_train,np.zeros((len(T0_X_train),1)))),np.hstack((T1_X_train,np.zeros((len(T1_X_train),1))+1)))),columns=np.append(T0_X_train.columns.values,\"treatment\"))\n",
    "        C_X_val = pd.DataFrame(data=np.vstack((np.hstack((T0_X_val,np.zeros((len(T0_X_val),1)))),np.hstack((T1_X_val,np.zeros((len(T1_X_val),1))+1)))),columns=np.append(T0_X_val.columns.values,\"treatment\"))\n",
    "        C_X_test_T0 = pd.DataFrame(data=np.hstack((X_test_separate,np.zeros((len(X_test_separate),1)))),columns=np.append(X_test_separate.columns.values,\"treatment\"))\n",
    "        C_X_test_T1 = pd.DataFrame(data=np.hstack((X_test_separate,np.zeros((len(X_test_separate),1))+1)),columns=np.append(X_test_separate.columns.values,\"treatment\"))\n",
    "        C_X_train_T0 = pd.DataFrame(data=np.hstack((X_train_separate,np.zeros((len(X_train_separate),1)))),columns=np.append(X_train_separate.columns.values,\"treatment\"))\n",
    "        C_X_train_T1 = pd.DataFrame(data=np.hstack((X_train_separate,np.zeros((len(X_train_separate),1))+1)),columns=np.append(X_train_separate.columns.values,\"treatment\"))\n",
    "        C_y_train = np.append(T0_y_train,T1_y_train)\n",
    "        C_y_val = np.append(T0_y_val,T1_y_val)\n",
    "        C_y_test = np.append(T0_y_test,T1_y_test)\n",
    "\n",
    "    if not combo:\n",
    "        T0_CB_model = CatBoostRegressor(verbose=verbose_bool,iterations=100,use_best_model=True)\n",
    "        T0_CB_model.fit(Pool(T0_X_train,T0_y_train),eval_set=(T0_X_val,T0_y_val))\n",
    "\n",
    "        T1_class_balance = [T1_y_train.sum()/len(T1_y_train),1-T1_y_train.sum()/len(T1_y_train)]\n",
    "        T1_CB_model = CatBoostRegressor(verbose=verbose_bool,iterations=100,use_best_model=True)\n",
    "        T1_CB_model.fit(Pool(T1_X_train,T1_y_train),eval_set=(T1_X_val,T1_y_val))\n",
    "        \n",
    "        label_ITE = T1_CB_model.predict(X_test_separate)-T0_CB_model.predict(X_test_separate)\n",
    "        train_label_ITE = T1_CB_model.predict(X_train_separate)-T0_CB_model.predict(X_train_separate)\n",
    "        \n",
    "        T1_explainer = shap.TreeExplainer(T1_CB_model)\n",
    "        T1_shap_values = T1_explainer.shap_values(X_test_separate)\n",
    "        T0_explainer = shap.TreeExplainer(T0_CB_model)\n",
    "        T0_shap_values = T0_explainer.shap_values(X_test_separate)\n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values,axis=0)\n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "\n",
    "    else:\n",
    "        C_CB_model = CatBoostRegressor(verbose=verbose_bool,iterations=100,use_best_model=True)\n",
    "        C_CB_model.fit(Pool(C_X_train,C_y_train),eval_set=(C_X_val,C_y_val))\n",
    "        \n",
    "        label_ITE = C_CB_model.predict(C_X_test_T1)-C_CB_model.predict(C_X_test_T0)\n",
    "        train_label_ITE = C_CB_model.predict(C_X_train_T1)-C_CB_model.predict(C_X_train_T0)\n",
    "\n",
    "        C_explainer = shap.TreeExplainer(C_CB_model)\n",
    "        T1_shap_values = C_explainer.shap_values(C_X_test_T1)\n",
    "        T0_shap_values = C_explainer.shap_values(C_X_test_T0)\n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values,axis=0)\n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "            \n",
    "\n",
    "\n",
    "    #print(\"\")\n",
    "    #print(np.mean(label_ITE))\n",
    "    mean_ITEs.append(np.mean(label_ITE))\n",
    "    std_ITEs.append(np.std(label_ITE))\n",
    "    train_mean_ITEs.append(np.mean(train_label_ITE))\n",
    "    train_std_ITEs.append(np.std(train_label_ITE))\n",
    "    pehes_temp = epsilon_PEHE(np.append(T0_test_dataset[\"y_1_outcome\"],T1_test_dataset[\"y_1_outcome\"]),np.append(T0_test_dataset[\"y_0_outcome\"],T1_test_dataset[\"y_0_outcome\"]),label_ITE)\n",
    "    train_pehes_temp = epsilon_PEHE(np.append(T0_train_dataset[\"y_1_outcome\"],T1_train_dataset[\"y_1_outcome\"]),np.append(T0_train_dataset[\"y_0_outcome\"],T1_train_dataset[\"y_0_outcome\"]),train_label_ITE)\n",
    "    pehes.append(pehes_temp)\n",
    "    train_pehes.append(train_pehes_temp)\n",
    "    #print(\"SQRT(E_PEHE) = \"+str(pehes_temp))\n",
    "\n",
    "#it does not matter which column array I pick, they all have the same\n",
    "if combo:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=np.append(T0_X_train.columns.values,\"treatment\"))\n",
    "else:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=T0_X_train.columns) \n",
    "    \n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(shap_difs_pd.columns)):\n",
    "    quantile = p_values_null_coef(np.array(shap_difs_pd.values[:,i]))/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_shap_diff_pd = pd.DataFrame(data=np.hstack([np.reshape(shap_difs_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_shap\",\"p_value\"],index=shap_difs_pd.mean().index)\n",
    "processed_shap_diff_pd = processed_shap_diff_pd.reindex(processed_shap_diff_pd.mean_shap.abs().sort_values(ascending=False).index)\n",
    "    \n",
    "## RESULT PRINTING\n",
    "print(\"\")       \n",
    "print(\"TRAINING SET\")\n",
    "quantile = p_values_null_coef(np.array(train_mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[np.round(np.mean(train_pehes),5),str(np.round(np.mean(train_mean_ITEs),5))+\" (+-\"+str(np.round(np.std(train_mean_ITEs),5))+\")\",str(np.round(np.mean(train_std_ITEs),5))+\" (+-\"+str(np.round(np.std(train_std_ITEs),5))+\")\",p_value]], [\"E PEHE\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))\n",
    "    \n",
    "print(\"\")       \n",
    "print(\"TEST SET\")\n",
    "quantile = p_values_null_coef(np.array(mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[np.round(np.mean(pehes),5),str(np.round(np.mean(mean_ITEs),5))+\" (+-\"+str(np.round(np.std(mean_ITEs),5))+\")\",str(np.round(np.mean(std_ITEs),5))+\" (+-\"+str(np.round(np.std(std_ITEs),5))+\")\",p_value]], [\"E PEHE\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))\n",
    "\n",
    "print(processed_shap_diff_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prognostic vs Predictive\n",
    "Based on paper: \"On Discovering Treatment-Effect  Modifiers Using Virtual Twins  and Causal Forest ML in the Presence  of Prognostic Biomarkers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M1(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*((x_features[:,6]>0).astype(int)*(x_features[:,7]>0).astype(int))+epsilon\n",
    "\n",
    "def M2(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*((x_features[:,0]>0).astype(int))+epsilon\n",
    "\n",
    "def M3(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*((x_features[:,19]>0).astype(int))+epsilon\n",
    "\n",
    "def M4(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+epsilon\n",
    "\n",
    "def M5(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*(x_features[:,9]+x_features[:,10]+x_features[:,11]+x_features[:,12]+x_features[:,13]+x_features[:,14])+epsilon\n",
    "\n",
    "def M6(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*((x_features[:,0]>0).astype(int)+(x_features[:,1]>0).astype(int)+(x_features[:,2]>0).astype(int)+(x_features[:,3]>0).astype(int)+(x_features[:,4]>0).astype(int))+T*((x_features[:,4]>0).astype(int))+epsilon\n",
    "\n",
    "def M7(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4]+x_features[:,5]+x_features[:,6]+x_features[:,7]+x_features[:,8]+x_features[:,9])+T*((x_features[:,19]>0).astype(int))+epsilon\n",
    "\n",
    "def M8(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4]+x_features[:,5]+x_features[:,6]+x_features[:,7]+x_features[:,8]+x_features[:,9])+T*((x_features[:,0]>0).astype(int))+epsilon\n",
    "\n",
    "def M9(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*np.sin(x_features[:,0])+epsilon\n",
    "\n",
    "def M10(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+10*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*((x_features[:,0]>0).astype(int))+epsilon\n",
    "\n",
    "def M11(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])**3+T*((x_features[:,0])**3)+epsilon\n",
    "\n",
    "def M12(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*(x_features[:,0])+epsilon\n",
    "\n",
    "def M13(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*(x_features[:,19])+epsilon\n",
    "\n",
    "def M14(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+50*T*((x_features[:,6]>0).astype(int)*(x_features[:,7]>0).astype(int))+epsilon\n",
    "\n",
    "def M15(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+50*T*((x_features[:,0]>0).astype(int))+epsilon\n",
    "\n",
    "def M16(T,x_features,N,npRandomState):\n",
    "    epsilon = npRandomState.normal(0,1,N)\n",
    "    return -1+3*(x_features[:,0]+x_features[:,1]+x_features[:,2]+x_features[:,3]+x_features[:,4])+T*((x_features[:,0]>0).astype(int)+10*(x_features[:,1]>0).astype(int)+5*(x_features[:,7]>0).astype(int))+epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../causalteshap/\")\n",
    "from causalteshap import CausalTeShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y</th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.423760</td>\n",
       "      <td>-0.678495</td>\n",
       "      <td>-0.143423</td>\n",
       "      <td>0.348286</td>\n",
       "      <td>0.170874</td>\n",
       "      <td>-1.980572</td>\n",
       "      <td>0.914098</td>\n",
       "      <td>-0.471858</td>\n",
       "      <td>1.049782</td>\n",
       "      <td>0.098206</td>\n",
       "      <td>0.499735</td>\n",
       "      <td>0.078838</td>\n",
       "      <td>1.417556</td>\n",
       "      <td>0.320152</td>\n",
       "      <td>-0.878442</td>\n",
       "      <td>0.664001</td>\n",
       "      <td>1.576923</td>\n",
       "      <td>0.960895</td>\n",
       "      <td>-0.508819</td>\n",
       "      <td>-1.705318</td>\n",
       "      <td>-1.705318</td>\n",
       "      <td>-1.705318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>-0.453414</td>\n",
       "      <td>-0.305499</td>\n",
       "      <td>-0.032656</td>\n",
       "      <td>0.283324</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>-1.054986</td>\n",
       "      <td>1.624487</td>\n",
       "      <td>1.012702</td>\n",
       "      <td>-0.780533</td>\n",
       "      <td>-0.064108</td>\n",
       "      <td>-0.427674</td>\n",
       "      <td>0.562897</td>\n",
       "      <td>-0.855488</td>\n",
       "      <td>1.115462</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>-0.296116</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>-0.369965</td>\n",
       "      <td>-0.951266</td>\n",
       "      <td>-3.077795</td>\n",
       "      <td>-3.077795</td>\n",
       "      <td>-3.077795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>-1.795643</td>\n",
       "      <td>-0.597381</td>\n",
       "      <td>0.064295</td>\n",
       "      <td>-0.936520</td>\n",
       "      <td>-0.431155</td>\n",
       "      <td>-0.587028</td>\n",
       "      <td>0.345517</td>\n",
       "      <td>-0.198187</td>\n",
       "      <td>1.199404</td>\n",
       "      <td>0.951791</td>\n",
       "      <td>0.247127</td>\n",
       "      <td>0.341102</td>\n",
       "      <td>1.672195</td>\n",
       "      <td>-1.505238</td>\n",
       "      <td>-1.128860</td>\n",
       "      <td>-0.066586</td>\n",
       "      <td>-1.404910</td>\n",
       "      <td>-0.579581</td>\n",
       "      <td>-0.105022</td>\n",
       "      <td>-8.204993</td>\n",
       "      <td>-8.204993</td>\n",
       "      <td>-8.204993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.330090</td>\n",
       "      <td>0.110418</td>\n",
       "      <td>0.946861</td>\n",
       "      <td>0.579584</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.149669</td>\n",
       "      <td>-0.255121</td>\n",
       "      <td>0.090569</td>\n",
       "      <td>-0.061126</td>\n",
       "      <td>1.532831</td>\n",
       "      <td>-1.455368</td>\n",
       "      <td>-1.277914</td>\n",
       "      <td>-0.428110</td>\n",
       "      <td>1.739606</td>\n",
       "      <td>1.157451</td>\n",
       "      <td>-0.175382</td>\n",
       "      <td>0.712897</td>\n",
       "      <td>0.933312</td>\n",
       "      <td>0.352032</td>\n",
       "      <td>9.012440</td>\n",
       "      <td>9.012440</td>\n",
       "      <td>9.012440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>0.732829</td>\n",
       "      <td>1.197179</td>\n",
       "      <td>-0.747217</td>\n",
       "      <td>-1.490083</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>1.024162</td>\n",
       "      <td>-1.066725</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.856153</td>\n",
       "      <td>0.686847</td>\n",
       "      <td>2.274512</td>\n",
       "      <td>-0.186220</td>\n",
       "      <td>-0.510500</td>\n",
       "      <td>0.330087</td>\n",
       "      <td>-0.747813</td>\n",
       "      <td>0.514054</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>-2.731540</td>\n",
       "      <td>-0.227100</td>\n",
       "      <td>-2.858491</td>\n",
       "      <td>-2.858491</td>\n",
       "      <td>-2.858491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        x1        x2        x3        x4        x5        x6  \\\n",
       "0      0  0.496714 -0.423760 -0.678495 -0.143423  0.348286  0.170874   \n",
       "1      1 -0.138264 -0.453414 -0.305499 -0.032656  0.283324  0.012255   \n",
       "2      2  0.647689 -1.795643 -0.597381  0.064295 -0.936520 -0.431155   \n",
       "3      3  1.523030 -0.330090  0.110418  0.946861  0.579584 -0.002527   \n",
       "4      4 -0.234153  0.732829  1.197179 -0.747217 -1.490083  0.490842   \n",
       "\n",
       "         x7        x8        x9       x10       x11       x12       x13  \\\n",
       "0 -1.980572  0.914098 -0.471858  1.049782  0.098206  0.499735  0.078838   \n",
       "1 -1.054986  1.624487  1.012702 -0.780533 -0.064108 -0.427674  0.562897   \n",
       "2 -0.587028  0.345517 -0.198187  1.199404  0.951791  0.247127  0.341102   \n",
       "3  0.149669 -0.255121  0.090569 -0.061126  1.532831 -1.455368 -1.277914   \n",
       "4  1.024162 -1.066725  0.717391  0.856153  0.686847  2.274512 -0.186220   \n",
       "\n",
       "        x14       x15       x16       x17       x18       x19       x20  \\\n",
       "0  1.417556  0.320152 -0.878442  0.664001  1.576923  0.960895 -0.508819   \n",
       "1 -0.855488  1.115462  0.618881 -0.296116  0.338188 -0.369965 -0.951266   \n",
       "2  1.672195 -1.505238 -1.128860 -0.066586 -1.404910 -0.579581 -0.105022   \n",
       "3 -0.428110  1.739606  1.157451 -0.175382  0.712897  0.933312  0.352032   \n",
       "4 -0.510500  0.330087 -0.747813  0.514054  0.009363 -2.731540 -0.227100   \n",
       "\n",
       "          y       y_0       y_1  T  \n",
       "0 -1.705318 -1.705318 -1.705318  1  \n",
       "1 -3.077795 -3.077795 -3.077795  1  \n",
       "2 -8.204993 -8.204993 -8.204993  0  \n",
       "3  9.012440  9.012440  9.012440  0  \n",
       "4 -2.858491 -2.858491 -2.858491  1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simulation dataset generation\n",
    "\n",
    "N = 5000 # 5000 or 800\n",
    "p = 20 #number of candidate biomarkers\n",
    "case = M1#9\n",
    "\n",
    "columns_list = []\n",
    "for i in range(p):\n",
    "    columns_list.append(\"x\"+str(i+1))\n",
    "    \n",
    "npRandomState = RandomState(1)\n",
    "npRandomState_or = RandomState(42)\n",
    "\n",
    "normal_mean = 0#npRandomState_or.uniform(-1,1,1) #1#0 #np.pi\n",
    "\n",
    "x_features = np.array([])\n",
    "for i in range(p):\n",
    "    if len(x_features)>0:\n",
    "        x_features = np.vstack([x_features,npRandomState_or.normal(normal_mean,1,N)])\n",
    "    else:\n",
    "        x_features = npRandomState_or.normal(normal_mean,1,N)\n",
    "x_features = np.transpose(x_features)\n",
    "\n",
    "\n",
    "treatment_assignment = npRandomState.randint(0,2,N)\n",
    "\n",
    "npRandomState_or = RandomState(42)\n",
    "y = case(treatment_assignment,x_features,N,npRandomState_or)\n",
    "npRandomState_or = RandomState(42)\n",
    "y_0 = case(np.zeros(N),x_features,N,npRandomState_or)\n",
    "npRandomState_or = RandomState(42)\n",
    "y_1 = case(np.zeros(N)+1,x_features,N,npRandomState_or)\n",
    "\n",
    "X_df = pd.DataFrame(data=x_features,columns=columns_list)\n",
    "X_df = X_df.reset_index()\n",
    "X_df[\"y\"]=y\n",
    "X_df[\"y_0\"]=y_0\n",
    "X_df[\"y_1\"]=y_1\n",
    "X_df[\"T\"]=treatment_assignment\n",
    "\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.073027\n",
      "0:\tlearn: 0.6917419\ttotal: 51.9ms\tremaining: 12.9s\n",
      "100:\tlearn: 0.6030709\ttotal: 400ms\tremaining: 589ms\n",
      "200:\tlearn: 0.5177116\ttotal: 748ms\tremaining: 182ms\n",
      "249:\tlearn: 0.4797549\ttotal: 915ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from causallib.estimation import IPW \n",
    "\n",
    "ipw = IPW(CatBoostClassifier(n_estimators=250,verbose=100))\n",
    "ipw.fit(X_df[columns_list], X_df[\"T\"])\n",
    "potential_outcomes = ipw.estimate_population_outcome(X_df[columns_list], X_df[\"T\"], X_df[\"y\"])\n",
    "effect = ipw.estimate_effect(potential_outcomes[1], potential_outcomes[0])\n",
    "effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diff    0.151654\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2374"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_df.y_1-X_df.y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_selector = CausalTeShap(CatBoostRegressor,iterations=50,S_learner=True,power_alpha=0.01,verbose=True,classification=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bf7bbbc42c4a5094da4e23dfa33f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n",
      "\n",
      "Failed to converge on a solution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "causal_selector = CausalTeShap(CatBoostRegressor,iterations=50,S_learner=True,power_alpha=0.01,verbose=True,classification=False)\n",
    "\n",
    "causal_selector.fit(X_df[columns_list],\n",
    "                    X_df.y.values,X_df[\"T\"].values,propensity_matching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Causality information:\n",
      "TRAIN: \t CATE = 0.20443478920609892 \t| p-value = 0.0\n",
      "VAL: \t CATE = 0.20684923441945055 \t| p-value = 0.0\n",
      "============================================================\n",
      "CATE shap stats\n",
      "----------------------------------------------------------------------\n",
      "|    |   impact |   p_value |\n",
      "|:---|---------:|----------:|\n",
      "| T  | 0.20855  |         0 |\n",
      "| x7 | 0.106005 |         0 |\n",
      "| x8 | 0.102044 |         0 |\n",
      "======================================================================\n",
      "T0 shap stats\n",
      "----------------------------------------------------------------------\n",
      "|    |    impact |   p_value |\n",
      "|:---|----------:|----------:|\n",
      "| x1 | 3.15342   |         0 |\n",
      "| x2 | 2.40154   |         0 |\n",
      "| x4 | 2.36939   |         0 |\n",
      "| x3 | 2.36261   |         0 |\n",
      "| x5 | 2.34721   |         0 |\n",
      "| T  | 0.103149  |         0 |\n",
      "| x7 | 0.064425  |         0 |\n",
      "| x8 | 0.0543367 |         0 |\n",
      "======================================================================\n",
      "T1 shap stats\n",
      "----------------------------------------------------------------------\n",
      "|    |   impact |   p_value |\n",
      "|:---|---------:|----------:|\n",
      "| x1 | 3.15346  |         0 |\n",
      "| x2 | 2.40343  |         0 |\n",
      "| x4 | 2.36846  |         0 |\n",
      "| x3 | 2.36348  |         0 |\n",
      "| x5 | 2.34722  |         0 |\n",
      "| x7 | 0.170958 |         0 |\n",
      "| x8 | 0.15678  |         0 |\n",
      "| T  | 0.104532 |         0 |\n",
      "======================================================================\n",
      "\n",
      "All predictive variables = \n",
      " \t \t['T', 'x7', 'x8']\n",
      "All prognostic variables = \n",
      " \t \t['T', 'x1', 'x2', 'x3', 'x4', 'x5', 'x7', 'x8']\n",
      " (Beware, S-learner is True, look at the impact to really discern between prognostic and predictive or only prognostic for variables that are both in the predictive and prognostic set)\n"
     ]
    }
   ],
   "source": [
    "causal_selector.show_all_causality_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47789915966386554"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test = train_test_split(X_df,test_size=0.2)\n",
    "\n",
    "X = X_train[columns_list]\n",
    "T = X_train[\"T\"]\n",
    "\n",
    "propensity_class_balance = [T.sum()/len(T),1-T.sum()/len(T)]\n",
    "propensity_model = CatBoostClassifier(verbose=0,n_estimators=250,class_weights=propensity_class_balance)\n",
    "propensity_model.fit(Pool(X,T))\n",
    "\n",
    "(fpr, tpr, thresholds) = get_roc_curve(propensity_model, Pool(data=X_test,label=X_test[\"T\"]), plot=False)\n",
    "auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3433\n",
      "0.5019004104696939\n",
      "0.5035101765466831\n"
     ]
    }
   ],
   "source": [
    "a,b,c = causal_selector.propensity_matching(X_df[columns_list],X_df[\"y\"],X_df[\"T\"])\n",
    "print(len(a))\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b8a7387d60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARFklEQVR4nO3df6zd9V3H8eert5dxmXOd45pIW1b+QLSOTdwN1CzR6TbpcGkRnVKtOl0kxmFmXDCQGZw4M7WJcYkYxbn4a4Kok1SHqVMxS5aBvdgNV1iXis62LHL3o+hCNy7t2z/OoR5u773n2/aUc++nz0fS5J7v+dzv903Leeb0fL+331QVkqTVb824B5AkjYZBl6RGGHRJaoRBl6RGGHRJasTacR344osvrk2bNo3r8JK0Kj388MOfr6rpxZ4bW9A3bdrE7OzsuA4vSatSks8u9ZwfuUhSIwy6JDXCoEtSIwy6JDXCoEtSI4Ze5ZLkA8CbgSer6pWLPB/gfcB1wNPAW6vqX0c96Om4b98R3r17P0ePzQNwwUSYP1FUwUTCjms28p7rrzy5dteeAzxx9BiXrJvilmuv4Pqr1nPfviP88t/s50tPz5/c70WTa7hg7QRPHZvnpVOTJHD06XkuWTfFd33TNA98eu7kfr7rm6b58COfe973D7Mm8KK1azg2f2K0vyHSmK0JnChYv8RrI8Bz/0zguqlJ3r3tW7j+qvWd97/U6/h016x2GfavLSb5DuDLwB8vEfTrgJ+lF/RrgPdV1TXDDjwzM1Pn4rLF+/Yd4Za/+CTzJ5b/79q55VJmXvF13Pahf+PY/PGT26cmJ/j+16znz/ceYv64/xKlNA6Ta8Kut7y6U3Dv23dk0dfxe2+48uT3d1mzWiR5uKpmFntu6EcuVfVR4IvLLNlOL/ZVVQ8C65J8w5mNevZ27TkwNOYAdz90iF17DjzvDxjg2Pxx7n7ImEvjNH+i2LXnQKe1S72OB7+/y5oWjOIz9PXAoYHHh/vbTpHkpiSzSWbn5uZGcOhTPXH0WKd1x6uWXHvcfyNeGruur+Wl1g1u77KmBS/oSdGququqZqpqZnp60Z9cPWuXrJvqtG4iWXLtRDLKkSSdga6v5aXWDW7vsqYFowj6EWDjwOMN/W1jccu1VzC5ZniQd1yzkVuuvYKpyYnnbZ+anGDHNRuZnDDq0rhMrgm3XHtFp7VLvY4Hv7/LmhaMIui7gR9Lzxbgqar63Aj2e0auv2o9u97yatZNTZ7cdsFEeO5N90TCzi2X8p7reydD3nvDlaxfN0XonYF/7w1X8p7rr2TXD7yal100+bx9XzS5hnVTk4TemfiXXTR58vt2brn0efvZueXSU75/mDWBqUmvJFV7nnuPtdRrY/Dt07qpyc4nRIElX8eD399lTQu6XOVyN/A64GLgv4FfAiYBqup3+5ct/jawld5liz9RVUMvXzlXV7lIUsuWu8pl6HXoVbVjyPMFvP0MZ5MkjYh/v5ekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRnQKepKtSQ4kOZjk1kWevzTJA0n2JXkkyXWjH1WStJyhQU8yAdwJvAnYDOxIsnnBsl8E7q2qq4Abgd8Z9aCSpOV1eYd+NXCwqh6vqmeAe4DtC9YU8LX9r18KPDG6ESVJXXQJ+nrg0MDjw/1tg94N7ExyGLgf+NnFdpTkpiSzSWbn5ubOYFxJ0lJGdVJ0B/CHVbUBuA74kySn7Luq7qqqmaqamZ6eHtGhJUnQLehHgI0Djzf0tw16G3AvQFV9HLgQuHgUA0qSuukS9L3A5UkuS3IBvZOeuxes+S/g9QBJvple0P1MRZJeQEODXlXPAjcDe4DH6F3Nsj/JHUm29Ze9E/ipJJ8E7gbeWlV1roaWJJ1qbZdFVXU/vZOdg9tuH/j6UeC1ox1NknQ6/ElRSWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRnQKepKtSQ4kOZjk1iXW/GCSR5PsT/Jnox1TkjTM2mELkkwAdwJvBA4De5PsrqpHB9ZcDtwGvLaqvpTk68/VwJKkxXV5h341cLCqHq+qZ4B7gO0L1vwUcGdVfQmgqp4c7ZiSpGG6BH09cGjg8eH+tkHfCHxjko8leTDJ1sV2lOSmJLNJZufm5s5sYknSokZ1UnQtcDnwOmAH8PtJ1i1cVFV3VdVMVc1MT0+P6NCSJOgW9CPAxoHHG/rbBh0GdlfVfFX9B/AZeoGXJL1AugR9L3B5ksuSXADcCOxesOY+eu/OSXIxvY9gHh/dmJKkYYYGvaqeBW4G9gCPAfdW1f4kdyTZ1l+2B/hCkkeBB4BbquoL52poSdKpUlVjOfDMzEzNzs6O5diStFolebiqZhZ7zp8UlaRGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGdAp6kq1JDiQ5mOTWZdZ9f5JKMjO6ESVJXQwNepIJ4E7gTcBmYEeSzYusewnwDuChUQ8pSRquyzv0q4GDVfV4VT0D3ANsX2TdrwC/DnxlhPNJkjrqEvT1wKGBx4f7205K8m3Axqr68HI7SnJTktkks3Nzc6c9rCRpaWd9UjTJGuA3gXcOW1tVd1XVTFXNTE9Pn+2hJUkDugT9CLBx4PGG/rbnvAR4JfDPSf4T2ALs9sSoJL2wugR9L3B5ksuSXADcCOx+7smqeqqqLq6qTVW1CXgQ2FZVs+dkYknSooYGvaqeBW4G9gCPAfdW1f4kdyTZdq4HlCR1s7bLoqq6H7h/wbbbl1j7urMfS5J0uvxJUUlqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEZ0CnqSrUkOJDmY5NZFnv/5JI8meSTJPyZ5xehHlSQtZ2jQk0wAdwJvAjYDO5JsXrBsHzBTVa8C/hL4jVEPKklaXpd36FcDB6vq8ap6BrgH2D64oKoeqKqn+w8fBDaMdkxJ0jBdgr4eODTw+HB/21LeBvzdYk8kuSnJbJLZubm57lNKkoYa6UnRJDuBGWDXYs9X1V1VNVNVM9PT06M8tCSd99Z2WHME2DjweEN/2/MkeQPwLuA7q+qroxlPktRVl3foe4HLk1yW5ALgRmD34IIkVwG/B2yrqidHP6YkaZihQa+qZ4GbgT3AY8C9VbU/yR1JtvWX7QK+BviLJJ9IsnuJ3UmSzpEuH7lQVfcD9y/YdvvA128Y8VySpNPkT4pKUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiPWdlmUZCvwPmACeH9V/dqC518E/DHwGuALwA9V1X+OdlS4b98Rdu05wBNHj3Hh5Bq++uwJThRMJOy4ZiPvuf7KU9atu2iSL39lnvkTS+9355ZL+Y+5L/Oxf//iqEeWdI687KJJquCpY/Ncsm6KW669AuDka/+SdVNsevnUKa/ryTXw4hdNcvTYPBMJx6tY3//+669aP/I5B3v00qlJEjj69P/PPMpjpqqWX5BMAJ8B3ggcBvYCO6rq0YE1PwO8qqp+OsmNwPdV1Q8tt9+ZmZmanZ3tPOh9+45w24f+jWPzx5dcs3PLpcy84uuGrpPUnsmJQMH8ieWbtpSpyQnee8OVIw3ssG6dyTGTPFxVM4s91+Ujl6uBg1X1eFU9A9wDbF+wZjvwR/2v/xJ4fZJ0nrCDXXsODI303Q8d6rROUnvmj9cZxxzg2Pxxdu05MMKJhndr1MfsEvT1wKGBx4f72xZdU1XPAk8BL1+4oyQ3JZlNMjs3N3dagz5x9NjQNcerOq2TpMWMuh9d9jfKY76gJ0Wr6q6qmqmqmenp6dP63kvWTQ1dM5F0WidJixl1P7rsb5TH7BL0I8DGgccb+tsWXZNkLfBSeidHR+aWa69ganJi2TU7rtnYaZ2k9kxOhMk1Z/5J79TkxMkTq6MyrEejPmaXq1z2ApcnuYxeuG8EfnjBmt3AjwMfB34A+Kcadrb1ND130qDLVS6D67zKRWrTarjKZWG3xn6VC0CS64DfonfZ4geq6leT3AHMVtXuJBcCfwJcBXwRuLGqHl9un6d7lYskafmrXDpdh15V9wP3L9h2+8DXXwHecjZDSpLOjj8pKkmNMOiS1AiDLkmNMOiS1IhOV7mckwMnc8BnX4BDXQx8/gU4ztlyztFbLbOuljlh9cy6WuaE05/1FVW16E9mji3oL5Qks0td4rOSOOforZZZV8ucsHpmXS1zwmhn9SMXSWqEQZekRpwPQb9r3AN05Jyjt1pmXS1zwuqZdbXMCSOctfnP0CXpfHE+vEOXpPOCQZekRjQf9CS/kuSRJJ9I8vdJLhn3TEtJsivJp/vz/nWSdeOeaTFJ3pJkf5ITSVbcpWFJtiY5kORgklvHPc9SknwgyZNJPjXuWZaTZGOSB5I82v9zf8e4Z1pKkguT/EuST/Zn/eVxz7ScJBNJ9iX521Hsr/mgA7uq6lVV9a3A3wK3D1k/Th8BXllVr6J3Y+7bxjzPUj4F3AB8dNyDLNS/qfmdwJuAzcCOJJvHO9WS/hDYOu4hOngWeGdVbQa2AG9fwb+nXwW+u6peDXwrsDXJlvGOtKx3AI+NamfNB72q/mfg4YuBFXsWuKr+vn9PVoAH6d0dasWpqseqarR30x2dLjc1XxGq6qP07h+wolXV56rqX/tf/y+9AI32ThAjUj1f7j+c7P9aka/5JBuA7wXeP6p9Nh90gCS/muQQ8COs7Hfog34S+LtxD7EKdbmpuc5Qkk30bmTz0JhHWVL/Y4xPAE8CH6mqlTrrbwG/ACxzP7XT00TQk/xDkk8t8ms7QFW9q6o2Ah8Ebl7Js/bXvIveX3M/uJLn1PklydcAfwX83IK/+a4oVXW8/xHrBuDqJK8c80inSPJm4MmqeniU++10x6KVrqre0HHpB+ndeemXzuE4yxo2a5K3Am8GXj/q+7KejtP4PV1putzUXKcpySS9mH+wqj407nm6qKqjSR6gd55ipZ14fi2wrX97zwuBr03yp1W182x22sQ79OUkuXzg4Xbg0+OaZZgkW+n9FWxbVT097nlWqZM3NU9yAb2bmu8e80yrWpIAfwA8VlW/Oe55lpNk+rmrw5JMAW9kBb7mq+q2qtpQVZvo/T/6T2cbczgPgg78Wv+jgkeA76F3Vnml+m3gJcBH+pdZ/u64B1pMku9Lchj4duDDSfaMe6bn9E8q3wzsoXfy7t6q2j/eqRaX5G7g48AVSQ4nedu4Z1rCa4EfBb67///lJ/rvLFeibwAe6L/e99L7DH0klwSuBv7ovyQ14nx4hy5J5wWDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1Ij/A2zvWhvwTxwsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_df[\"x1\"],y_1-y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propensity matching was included in fitting - Propensity information: \n",
      "\n",
      "Before matching auc \t | mean (std) = 0.9921 (0.0009)\n",
      "After matching auc \t | mean (std) = 0.9268 (0.0058)\n",
      "T0 all matched 146 samples\n",
      "T1 all matched 1979 samples\n",
      "\n",
      "Causality information:\n",
      "TRAIN: \t CATE = 0.1546563737474471 \t| p-value = 0.0\n",
      "VAL: \t CATE = 0.15297648396152505 \t| p-value = 0.0\n",
      "============================================================\n",
      "Include all mode\n",
      "============================================================\n",
      "CATE shap stats\n",
      "----------------------------------------------------------------------\n",
      "|                        |       impact |   p_value |   effect_size |   power_0.01_alpha |   0.99_power_its_req |\n",
      "|:-----------------------|-------------:|----------:|--------------:|-------------------:|---------------------:|\n",
      "| x8                     |  0.0771913   |      0    |    -7.24125   |          1         |              3.63459 |\n",
      "| x7                     |  0.076446    |      0    |    -9.51286   |          1         |              3.27014 |\n",
      "| T                      |  0.0206469   |      0.05 |    -3.34314   |          1         |              5.72053 |\n",
      "| x4                     |  0.0034496   |      0.15 |    -1.04587   |          0.953495  |             25.425   |\n",
      "| x3                     |  0.0031201   |      0.15 |    -1.07921   |          0.965174  |             24.0953  |\n",
      "| x2                     |  0.00309574  |      0.1  |    -1.26115   |          0.994562  |             18.6075  |\n",
      "| x1                     |  0.00265554  |      0.2  |    -0.676872  |          0.57409   |             55.8357  |\n",
      "| x17                    | -0.00075471  |      0    |     0.987756  |          0.9258    |             28.0742  |\n",
      "| x14                    | -0.000485255 |      0.1  |     0.829241  |          0.789407  |             38.3593  |\n",
      "| x11                    | -0.0004198   |      0.25 |     0.343994  |          0.12146   |            206.42    |\n",
      "| x12                    | -0.000354759 |      0.15 |     0.6683    |          0.560409  |             57.1884  |\n",
      "| x5                     | -0.000171234 |      0.3  |     0.0823676 |          0.0143952 |           3545.46    |\n",
      "| x10                    |  0.000160894 |      0.45 |    -0.192375  |          0.0373139 |            652.675   |\n",
      "| x20                    | -0.0001505   |      0.2  |     0.300351  |          0.0892114 |            269.724   |\n",
      "| x19                    | -0.000126355 |      0.3  |     0.277376  |          0.0750484 |            315.678   |\n",
      "| x16                    |  0.000122776 |      0.4  |    -0.0445185 |          0.0112542 |          12128.7     |\n",
      "| x15                    | -0.000122606 |      0.2  |     0.318093  |          0.101453  |            240.836   |\n",
      "| random_uniform_feature |  7.98019e-05 |      0.15 |     0         |          0.01      |              0       |\n",
      "| x13                    |  5.40727e-05 |      0.25 |     0.0477939 |          0.0114477 |          10523.7     |\n",
      "| x6                     | -5.33159e-05 |      0.2  |     0.22889   |          0.0509205 |            462.022   |\n",
      "| x9                     | -5.03527e-05 |      0.25 |     0.163904  |          0.0290362 |            897.855   |\n",
      "| x18                    |  2.0731e-05  |      0.3  |     0.0800987 |          0.014149  |           3748.97    |\n",
      "======================================================================\n",
      "T0 shap stats\n",
      "----------------------------------------------------------------------\n",
      "|                        |    impact |   p_value |   effect_size |   power_0.01_alpha |   0.99_power_its_req |\n",
      "|:-----------------------|----------:|----------:|--------------:|-------------------:|---------------------:|\n",
      "| x1                     | 3.11671   |      0    |   -66.4031    |        1           |             10       |\n",
      "| x2                     | 2.39436   |      0    |   -58.7014    |        1           |             10       |\n",
      "| x4                     | 2.38113   |      0    |   -45.7639    |        1           |              2.06667 |\n",
      "| x3                     | 2.37632   |      0    |   -55.4199    |        1           |              2.0121  |\n",
      "| x5                     | 2.32788   |      0    |   -65.1336    |        1           |             10       |\n",
      "| T                      | 0.148164  |      0    |    -5.28465   |        1           |              3.73483 |\n",
      "| x7                     | 0.134497  |      0    |   -11.2601    |        1           |              2.76706 |\n",
      "| x8                     | 0.128722  |      0    |   -10.5545    |        1           |              2.82242 |\n",
      "| x13                    | 0.0194713 |      0.15 |    -1.01343   |        0.969341    |             23.9205  |\n",
      "| x18                    | 0.019198  |      0.25 |    -1.02837   |        0.973364    |             23.3157  |\n",
      "| x17                    | 0.0159953 |      0.35 |    -0.460422  |        0.339927    |            104.855   |\n",
      "| x14                    | 0.0156458 |      0.25 |    -0.512044  |        0.421211    |             85.3101  |\n",
      "| x9                     | 0.0143593 |      0.45 |    -0.20588   |        0.0708825   |            513.431   |\n",
      "| x6                     | 0.0142564 |      0.45 |    -0.18451   |        0.0596037   |            638.581   |\n",
      "| random_uniform_feature | 0.0134288 |      0.55 |     0         |        0.01        |              0       |\n",
      "| x19                    | 0.013268  |      0.55 |     0.0299669 |        0.00711726  |             10       |\n",
      "| x16                    | 0.0131551 |      0.65 |     0.0558189 |        0.00524697  |             10       |\n",
      "| x15                    | 0.01232   |      0.65 |     0.261292  |        0.00031616  |             10       |\n",
      "| x10                    | 0.0121028 |      0.85 |     0.295823  |        0.000184153 |             10       |\n",
      "| x11                    | 0.0119723 |      0.9  |     0.257366  |        0.000335776 |             10       |\n",
      "| x20                    | 0.011971  |      0.75 |     0.311859  |        0.000142307 |             10       |\n",
      "| x12                    | 0.0102416 |      0.85 |     0.792155  |        7.40221e-09 |             10       |\n",
      "======================================================================\n",
      "T1 shap stats\n",
      "----------------------------------------------------------------------\n",
      "|                        |     impact |   p_value |   effect_size |   power_0.01_alpha |   0.99_power_its_req |\n",
      "|:-----------------------|-----------:|----------:|--------------:|-------------------:|---------------------:|\n",
      "| x1                     | 3.11979    |      0    |   -65.1426    |        1           |             10       |\n",
      "| x2                     | 2.39735    |      0    |   -58.6143    |        1           |             10       |\n",
      "| x4                     | 2.3846     |      0    |   -46.4176    |        1           |              2.06243 |\n",
      "| x3                     | 2.37925    |      0    |   -55.2484    |        1           |              2.01293 |\n",
      "| x5                     | 2.32791    |      0    |   -65.9367    |        1           |             10       |\n",
      "| x7                     | 0.214108   |      0    |   -27.0077    |        1           |              2.25311 |\n",
      "| x8                     | 0.206467   |      0    |   -24.3437    |        1           |              2.29784 |\n",
      "| x13                    | 0.0195233  |      0.15 |    -1.00942   |        0.96818     |             24.0874  |\n",
      "| x18                    | 0.019279   |      0.2  |    -1.04778   |        0.97792     |             22.5687  |\n",
      "| x17                    | 0.0153158  |      0.4  |    -0.325243  |        0.165188    |            207.364   |\n",
      "| x14                    | 0.0152255  |      0.25 |    -0.406573  |        0.262421    |            133.689   |\n",
      "| x9                     | 0.0143684  |      0.5  |    -0.187913  |        0.0612993   |            615.759   |\n",
      "| x6                     | 0.0142522  |      0.4  |    -0.170957  |        0.0532117   |            743.399   |\n",
      "| random_uniform_feature | 0.0134914  |      0.55 |     0         |        0.01        |              0       |\n",
      "| x16                    | 0.0132679  |      0.65 |     0.0456924 |        0.00592006  |             10       |\n",
      "| x19                    | 0.0130449  |      0.55 |     0.085365  |        0.00365493  |             10       |\n",
      "| x10                    | 0.0123159  |      0.75 |     0.265272  |        0.000297368 |             10       |\n",
      "| x15                    | 0.0121981  |      0.7  |     0.304215  |        0.000161    |             10       |\n",
      "| x20                    | 0.0118177  |      0.75 |     0.359909  |        6.40546e-05 |             10       |\n",
      "| T                      | 0.0115343  |      0.8  |     0.455198  |        1.17196e-05 |             10       |\n",
      "| x11                    | 0.0115232  |      0.9  |     0.406908  |        2.8255e-05  |             10       |\n",
      "| x12                    | 0.00991414 |      0.95 |     0.908382  |        0           |             10       |\n",
      "\n",
      "All predictive variables = \n",
      " \t \t['x8', 'x7', 'x17']\n",
      "All prognostic variables = \n",
      " \t \t['x1', 'x2', 'x3', 'x4', 'x5', 'x7', 'x8']\n",
      " (Beware, S-learner is True, look at the impact to really discern between prognostic and predictive or only prognostic for variables that are both in the predictive and prognostic set)\n"
     ]
    }
   ],
   "source": [
    "causal_selector.show_all_causality_information(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE\n",
    "run_old_cold = False\n",
    "if run_old_cold:\n",
    "    from scipy import stats\n",
    "    from statsmodels.stats.power import TTestPower,FTestAnovaPower\n",
    "\n",
    "    N = 5000 # 5000 or 800\n",
    "    p = 50 #number of candidate biomarkers\n",
    "    iterations = 10\n",
    "    case = M2\n",
    "    S_learner = True\n",
    "    shap_prognost_predict = True\n",
    "\n",
    "    pehes = []\n",
    "    train_pehes = []\n",
    "    mean_ITEs = []\n",
    "    std_ITEs = []\n",
    "    train_std_ITEs = []\n",
    "    train_mean_ITEs = []\n",
    "    shap_difs = np.array([])\n",
    "    T0_shaps = np.array([])\n",
    "    T0_shap_values_ar = np.array([])\n",
    "    T1_shaps  = np.array([])\n",
    "    T1_shap_values_ar = np.array([])\n",
    "    T1_X_shap_ar = np.array([])\n",
    "    T0_X_shap_ar = np.array([])\n",
    "\n",
    "    columns_list = []\n",
    "    for i in range(p):\n",
    "        columns_list.append(\"x\"+str(i+1))\n",
    "\n",
    "    columns_list_with_random = columns_list+[\"random_uniform_feature\"]\n",
    "\n",
    "    npRandomState = RandomState(1)\n",
    "\n",
    "    npRandomState_or = RandomState(42)\n",
    "\n",
    "    \"\"\"normal_mean = npRandomState_or.uniform(-1,1,1) #1#0 #np.pi\n",
    "    x_features = np.array([])\n",
    "    for i in range(p):\n",
    "        if len(x_features)>0:\n",
    "            x_features = np.vstack([x_features,npRandomState_or.normal(normal_mean,1,N)])\n",
    "        else:\n",
    "            x_features = npRandomState_or.normal(normal_mean,1,N)\n",
    "\n",
    "    x_features = np.transpose(x_features)\n",
    "    treatment_assignment = npRandomState.randint(0,2,N)\n",
    "\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y = case(treatment_assignment,x_features,N,npRandomState_or)\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y_0 = case(np.zeros(N),x_features,N,npRandomState_or)\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y_1 = case(np.zeros(N)+1,x_features,N,npRandomState_or)\"\"\"\n",
    "\n",
    "    for i in tqdm(range(iterations)):\n",
    "        npRandomState = RandomState(i)\n",
    "\n",
    "        random_uniform_feature = npRandomState.uniform(-1,1,N)\n",
    "\n",
    "        #X_df = pd.DataFrame(data=x_features,columns=columns_list)\n",
    "        #X_df = X_df.reset_index()\n",
    "        #X_df[\"y\"]=y\n",
    "        #X_df[\"y_0\"]=y_0\n",
    "        #X_df[\"y_1\"]=y_1\n",
    "        #X_df[\"T\"]=treatment_assignment\n",
    "        X_df.loc[:,\"random_uniform_feature\"] = random_uniform_feature\n",
    "\n",
    "        #indices_temp = X_df[\"index\"].values\n",
    "        #scaler = MinMaxScaler()\n",
    "        #scaler.fit(X_df)\n",
    "        #X_df = pd.DataFrame(data=scaler.transform(X_df),columns=X_df.columns)\n",
    "        #X_df.loc[:,\"index\"]=indices_temp\n",
    "\n",
    "        if S_learner:\n",
    "            columns_list_current = columns_list_with_random + [\"T\"]\n",
    "        else: \n",
    "            columns_list_current = columns_list_with_random\n",
    "\n",
    "        train_index,test_index = train_test_split(X_df[\"index\"].values,test_size=0.2,random_state=i,stratify=X_df[\"T\"])\n",
    "        #print(len(train_index))\n",
    "        train_index_t,val_index = train_test_split(train_index,test_size=0.2,random_state=i,stratify=X_df[X_df[\"index\"].isin(train_index)][\"T\"])\n",
    "        #print(len(train_index))\n",
    "\n",
    "        T0_X_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "        T0_X_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "        T0_X_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "        T1_X_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "        T1_X_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "        T1_X_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "\n",
    "        T0_y_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y\n",
    "        T0_y_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==0)].y\n",
    "        T0_y_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y\n",
    "        T1_y_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y\n",
    "        T1_y_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==1)].y\n",
    "        T1_y_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y\n",
    "\n",
    "\n",
    "        if S_learner:\n",
    "            S_X_train = T0_X_train.append(T1_X_train)\n",
    "            S_X_train_T1 = S_X_train.copy(deep=True)\n",
    "            S_X_train_T1.loc[:,\"T\"] = 1\n",
    "            S_X_train_T0 = S_X_train.copy(deep=True)\n",
    "            S_X_train_T0.loc[:,\"T\"] = 0\n",
    "\n",
    "            S_X_val = T0_X_val.append(T1_X_val)\n",
    "            S_X_val_T1 = S_X_val.copy(deep=True)\n",
    "            S_X_val_T1.loc[:,\"T\"] = 1\n",
    "            S_X_val_T0 = S_X_val.copy(deep=True)\n",
    "            S_X_val_T0.loc[:,\"T\"] = 0\n",
    "\n",
    "            S_X_test = T0_X_test.append(T1_X_test)\n",
    "            S_X_test_T1 = S_X_test.copy(deep=True)\n",
    "            S_X_test_T1.loc[:,\"T\"] = 1\n",
    "            S_X_test_T0 = S_X_test.copy(deep=True)\n",
    "            S_X_test_T0.loc[:,\"T\"] = 0\n",
    "\n",
    "            S_y_train = T0_y_train.append(T1_y_train)\n",
    "            S_y_val = T0_y_val.append(T1_y_val)\n",
    "            S_y_test = T0_y_test.append(T1_y_test)\n",
    "\n",
    "            S_model = CatBoostRegressor(iterations=250,verbose=False,use_best_model=False)\n",
    "            S_model.fit(S_X_train,S_y_train,eval_set=(S_X_val,S_y_val))\n",
    "\n",
    "            ITE = S_model.predict(S_X_test_T1)-S_model.predict(S_X_test_T0)\n",
    "            train_ITE = S_model.predict(S_X_train_T1)-S_model.predict(S_X_train_T0)\n",
    "\n",
    "            C_explainer = shap.TreeExplainer(S_model)\n",
    "            #T1_shap_values = C_explainer.shap_values(S_X_test_T1)\n",
    "            #T0_shap_values = C_explainer.shap_values(S_X_test_T0)\n",
    "            T1_shap_values = C_explainer.shap_values(S_X_val_T1)\n",
    "            T0_shap_values = C_explainer.shap_values(S_X_val_T0)\n",
    "\n",
    "            if len(T0_shap_values_ar)>0:\n",
    "                T0_shap_values_ar = np.vstack([T0_shap_values_ar,T0_shap_values])\n",
    "                T1_shap_values_ar = np.vstack([T1_shap_values_ar,T1_shap_values])\n",
    "                #T1_X_shap_ar = np.vstack([T1_X_shap_ar,S_X_test_T1])\n",
    "                #T0_X_shap_ar = np.vstack([T0_X_shap_ar,S_X_test_T0])\n",
    "                T1_X_shap_ar = np.vstack([T1_X_shap_ar,S_X_val_T1])\n",
    "                T0_X_shap_ar = np.vstack([T0_X_shap_ar,S_X_val_T0])\n",
    "            else:\n",
    "                T0_shap_values_ar = T0_shap_values\n",
    "                T1_shap_values_ar = T1_shap_values\n",
    "                #T1_X_shap_ar = S_X_test_T1\n",
    "                #T0_X_shap_ar = S_X_test_T0\n",
    "                T1_X_shap_ar = S_X_val_T1\n",
    "                T0_X_shap_ar = S_X_val_T0\n",
    "\n",
    "            #T1_shap_values = np.abs(T1_shap_values)\n",
    "            #T0_shap_values = np.abs(T0_shap_values)\n",
    "\n",
    "            ## includes predictive features, but not for features where the CATE = 0 but there is a large ITE (such as sinus)\n",
    "            shap_diff_ar = np.mean(T1_shap_values-T0_shap_values+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "\n",
    "            ## includes all relevant features\n",
    "            #shap_diff_ar = np.mean(np.abs(T1_shap_values-T0_shap_values)+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "\n",
    "            T1_shap_values = np.abs(T1_shap_values)\n",
    "            T0_shap_values = np.abs(T0_shap_values)\n",
    "\n",
    "            if len(shap_difs)>0:\n",
    "                shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "                T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "                T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "            else:\n",
    "                shap_difs = shap_diff_ar\n",
    "                T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "                T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "\n",
    "        else:\n",
    "            Total_X_train = T0_X_train.append(T1_X_train)\n",
    "            Total_X_test = T0_X_test.append(T1_X_test)\n",
    "            Total_X_val = T0_X_val.append(T1_X_val)\n",
    "            Total_y_val = T0_y_val.append(T1_y_val)\n",
    "            Total_y_train = T0_y_train.append(T1_y_train)\n",
    "            Total_y_test = T0_y_test.append(T1_y_test)\n",
    "\n",
    "            T0_model = CatBoostRegressor(iterations=250,verbose=False,use_best_model=True)\n",
    "            T0_model.fit(T0_X_train,T0_y_train,eval_set=(T0_X_val,T0_y_val))\n",
    "\n",
    "            T1_model = CatBoostRegressor(iterations=250,verbose=False,use_best_model=True)\n",
    "            T1_model.fit(T1_X_train,T1_y_train,eval_set=(T1_X_val,T1_y_val))\n",
    "\n",
    "            ITE = T1_model.predict(Total_X_test)-T0_model.predict(Total_X_test)\n",
    "            train_ITE = T1_model.predict(Total_X_train)-T0_model.predict(Total_X_train)\n",
    "\n",
    "            T1_explainer = shap.TreeExplainer(T1_model)\n",
    "            #T1_shap_values = T1_explainer.shap_values(Total_X_test)\n",
    "            T1_shap_values = T1_explainer.shap_values(Total_X_val)\n",
    "\n",
    "            T0_explainer = shap.TreeExplainer(T0_model)\n",
    "            #T0_shap_values = T0_explainer.shap_values(Total_X_test)\n",
    "            T0_shap_values = T0_explainer.shap_values(Total_X_val)\n",
    "\n",
    "            if len(T0_shap_values_ar)>0:\n",
    "                T0_shap_values_ar = np.vstack([T0_shap_values_ar,T0_shap_values])\n",
    "                T1_shap_values_ar = np.vstack([T1_shap_values_ar,T1_shap_values])\n",
    "                #T1_X_shap_ar = np.vstack([T1_X_shap_ar,Total_X_test])\n",
    "                #T0_X_shap_ar = np.vstack([T0_X_shap_ar,Total_X_test])\n",
    "                T1_X_shap_ar = np.vstack([T1_X_shap_ar,Total_X_val])\n",
    "                T0_X_shap_ar = np.vstack([T0_X_shap_ar,Total_X_val])\n",
    "            else:\n",
    "                T0_shap_values_ar = T0_shap_values\n",
    "                T1_shap_values_ar = T1_shap_values\n",
    "                #T1_X_shap_ar = Total_X_test\n",
    "                #T0_X_shap_ar = Total_X_test\n",
    "                T1_X_shap_ar = Total_X_val\n",
    "                T0_X_shap_ar = Total_X_val\n",
    "\n",
    "            T1_shap_values = np.abs(T1_shap_values)\n",
    "            T0_shap_values = np.abs(T0_shap_values)\n",
    "\n",
    "            shap_diff_ar = np.mean(T1_shap_values-T0_shap_values+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "            if len(shap_difs)>0:\n",
    "                shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "                T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "                T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "            else:\n",
    "                shap_difs = shap_diff_ar\n",
    "                T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "                T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "\n",
    "        pehes.append(normalized_epsilon_PEHE(np.append(X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y_1.values,X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y_1.values)\n",
    "                                  ,np.append(X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y_0.values,X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y_0.values)\n",
    "                                  ,ITE))\n",
    "        train_pehes.append(normalized_epsilon_PEHE(np.append(X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y_1.values,X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y_1.values)\n",
    "                                  ,np.append(X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y_0.values,X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y_0.values)\n",
    "                                        ,train_ITE))\n",
    "\n",
    "        mean_ITEs.append(np.mean(ITE))\n",
    "        std_ITEs.append(np.std(ITE))\n",
    "        train_mean_ITEs.append(np.mean(train_ITE))\n",
    "        train_std_ITEs.append(np.std(train_ITE))\n",
    "\n",
    "\n",
    "    #it does not matter which column array I pick, they all have the same\n",
    "    if S_learner:\n",
    "        shap_difs_pd = pd.DataFrame(data=shap_difs,columns=columns_list_current)\n",
    "        T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=columns_list_current)\n",
    "        T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=columns_list_current)\n",
    "    else:\n",
    "        shap_difs_pd = pd.DataFrame(data=shap_difs,columns=columns_list_current) \n",
    "        T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=columns_list_current) \n",
    "        T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=columns_list_current) \n",
    "\n",
    "    ########################################################################################################################################################   \n",
    "    ## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "    p_values = []\n",
    "    for i in range(len(shap_difs_pd.columns)):\n",
    "        quantile = p_values_null_coef(np.array(shap_difs_pd.values[:,i]))/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    processed_shap_diff_pd = pd.DataFrame(data=np.hstack([np.reshape(shap_difs_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_shap\",\"p_value\"],index=shap_difs_pd.mean().index)\n",
    "    processed_shap_diff_pd = processed_shap_diff_pd.reindex(processed_shap_diff_pd.mean_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "    ## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "    p_values = []\n",
    "    effect_size = []\n",
    "    power_list = []\n",
    "    required_iterations = []\n",
    "    power_alpha=0.01\n",
    "    n_samples = len(T0_shaps_pd[\"random_uniform_feature\"].values)\n",
    "    for i in range(len(T0_shaps_pd.columns)):\n",
    "        if shap_prognost_predict:\n",
    "            mean_random_uniform = T0_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "            quantile = p_values_arg_coef(np.array(T0_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "            p_value = quantile\n",
    "            pooled_standard_deviation = np.sqrt(\n",
    "                (\n",
    "                    (T0_shaps_pd.std()[i] ** 2) * (n_samples - 1)\n",
    "                    + (n_samples - 1)\n",
    "                    * (T0_shaps_pd[\"random_uniform_feature\"].values.std() ** 2)\n",
    "                )\n",
    "                / (n_samples * 2 - 2)\n",
    "            )\n",
    "            effect_size.append(\n",
    "                (np.abs(T0_shaps_pd.mean()[i] - mean_random_uniform))\n",
    "                / pooled_standard_deviation\n",
    "            )\n",
    "            power_list.append(\n",
    "                TTestPower().power(\n",
    "                    effect_size=effect_size[-1],\n",
    "                    nobs=n_samples,\n",
    "                    alpha=power_alpha,\n",
    "                    df=None,\n",
    "                    alternative=\"larger\",\n",
    "                )\n",
    "            )\n",
    "            if T0_shaps_pd.columns[i] == \"random_uniform_feature\":\n",
    "                required_iterations.append(0)\n",
    "            else:\n",
    "                required_iterations.append(\n",
    "                    TTestPower().solve_power(\n",
    "                        effect_size=effect_size[-1],\n",
    "                        nobs=None,\n",
    "                        alpha=power_alpha,\n",
    "                        power=0.95,\n",
    "                        alternative=\"larger\",\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            quantile = p_values_null_coef(np.array(T0_shaps_pd.values[:,i]))/100\n",
    "            if quantile > 0.5:\n",
    "                p_value = 1-quantile\n",
    "            else:\n",
    "                p_value = quantile\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    processed_T0_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T0_shaps_pd.mean().values,(-1,1)),\n",
    "                                                         np.reshape(np.array(p_values),(len(p_values),1)),\n",
    "                                                        np.reshape(np.array(effect_size), (len(effect_size), 1)),\n",
    "                                                        np.reshape(np.array(power_list), (len(power_list), 1)),\n",
    "                                                        np.reshape(\n",
    "                                                            np.array(required_iterations), (len(required_iterations), 1)\n",
    "                                                        ),]),\n",
    "                                         columns=[\"mean_absolute_shap\",\"p_value\",\"effect_size\",\"power\",\"req_iterations\"],index=T0_shaps_pd.mean().index)\n",
    "    processed_T0_shaps_pd = processed_T0_shaps_pd.reindex(processed_T0_shaps_pd.mean_absolute_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "    ## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "    p_values = []\n",
    "    for i in range(len(T1_shaps_pd.columns)):\n",
    "        if shap_prognost_predict:\n",
    "            mean_random_uniform = T1_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "            quantile = p_values_arg_coef(np.array(T1_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "            p_value = quantile\n",
    "        else:\n",
    "            quantile = p_values_null_coef(np.array(T1_shaps_pd.values[:,i]))/100\n",
    "            if quantile > 0.5:\n",
    "                p_value = 1-quantile\n",
    "            else:\n",
    "                p_value = quantile\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    processed_T1_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T1_shaps_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=T1_shaps_pd.mean().index)\n",
    "    processed_T1_shaps_pd = processed_T1_shaps_pd.reindex(processed_T1_shaps_pd.mean_absolute_shap.abs().sort_values(ascending=False).index)\n",
    "    ########################################################################################################################################################   \n",
    "\n",
    "    ## RESULT PRINTING\n",
    "    print(\"\")       \n",
    "    print(\"TRAINING SET\")\n",
    "    quantile = p_values_null_coef(np.array(train_mean_ITEs))/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "\n",
    "    print(tabulate([[str(np.round(np.mean(train_pehes),5))+\" (+-\"+str(np.round(np.std(train_pehes),5))+\")\",str(np.round(np.mean(train_mean_ITEs),5))+\" (+-\"+str(np.round(np.std(train_mean_ITEs),5))+\")\",str(np.round(np.mean(train_std_ITEs),5))+\" (+-\"+str(np.round(np.std(train_std_ITEs),5))+\")\",p_value]], [\"PEHE (std)\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))\n",
    "\n",
    "    print(\"\")       \n",
    "    print(\"TEST SET\")\n",
    "    quantile = p_values_null_coef(np.array(mean_ITEs))/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "\n",
    "    print(tabulate([[str(np.round(np.mean(pehes),5))+\" (+-\"+str(np.round(np.std(pehes),5))+\")\", str(np.round(np.mean(mean_ITEs),5))+\" (+-\"+str(np.round(np.std(mean_ITEs),5))+\")\",str(np.round(np.mean(std_ITEs),5))+\" (+-\"+str(np.round(np.std(std_ITEs),5))+\")\",p_value]], [\"PEHE (std)\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))\n",
    "    \n",
    "    for i in range(p):\n",
    "        print(\"feature: \"+str(columns_list_current[i]))\n",
    "        print(\"p-value: \"+str(stats.kstest(T1_shaps[:,i],T0_shaps[:,i])[1] ))\n",
    "        print(50*\"=\")\n",
    "    \n",
    "    processed_T1_shaps_pd[processed_T1_shaps_pd.p_value<0.05]\n",
    "    processed_T0_shaps_pd[processed_T0_shaps_pd.p_value<0.05]\n",
    "    processed_shap_diff_pd[processed_shap_diff_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(T1_shap_values_ar[:,list(idx[0])],density=True,label=\"T1\")\n",
    "plt.hist(T0_shap_values_ar[:,list(idx[0])],density=True,label=\"T0\",alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs(T1_shap_values_ar[:,list(idx[0])]),density=True,label=\"T1\")\n",
    "plt.hist(np.abs(T0_shap_values_ar[:,list(idx[0])]),density=True,label=\"T0\",alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(np.isin(columns_list_current,\"T\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(T1_shap_values_ar[:,list(idx[0])],density=True,label=\"T1\")\n",
    "plt.hist(T0_shap_values_ar[:,list(idx[0])],density=True,label=\"T0\",alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs(T1_shap_values_ar[:,list(idx[0])]),density=True,label=\"T1\")\n",
    "plt.hist(np.abs(T0_shap_values_ar[:,list(idx[0])]),density=True,label=\"T0\",alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "#@activationFunction: \"relu\",\"tanh\",\"sigmoid\"\n",
    "class NN_model(tf.keras.Model):\n",
    "    def __init__(self,Layer_structure,activationFunction=\"relu\"):\n",
    "        super(NN_model,self).__init__()\n",
    "\n",
    "        ff_shape = len(Layer_structure)\n",
    "        \n",
    "        self.ff_layers = []\n",
    "\n",
    "        for ff_layer_i in range(ff_shape):\n",
    "            self.ff_layers.append(tf.keras.layers.Dense(Layer_structure[ff_layer_i], name=\"ff_layer_\"+str(ff_layer_i) ,activation=activationFunction))\n",
    "\n",
    "        self.y = tf.keras.layers.Dense(1, activation=\"linear\",name=\"final_layer\")\n",
    "\n",
    "    def call(self,inputs):\n",
    "        ffik = self.ff_layers[0](inputs)\n",
    "        for ff_layer in self.ff_layers[1:]:\n",
    "            ffik = ff_layer(ffik)\n",
    "\n",
    "        return self.y(ffik)\n",
    "\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        return self.call(inputs)\n",
    "    \n",
    "#@activationFunction: \"relu\",\"tanh\",\"sigmoid\"\n",
    "def NN_model(NNinputs,Layer_structure,activationFunction=\"relu\"):\n",
    "    #pass the input into the first layer\n",
    "\n",
    "    ffik = tf.keras.layers.Dense(Layer_structure[0], activation=activationFunction)(NNinputs)\n",
    "    ffiks = [ffik]\n",
    "    for ff_layer_i in range(len(Layer_structure)-1):\n",
    "            ffiks.append(tf.keras.layers.Dense(Layer_structure[ff_layer_i+1], activation=activationFunction)(ffiks[-1]))\n",
    "\n",
    "    y = tf.keras.layers.Dense(1, activation=\"linear\",name=\"final_layer\")(ffiks[-1])\n",
    "\n",
    "    model = tf.keras.Model(inputs=NNinputs, outputs=y, name=\"NN_model\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001 #0.001#25\n",
    "DECAY = 0.99\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 256 #256 #2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:235: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [3:38:41<00:00, 65.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING SET\n",
      "+---------------------+---------------------+---------------------+---------------------+\n",
      "| PEHE (std)          | ATE (std)           | STD ITE (std)       |   p-Value Treatment |\n",
      "+=====================+=====================+=====================+=====================+\n",
      "| 0.00451 (+-0.00027) | 0.43891 (+-0.01774) | 0.03798 (+-0.00915) |                   0 |\n",
      "+---------------------+---------------------+---------------------+---------------------+\n",
      "\n",
      "TEST SET\n",
      "+---------------------+---------------------+--------------------+---------------------+\n",
      "| PEHE (std)          | ATE (std)           | STD ITE (std)      |   p-Value Treatment |\n",
      "+=====================+=====================+====================+=====================+\n",
      "| 0.00524 (+-0.00056) | 0.43708 (+-0.01767) | 0.03988 (+-0.0093) |                   0 |\n",
      "+---------------------+---------------------+--------------------+---------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 5000 # 5000 or 800\n",
    "p = 300 #number of candidate biomarkers\n",
    "iterations = 200\n",
    "case = M1\n",
    "S_learner = True\n",
    "shap_prognost_predict = True\n",
    "\n",
    "layer_structure = [128,64,32]\n",
    "\n",
    "pehes = []\n",
    "train_pehes = []\n",
    "mean_ITEs = []\n",
    "std_ITEs = []\n",
    "train_std_ITEs = []\n",
    "train_mean_ITEs = []\n",
    "shap_difs = np.array([])\n",
    "T0_shaps = np.array([])\n",
    "T0_shap_values_ar = np.array([])\n",
    "T1_shaps  = np.array([])\n",
    "T1_shap_values_ar = np.array([])\n",
    "T1_X_shap_ar = np.array([])\n",
    "T0_X_shap_ar = np.array([])\n",
    "\n",
    "columns_list = []\n",
    "for i in range(p):\n",
    "    columns_list.append(\"x\"+str(i+1))\n",
    "\n",
    "columns_list_with_random = columns_list+[\"random_uniform_feature\"]\n",
    "\n",
    "npRandomState_or = RandomState(42)\n",
    "\n",
    "normal_mean = 0.5 #npRandomState_or.uniform(-1,1,1) #1#0 #np.pi\n",
    "x_features = np.array([])\n",
    "for i in range(p):\n",
    "    if len(x_features)>0:\n",
    "        x_features = np.vstack([x_features,npRandomState_or.normal(normal_mean,1,N)])\n",
    "    else:\n",
    "        x_features = npRandomState_or.normal(normal_mean,1,N)\n",
    "\n",
    "x_features = np.transpose(x_features)\n",
    "\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    npRandomState = RandomState(i)\n",
    "    \n",
    "    treatment_assignment = npRandomState.randint(0,2,N)\n",
    "    random_uniform_feature = npRandomState.normal(0,1,N)#npRandomState.uniform(-1,1,N)\n",
    "\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y = case(treatment_assignment,x_features,N,npRandomState_or)\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y_0 = case(np.zeros(N),x_features,N,npRandomState_or)\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y_1 = case(np.zeros(N)+1,x_features,N,npRandomState_or)\n",
    "    \n",
    "    X_df = pd.DataFrame(data=x_features,columns=columns_list)\n",
    "    X_df = X_df.reset_index()\n",
    "    X_df[\"y\"]=y\n",
    "    X_df[\"y_0\"]=y_0\n",
    "    X_df[\"y_1\"]=y_1\n",
    "    X_df[\"T\"]=treatment_assignment\n",
    "    X_df[\"random_uniform_feature\"]=random_uniform_feature\n",
    "    \n",
    "    #indices_temp = X_df[\"index\"].values\n",
    "    #scaler = MinMaxScaler()\n",
    "    #scaler.fit(X_df)\n",
    "    #X_df = pd.DataFrame(data=scaler.transform(X_df),columns=X_df.columns)\n",
    "    #X_df.loc[:,\"index\"]=indices_temp\n",
    "    \n",
    "    if S_learner:\n",
    "        columns_list_current = columns_list_with_random + [\"T\"]\n",
    "    else: \n",
    "        columns_list_current = columns_list_with_random\n",
    "    \n",
    "    train_index,test_index = train_test_split(X_df[\"index\"].values,test_size=0.2,random_state=i,stratify=X_df[\"T\"])\n",
    "    train_index,val_index = train_test_split(train_index,test_size=0.2,random_state=i,stratify=X_df[X_df[\"index\"].isin(train_index)][\"T\"])\n",
    "    \n",
    "    T0_X_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "    T0_X_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "    T0_X_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "    T1_X_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "    T1_X_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "    T1_X_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "    \n",
    "    T0_y_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y\n",
    "    T0_y_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==0)].y\n",
    "    T0_y_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y\n",
    "    T1_y_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y\n",
    "    T1_y_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==1)].y\n",
    "    T1_y_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y\n",
    "    \n",
    "    \n",
    "    if S_learner:\n",
    "        S_X_train = T0_X_train.append(T1_X_train).sample(len(T0_X_train)+len(T1_X_train),replace=False,random_state=i)\n",
    "        S_X_train_T1 = S_X_train.copy(deep=True)\n",
    "        S_X_train_T1.loc[:,\"T\"] = 1\n",
    "        S_X_train_T0 = S_X_train.copy(deep=True)\n",
    "        S_X_train_T0.loc[:,\"T\"] = 0\n",
    "        \n",
    "        S_X_val = T0_X_val.append(T1_X_val)\n",
    "        S_X_val_T1 = S_X_val.copy(deep=True)\n",
    "        S_X_val_T1.loc[:,\"T\"] = 1\n",
    "        S_X_val_T0 = S_X_val.copy(deep=True)\n",
    "        S_X_val_T0.loc[:,\"T\"] = 0\n",
    "        \n",
    "        S_X_test = T0_X_test.append(T1_X_test)\n",
    "        S_X_test_T1 = S_X_test.copy(deep=True)\n",
    "        S_X_test_T1.loc[:,\"T\"] = 1\n",
    "        S_X_test_T0 = S_X_test.copy(deep=True)\n",
    "        S_X_test_T0.loc[:,\"T\"] = 0\n",
    "        \n",
    "        S_y_train = T0_y_train.append(T1_y_train).sample(len(T0_X_train)+len(T1_X_train),replace=False,random_state=i)\n",
    "        S_y_val = T0_y_val.append(T1_y_val)\n",
    "        S_y_test = T0_y_test.append(T1_y_test)\n",
    "        \n",
    "        \n",
    "        S_model = NN_model(tf.keras.Input(shape=(np.shape(S_X_train.values)[1],)),layer_structure,\"relu\")#best_params['Flayer'],best_params['Slayer'],best_params['Tlayer'],\"relu\")#128,64,64\n",
    "        S_model.compile(\n",
    "            loss=\"MSE\",\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=DECAY),\n",
    "            metrics=[tf.keras.metrics.MeanSquaredError()], \n",
    "        )\n",
    "        S_model.fit(S_X_train.values,S_y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS, validation_data=(S_X_val.values,S_y_val),verbose=0)#, callbacks=[TqdmCallback(verbose=0)])\n",
    "        \n",
    "        ITE = S_model.predict(S_X_test_T1.values)-S_model.predict(S_X_test_T0.values)\n",
    "        train_ITE = S_model.predict(S_X_train_T1.values)-S_model.predict(S_X_train_T0.values)\n",
    "\n",
    "        C_explainer = shap.DeepExplainer(S_model,S_X_train.values)\n",
    "        #T1_shap_values = C_explainer.shap_values(S_X_test_T1)\n",
    "        #T0_shap_values = C_explainer.shap_values(S_X_test_T0)\n",
    "        T1_shap_values = C_explainer.shap_values(S_X_val_T1.values)[0]\n",
    "        T0_shap_values = C_explainer.shap_values(S_X_val_T0.values)[0]\n",
    "        \n",
    "        if len(T0_shap_values_ar)>0:\n",
    "            T0_shap_values_ar = np.vstack([T0_shap_values_ar,T0_shap_values])\n",
    "            T1_shap_values_ar = np.vstack([T1_shap_values_ar,T1_shap_values])\n",
    "            #T1_X_shap_ar = np.vstack([T1_X_shap_ar,S_X_test_T1])\n",
    "            #T0_X_shap_ar = np.vstack([T0_X_shap_ar,S_X_test_T0])\n",
    "            T1_X_shap_ar = np.vstack([T1_X_shap_ar,S_X_val_T1])\n",
    "            T0_X_shap_ar = np.vstack([T0_X_shap_ar,S_X_val_T0])\n",
    "        else:\n",
    "            T0_shap_values_ar = T0_shap_values\n",
    "            T1_shap_values_ar = T1_shap_values\n",
    "            #T1_X_shap_ar = S_X_test_T1\n",
    "            #T0_X_shap_ar = S_X_test_T0\n",
    "            T1_X_shap_ar = S_X_val_T1\n",
    "            T0_X_shap_ar = S_X_val_T0\n",
    "\n",
    "        #T1_shap_values = np.abs(T1_shap_values)\n",
    "        #T0_shap_values = np.abs(T0_shap_values)\n",
    "        \n",
    "        ## includes predictive features, but not for features where the CATE = 0 but there is a large ITE (such as sinus)\n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "        \n",
    "        ## includes all relevant features\n",
    "        #shap_diff_ar = np.mean(np.abs(T1_shap_values-T0_shap_values)+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "        \n",
    "        T1_shap_values = np.abs(T1_shap_values)\n",
    "        T0_shap_values = np.abs(T0_shap_values)\n",
    "        \n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "            T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "            T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "            T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "            T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "        \n",
    "    else:\n",
    "        Total_X_train = T0_X_train.append(T1_X_train)\n",
    "        Total_X_test = T0_X_test.append(T1_X_test)\n",
    "        Total_X_val = T0_X_val.append(T1_X_val)\n",
    "        Total_y_val = T0_y_val.append(T1_y_val)\n",
    "        Total_y_train = T0_y_train.append(T1_y_train)\n",
    "        Total_y_test = T0_y_test.append(T1_y_test)\n",
    "\n",
    "        T0_model = NN_model(tf.keras.Input(shape=(np.shape(T0_X_train.values)[1],)),layer_structure,\"relu\")#best_params['Flayer'],best_params['Slayer'],best_params['Tlayer'],\"relu\")#128,64,64\n",
    "        T0_model.compile(\n",
    "            loss=\"MSE\",\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=DECAY),\n",
    "            metrics=[tf.keras.metrics.MeanSquaredError()], \n",
    "        )\n",
    "        T0_model.fit(T0_X_train.values,T0_y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS, validation_data=(T0_X_val.values,T0_y_val),verbose=0)#, callbacks=[TqdmCallback(verbose=1)])\n",
    "        \n",
    "        T1_model = NN_model(tf.keras.Input(shape=(np.shape(T1_X_train.values)[1],)),layer_structure,\"relu\")#best_params['Flayer'],best_params['Slayer'],best_params['Tlayer'],\"relu\")#128,64,64\n",
    "        T1_model.compile(\n",
    "            loss=\"MSE\",\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=DECAY),\n",
    "            metrics=[tf.keras.metrics.MeanSquaredError()], \n",
    "        )\n",
    "        T1_model.fit(T1_X_train.values,T1_y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS, validation_data=(T1_X_val.values,T1_y_val),verbose=0)#, callbacks=[TqdmCallback(verbose=1)])\n",
    "        \n",
    "        ITE = T1_model.predict(Total_X_test.values)-T0_model.predict(Total_X_test.values)\n",
    "        train_ITE = T1_model.predict(Total_X_train.values)-T0_model.predict(Total_X_train.values)\n",
    "\n",
    "        T1_explainer = shap.DeepExplainer(T1_model,T1_X_train.values)\n",
    "        #T1_shap_values = T1_explainer.shap_values(Total_X_test)\n",
    "        T1_shap_values = T1_explainer.shap_values(Total_X_val.values)[0]\n",
    "        \n",
    "        T0_explainer = shap.DeepExplainer(T0_model,T0_X_train.values)\n",
    "        #T0_shap_values = T0_explainer.shap_values(Total_X_test)\n",
    "        T0_shap_values = T0_explainer.shap_values(Total_X_val.values)[0]\n",
    "            \n",
    "        if len(T0_shap_values_ar)>0:\n",
    "            T0_shap_values_ar = np.vstack([T0_shap_values_ar,T0_shap_values])\n",
    "            T1_shap_values_ar = np.vstack([T1_shap_values_ar,T1_shap_values])\n",
    "            #T1_X_shap_ar = np.vstack([T1_X_shap_ar,Total_X_test])\n",
    "            #T0_X_shap_ar = np.vstack([T0_X_shap_ar,Total_X_test])\n",
    "            T1_X_shap_ar = np.vstack([T1_X_shap_ar,Total_X_val])\n",
    "            T0_X_shap_ar = np.vstack([T0_X_shap_ar,Total_X_val])\n",
    "        else:\n",
    "            T0_shap_values_ar = T0_shap_values\n",
    "            T1_shap_values_ar = T1_shap_values\n",
    "            #T1_X_shap_ar = Total_X_test\n",
    "            #T0_X_shap_ar = Total_X_test\n",
    "            T1_X_shap_ar = Total_X_val\n",
    "            T0_X_shap_ar = Total_X_val\n",
    "        \n",
    "        T1_shap_values = np.abs(T1_shap_values)\n",
    "        T0_shap_values = np.abs(T0_shap_values)\n",
    "        \n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "            T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "            T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "            T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "            T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "            \n",
    "    pehes.append(normalized_epsilon_PEHE(np.append(X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y_1.values,X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y_1.values)\n",
    "                              ,np.append(X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y_0.values,X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y_0.values)\n",
    "                              ,ITE[:,0]))\n",
    "    train_pehes.append(normalized_epsilon_PEHE(np.append(X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y_1.values,X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y_1.values)\n",
    "                              ,np.append(X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y_0.values,X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y_0.values)\n",
    "                                    ,train_ITE[:,0]))\n",
    "            \n",
    "    mean_ITEs.append(np.mean(ITE))\n",
    "    std_ITEs.append(np.std(ITE))\n",
    "    train_mean_ITEs.append(np.mean(train_ITE))\n",
    "    train_std_ITEs.append(np.std(train_ITE))\n",
    "    \n",
    "\n",
    "#it does not matter which column array I pick, they all have the same\n",
    "if S_learner:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=columns_list_current)\n",
    "    T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=columns_list_current)\n",
    "    T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=columns_list_current)\n",
    "else:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=columns_list_current) \n",
    "    T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=columns_list_current) \n",
    "    T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=columns_list_current) \n",
    "    \n",
    "########################################################################################################################################################   \n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(shap_difs_pd.columns)):\n",
    "    quantile = p_values_null_coef(np.array(shap_difs_pd.values[:,i]))/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_shap_diff_pd = pd.DataFrame(data=np.hstack([np.reshape(shap_difs_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_shap\",\"p_value\"],index=shap_difs_pd.mean().index)\n",
    "processed_shap_diff_pd = processed_shap_diff_pd.reindex(processed_shap_diff_pd.mean_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(T0_shaps_pd.columns)):\n",
    "    if shap_prognost_predict:\n",
    "        mean_random_uniform = T0_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "        quantile = p_values_arg_coef(np.array(T0_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "        p_value = quantile\n",
    "    else:\n",
    "        quantile = p_values_null_coef(np.array(T0_shaps_pd.values[:,i]))/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_T0_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T0_shaps_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=T0_shaps_pd.mean().index)\n",
    "processed_T0_shaps_pd = processed_T0_shaps_pd.reindex(processed_T0_shaps_pd.mean_absolute_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(T1_shaps_pd.columns)):\n",
    "    if shap_prognost_predict:\n",
    "        mean_random_uniform = T1_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "        quantile = p_values_arg_coef(np.array(T1_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "        p_value = quantile\n",
    "    else:\n",
    "        quantile = p_values_null_coef(np.array(T1_shaps_pd.values[:,i]))/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_T1_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T1_shaps_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=T1_shaps_pd.mean().index)\n",
    "processed_T1_shaps_pd = processed_T1_shaps_pd.reindex(processed_T1_shaps_pd.mean_absolute_shap.abs().sort_values(ascending=False).index)\n",
    "########################################################################################################################################################   \n",
    "\n",
    "## RESULT PRINTING\n",
    "print(\"\")       \n",
    "print(\"TRAINING SET\")\n",
    "quantile = p_values_null_coef(np.array(train_mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[str(np.round(np.mean(train_pehes),5))+\" (+-\"+str(np.round(np.std(train_pehes),5))+\")\",str(np.round(np.mean(train_mean_ITEs),5))+\" (+-\"+str(np.round(np.std(train_mean_ITEs),5))+\")\",str(np.round(np.mean(train_std_ITEs),5))+\" (+-\"+str(np.round(np.std(train_std_ITEs),5))+\")\",p_value]], [\"PEHE (std)\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))\n",
    "    \n",
    "print(\"\")       \n",
    "print(\"TEST SET\")\n",
    "quantile = p_values_null_coef(np.array(mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[str(np.round(np.mean(pehes),5))+\" (+-\"+str(np.round(np.std(pehes),5))+\")\", str(np.round(np.mean(mean_ITEs),5))+\" (+-\"+str(np.round(np.std(mean_ITEs),5))+\")\",str(np.round(np.mean(std_ITEs),5))+\" (+-\"+str(np.round(np.std(std_ITEs),5))+\")\",p_value]], [\"PEHE (std)\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_absolute_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>3.144911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>2.396399</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>2.376514</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>2.365746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>2.342088</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.221871</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_absolute_shap  p_value\n",
       "x1            3.144911      0.0\n",
       "x2            2.396399      0.0\n",
       "x4            2.376514      0.0\n",
       "x3            2.365746      0.0\n",
       "x5            2.342088      0.0\n",
       "T             0.221871      0.0\n",
       "x7            0.093994      0.0\n",
       "x8            0.090820      0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_T1_shaps_pd[processed_T1_shaps_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_absolute_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>3.144307</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>2.395781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>2.375899</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>2.365166</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>2.341476</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.221868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>0.093667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_absolute_shap  p_value\n",
       "x1            3.144307      0.0\n",
       "x2            2.395781      0.0\n",
       "x4            2.375899      0.0\n",
       "x3            2.365166      0.0\n",
       "x5            2.341476      0.0\n",
       "T             0.221868      0.0\n",
       "x7            0.093667      0.0\n",
       "x8            0.090500      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_T0_shaps_pd[processed_T0_shaps_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_shap_diff_pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0176cd106d33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_shap_diff_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprocessed_shap_diff_pd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_value\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'processed_shap_diff_pd' is not defined"
     ]
    }
   ],
   "source": [
    "processed_shap_diff_pd[processed_shap_diff_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:46<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING SET\n",
      "+---------------------+----------------------+-----------------+---------------------+\n",
      "| PEHE (std)          | ATE (std)            | STD ITE (std)   |   p-Value Treatment |\n",
      "+=====================+======================+=================+=====================+\n",
      "| 0.01778 (+-0.00104) | -0.25524 (+-0.03215) | 0.0 (+-0.0)     |                   0 |\n",
      "+---------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "TEST SET\n",
      "+--------------------+----------------------+-----------------+---------------------+\n",
      "| PEHE (std)         | ATE (std)            | STD ITE (std)   |   p-Value Treatment |\n",
      "+====================+======================+=================+=====================+\n",
      "| 0.02195 (+-0.0021) | -0.25524 (+-0.03215) | 0.0 (+-0.0)     |                   0 |\n",
      "+--------------------+----------------------+-----------------+---------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 5000 # 5000 or 800\n",
    "p = 100 #number of candidate biomarkers\n",
    "iterations = 200\n",
    "case = M12\n",
    "S_learner = True\n",
    "shap_prognost_predict = True\n",
    "\n",
    "pehes = []\n",
    "train_pehes = []\n",
    "mean_ITEs = []\n",
    "std_ITEs = []\n",
    "train_std_ITEs = []\n",
    "train_mean_ITEs = []\n",
    "shap_difs = np.array([])\n",
    "T0_shaps = np.array([])\n",
    "T0_shap_values_ar = np.array([])\n",
    "T1_shaps  = np.array([])\n",
    "T1_shap_values_ar = np.array([])\n",
    "T1_X_shap_ar = np.array([])\n",
    "T0_X_shap_ar = np.array([])\n",
    "\n",
    "columns_list = []\n",
    "for i in range(p):\n",
    "    columns_list.append(\"x\"+str(i+1))\n",
    "\n",
    "columns_list_with_random = columns_list+[\"random_uniform_feature\"]\n",
    "\n",
    "npRandomState_or = RandomState(42)\n",
    "\n",
    "normal_mean = npRandomState_or.uniform(-1,1,1) #1#0 #np.pi\n",
    "x_features = np.array([])\n",
    "for i in range(p):\n",
    "    if len(x_features)>0:\n",
    "        x_features = np.vstack([x_features,npRandomState_or.normal(normal_mean,1,N)])\n",
    "    else:\n",
    "        x_features = npRandomState_or.normal(normal_mean,1,N)\n",
    "\n",
    "x_features = np.transpose(x_features)\n",
    "\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    npRandomState = RandomState(i)\n",
    "    \n",
    "    treatment_assignment = npRandomState.randint(0,2,N)\n",
    "    random_uniform_feature = npRandomState.normal(0,1,N)#uniform(-1,1,N)\n",
    "\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y = case(treatment_assignment,x_features,N,npRandomState_or)\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y_0 = case(np.zeros(N),x_features,N,npRandomState_or)\n",
    "    npRandomState_or = RandomState(42)\n",
    "    y_1 = case(np.zeros(N)+1,x_features,N,npRandomState_or)\n",
    "    \n",
    "    X_df = pd.DataFrame(data=x_features,columns=columns_list)\n",
    "    X_df = X_df.reset_index()\n",
    "    X_df[\"y\"]=y\n",
    "    X_df[\"y_0\"]=y_0\n",
    "    X_df[\"y_1\"]=y_1\n",
    "    X_df[\"T\"]=treatment_assignment\n",
    "    X_df[\"random_uniform_feature\"]=random_uniform_feature\n",
    "    \n",
    "    #indices_temp = X_df[\"index\"].values\n",
    "    #scaler = MinMaxScaler()\n",
    "    #scaler.fit(X_df)\n",
    "    #X_df = pd.DataFrame(data=scaler.transform(X_df),columns=X_df.columns)\n",
    "    #X_df.loc[:,\"index\"]=indices_temp\n",
    "    \n",
    "    if S_learner:\n",
    "        columns_list_current = columns_list_with_random + [\"T\"]\n",
    "    else: \n",
    "        columns_list_current = columns_list_with_random\n",
    "    \n",
    "    train_index,test_index = train_test_split(X_df[\"index\"].values,test_size=0.1,random_state=i,stratify=X_df[\"T\"])\n",
    "    #print(len(train_index))\n",
    "    train_index,val_index = train_test_split(train_index,test_size=0.2,random_state=i,stratify=X_df[X_df[\"index\"].isin(train_index)][\"T\"])\n",
    "    #print(len(train_index))\n",
    "    \n",
    "    T0_X_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "    T0_X_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "    T0_X_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)][columns_list_current]\n",
    "    T1_X_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "    T1_X_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "    T1_X_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)][columns_list_current]\n",
    "    \n",
    "    T0_y_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y\n",
    "    T0_y_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==0)].y\n",
    "    T0_y_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y\n",
    "    T1_y_train = X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y\n",
    "    T1_y_val = X_df[(X_df[\"index\"].isin(val_index))&(X_df[\"T\"]==1)].y\n",
    "    T1_y_test = X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y\n",
    "    \n",
    "    \n",
    "    if S_learner:\n",
    "        S_X_train = T0_X_train.append(T1_X_train)\n",
    "        S_X_train_T1 = S_X_train.copy(deep=True)\n",
    "        S_X_train_T1.loc[:,\"T\"] = 1\n",
    "        S_X_train_T0 = S_X_train.copy(deep=True)\n",
    "        S_X_train_T0.loc[:,\"T\"] = 0\n",
    "        \n",
    "        S_X_val = T0_X_val.append(T1_X_val)\n",
    "        S_X_val_T1 = S_X_val.copy(deep=True)\n",
    "        S_X_val_T1.loc[:,\"T\"] = 1\n",
    "        S_X_val_T0 = S_X_val.copy(deep=True)\n",
    "        S_X_val_T0.loc[:,\"T\"] = 0\n",
    "        \n",
    "        S_X_test = T0_X_test.append(T1_X_test)\n",
    "        S_X_test_T1 = S_X_test.copy(deep=True)\n",
    "        S_X_test_T1.loc[:,\"T\"] = 1\n",
    "        S_X_test_T0 = S_X_test.copy(deep=True)\n",
    "        S_X_test_T0.loc[:,\"T\"] = 0\n",
    "        \n",
    "        S_y_train = T0_y_train.append(T1_y_train)\n",
    "        S_y_val = T0_y_val.append(T1_y_val)\n",
    "        S_y_test = T0_y_test.append(T1_y_test)\n",
    "        \n",
    "        S_model = Pipeline(\n",
    "        [\n",
    "            (\"scale\", RobustScaler()),\n",
    "            (\"model\", Ridge(alpha=0.1)),\n",
    "        ])\n",
    "        \n",
    "        #S_model = Ridge()\n",
    "        S_model.fit(S_X_train,S_y_train)\n",
    "        \n",
    "        ITE = S_model.predict(S_X_test_T1)-S_model.predict(S_X_test_T0)\n",
    "        train_ITE = S_model.predict(S_X_train_T1)-S_model.predict(S_X_train_T0)\n",
    "        \n",
    "        C_explainer = shap.explainers.Linear(S_model['model'],S_X_train)\n",
    "        #T1_shap_values = C_explainer.shap_values(S_X_test_T1)\n",
    "        #T0_shap_values = C_explainer.shap_values(S_X_test_T0)\n",
    "        T1_shap_values = C_explainer.shap_values(S_X_val_T1)\n",
    "        T0_shap_values = C_explainer.shap_values(S_X_val_T0)\n",
    "        \n",
    "        if len(T0_shap_values_ar)>0:\n",
    "            T0_shap_values_ar = np.vstack([T0_shap_values_ar,T0_shap_values])\n",
    "            T1_shap_values_ar = np.vstack([T1_shap_values_ar,T1_shap_values])\n",
    "            #T1_X_shap_ar = np.vstack([T1_X_shap_ar,S_X_test_T1])\n",
    "            #T0_X_shap_ar = np.vstack([T0_X_shap_ar,S_X_test_T0])\n",
    "            T1_X_shap_ar = np.vstack([T1_X_shap_ar,S_X_val_T1])\n",
    "            T0_X_shap_ar = np.vstack([T0_X_shap_ar,S_X_val_T0])\n",
    "        else:\n",
    "            T0_shap_values_ar = T0_shap_values\n",
    "            T1_shap_values_ar = T1_shap_values\n",
    "            #T1_X_shap_ar = S_X_test_T1\n",
    "            #T0_X_shap_ar = S_X_test_T0\n",
    "            T1_X_shap_ar = S_X_val_T1\n",
    "            T0_X_shap_ar = S_X_val_T0\n",
    "\n",
    "        #T1_shap_values = np.abs(T1_shap_values)\n",
    "        #T0_shap_values = np.abs(T0_shap_values)\n",
    "        \n",
    "        ## includes predictive features, but not for features where the CATE = 0 but there is a large ITE (such as sinus)\n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "        \n",
    "        ## includes all relevant features\n",
    "        #shap_diff_ar = np.mean(np.abs(T1_shap_values-T0_shap_values)+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "        \n",
    "        T1_shap_values = np.abs(T1_shap_values)\n",
    "        T0_shap_values = np.abs(T0_shap_values)\n",
    "        \n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "            T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "            T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "            T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "            T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "        \n",
    "    else:\n",
    "        Total_X_train = T0_X_train.append(T1_X_train)\n",
    "        Total_X_test = T0_X_test.append(T1_X_test)\n",
    "        Total_X_val = T0_X_val.append(T1_X_val)\n",
    "        Total_y_val = T0_y_val.append(T1_y_val)\n",
    "        Total_y_train = T0_y_train.append(T1_y_train)\n",
    "        Total_y_test = T0_y_test.append(T1_y_test)\n",
    "        \n",
    "        T0_model = Pipeline(\n",
    "        [\n",
    "            (\"scale\", RobustScaler()),\n",
    "            (\"model\", Ridge()),\n",
    "        ])\n",
    "        \n",
    "        T1_model = Pipeline(\n",
    "        [\n",
    "            (\"scale\", RobustScaler()),\n",
    "            (\"model\", Ridge()),\n",
    "        ])\n",
    "        \n",
    "        #S_model = Ridge()\n",
    "        T0_model.fit(T0_X_train,T0_y_train)\n",
    "        T1_model.fit(T1_X_train,T1_y_train)\n",
    "        \n",
    "        ITE = T1_model.predict(Total_X_test)-T0_model.predict(Total_X_test)\n",
    "        train_ITE = T1_model.predict(Total_X_train)-T0_model.predict(Total_X_train)\n",
    "\n",
    "        T1_explainer = shap.explainers.Linear(T1_model['model'],T1_X_train)\n",
    "        #T1_shap_values = T1_explainer.shap_values(Total_X_test)\n",
    "        T1_shap_values = T1_explainer.shap_values(Total_X_val)\n",
    "        \n",
    "        T0_explainer = shap.explainers.Linear(T0_model['model'],T0_X_train)\n",
    "        #T0_shap_values = T0_explainer.shap_values(Total_X_test)\n",
    "        T0_shap_values = T0_explainer.shap_values(Total_X_val)\n",
    "            \n",
    "        if len(T0_shap_values_ar)>0:\n",
    "            T0_shap_values_ar = np.vstack([T0_shap_values_ar,T0_shap_values])\n",
    "            T1_shap_values_ar = np.vstack([T1_shap_values_ar,T1_shap_values])\n",
    "            #T1_X_shap_ar = np.vstack([T1_X_shap_ar,Total_X_test])\n",
    "            #T0_X_shap_ar = np.vstack([T0_X_shap_ar,Total_X_test])\n",
    "            T1_X_shap_ar = np.vstack([T1_X_shap_ar,Total_X_val])\n",
    "            T0_X_shap_ar = np.vstack([T0_X_shap_ar,Total_X_val])\n",
    "        else:\n",
    "            T0_shap_values_ar = T0_shap_values\n",
    "            T1_shap_values_ar = T1_shap_values\n",
    "            #T1_X_shap_ar = Total_X_test\n",
    "            #T0_X_shap_ar = Total_X_test\n",
    "            T1_X_shap_ar = Total_X_val\n",
    "            T0_X_shap_ar = Total_X_val\n",
    "        \n",
    "        T1_shap_values = np.abs(T1_shap_values)\n",
    "        T0_shap_values = np.abs(T0_shap_values)\n",
    "        \n",
    "        shap_diff_ar = np.mean(T1_shap_values-T0_shap_values+np.abs(T1_shap_values)-np.abs(T0_shap_values),axis=0)\n",
    "        if len(shap_difs)>0:\n",
    "            shap_difs = np.vstack([shap_difs,shap_diff_ar])\n",
    "            T0_shaps = np.vstack([T0_shaps,np.mean(T0_shap_values,axis=0)])\n",
    "            T1_shaps = np.vstack([T1_shaps,np.mean(T1_shap_values,axis=0)])\n",
    "        else:\n",
    "            shap_difs = shap_diff_ar\n",
    "            T0_shaps = np.mean(T0_shap_values,axis=0)\n",
    "            T1_shaps = np.mean(T1_shap_values,axis=0)\n",
    "            \n",
    "    pehes.append(normalized_epsilon_PEHE(np.append(X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y_1.values,X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y_1.values)\n",
    "                              ,np.append(X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==0)].y_0.values,X_df[(X_df[\"index\"].isin(test_index))&(X_df[\"T\"]==1)].y_0.values)\n",
    "                              ,ITE))\n",
    "    train_pehes.append(normalized_epsilon_PEHE(np.append(X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y_1.values,X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y_1.values)\n",
    "                              ,np.append(X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==0)].y_0.values,X_df[(X_df[\"index\"].isin(train_index))&(X_df[\"T\"]==1)].y_0.values)\n",
    "                                    ,train_ITE))\n",
    "            \n",
    "    mean_ITEs.append(np.mean(ITE))\n",
    "    std_ITEs.append(np.std(ITE))\n",
    "    train_mean_ITEs.append(np.mean(train_ITE))\n",
    "    train_std_ITEs.append(np.std(train_ITE))\n",
    "    \n",
    "\n",
    "#it does not matter which column array I pick, they all have the same\n",
    "if S_learner:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=columns_list_current)\n",
    "    T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=columns_list_current)\n",
    "    T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=columns_list_current)\n",
    "else:\n",
    "    shap_difs_pd = pd.DataFrame(data=shap_difs,columns=columns_list_current) \n",
    "    T0_shaps_pd = pd.DataFrame(data=T0_shaps,columns=columns_list_current) \n",
    "    T1_shaps_pd = pd.DataFrame(data=T1_shaps,columns=columns_list_current) \n",
    "    \n",
    "########################################################################################################################################################   \n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(shap_difs_pd.columns)):\n",
    "    quantile = p_values_null_coef(np.array(shap_difs_pd.values[:,i]))/100\n",
    "    if quantile > 0.5:\n",
    "        p_value = 1-quantile\n",
    "    else:\n",
    "        p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_shap_diff_pd = pd.DataFrame(data=np.hstack([np.reshape(shap_difs_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_shap\",\"p_value\"],index=shap_difs_pd.mean().index)\n",
    "processed_shap_diff_pd = processed_shap_diff_pd.reindex(processed_shap_diff_pd.mean_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(T0_shaps_pd.columns)):\n",
    "    if shap_prognost_predict:\n",
    "        mean_random_uniform = T0_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "        quantile = p_values_arg_coef(np.array(T0_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "        p_value = quantile\n",
    "    else:\n",
    "        quantile = p_values_null_coef(np.array(T0_shaps_pd.values[:,i]))/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_T0_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T0_shaps_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=T0_shaps_pd.mean().index)\n",
    "processed_T0_shaps_pd = processed_T0_shaps_pd.reindex(processed_T0_shaps_pd.mean_absolute_shap.abs().sort_values(ascending=False).index)\n",
    "\n",
    "## SHAP VALUE DIFFERENCE ANALYSIS\n",
    "p_values = []\n",
    "for i in range(len(T1_shaps_pd.columns)):\n",
    "    if shap_prognost_predict:\n",
    "        mean_random_uniform = T1_shaps_pd[\"random_uniform_feature\"].values.mean()\n",
    "        quantile = p_values_arg_coef(np.array(T1_shaps_pd.values[:,i]),mean_random_uniform)/100\n",
    "        p_value = quantile\n",
    "    else:\n",
    "        quantile = p_values_null_coef(np.array(T1_shaps_pd.values[:,i]))/100\n",
    "        if quantile > 0.5:\n",
    "            p_value = 1-quantile\n",
    "        else:\n",
    "            p_value = quantile\n",
    "    p_values.append(p_value)\n",
    "    \n",
    "processed_T1_shaps_pd = pd.DataFrame(data=np.hstack([np.reshape(T1_shaps_pd.mean().values,(-1,1)),np.reshape(np.array(p_values),(len(p_values),1))]),columns=[\"mean_absolute_shap\",\"p_value\"],index=T1_shaps_pd.mean().index)\n",
    "processed_T1_shaps_pd = processed_T1_shaps_pd.reindex(processed_T1_shaps_pd.mean_absolute_shap.abs().sort_values(ascending=False).index)\n",
    "########################################################################################################################################################   \n",
    "\n",
    "## RESULT PRINTING\n",
    "print(\"\")       \n",
    "print(\"TRAINING SET\")\n",
    "quantile = p_values_null_coef(np.array(train_mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[str(np.round(np.mean(train_pehes),5))+\" (+-\"+str(np.round(np.std(train_pehes),5))+\")\",str(np.round(np.mean(train_mean_ITEs),5))+\" (+-\"+str(np.round(np.std(train_mean_ITEs),5))+\")\",str(np.round(np.mean(train_std_ITEs),5))+\" (+-\"+str(np.round(np.std(train_std_ITEs),5))+\")\",p_value]], [\"PEHE (std)\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))\n",
    "    \n",
    "print(\"\")       \n",
    "print(\"TEST SET\")\n",
    "quantile = p_values_null_coef(np.array(mean_ITEs))/100\n",
    "if quantile > 0.5:\n",
    "    p_value = 1-quantile\n",
    "else:\n",
    "    p_value = quantile\n",
    "\n",
    "print(tabulate([[str(np.round(np.mean(pehes),5))+\" (+-\"+str(np.round(np.std(pehes),5))+\")\", str(np.round(np.mean(mean_ITEs),5))+\" (+-\"+str(np.round(np.std(mean_ITEs),5))+\")\",str(np.round(np.mean(std_ITEs),5))+\" (+-\"+str(np.round(np.std(std_ITEs),5))+\")\",p_value]], [\"PEHE (std)\",\"ATE (std)\",\"STD ITE (std)\",\"p-Value Treatment\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_absolute_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>3.753355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>3.341375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>3.316188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>3.249610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>3.208891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.127625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_absolute_shap  p_value\n",
       "x1            3.753355      0.0\n",
       "x2            3.341375      0.0\n",
       "x3            3.316188      0.0\n",
       "x4            3.249610      0.0\n",
       "x5            3.208891      0.0\n",
       "T             0.127625      0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_T1_shaps_pd[processed_T1_shaps_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_absolute_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>3.753355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>3.341375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>3.316188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>3.249610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>3.208891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.127612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_absolute_shap  p_value\n",
       "x1            3.753355      0.0\n",
       "x2            3.341375      0.0\n",
       "x3            3.316188      0.0\n",
       "x4            3.249610      0.0\n",
       "x5            3.208891      0.0\n",
       "T             0.127612      0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_T0_shaps_pd[processed_T0_shaps_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_shap</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>-0.255223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_shap  p_value\n",
       "T  -0.255223      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_shap_diff_pd[processed_shap_diff_pd.p_value<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
